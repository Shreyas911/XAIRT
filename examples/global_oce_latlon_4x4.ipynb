{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ea14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import the required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import xarray as xr\n",
    "import xmitgcm\n",
    "from xmitgcm import open_mdsdataset\n",
    "\n",
    "# Append to sys.path the absolute path to src/XAIRT\n",
    "path_list = os.path.abspath('').split('/')\n",
    "path_src_XAIRT = ''\n",
    "for link in path_list[:-1]:\n",
    "    path_src_XAIRT = path_src_XAIRT+link+'/'\n",
    "sys.path.append(path_src_XAIRT+'/src')\n",
    "\n",
    "# Now import module XAIRT\n",
    "from XAIRT import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Corresponds to grid point index (ny,nx) = (32,58)\n",
    "costLon  = 240\n",
    "costLat  = 50\n",
    "\n",
    "nx = 90\n",
    "ny = 40\n",
    "nz = 15\n",
    "\n",
    "mainDir = '/scratch2/shreyas/global_oce_latlon_4x4'\n",
    "\n",
    "gridDir = mainDir + '/run_spinup/GRID'\n",
    "\n",
    "DataDirs = [mainDir + '/run_forward_50yr_dailydump_pk000059400/diags/untarred_output',\n",
    "             mainDir + '/run_forward_50yr_dailydump_pk000061200/diags/untarred_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf87cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SAVING DATA INTO XARRAY DATASET ####\n",
    "#### SAVING XARRAY DATASET AS NC FILE ####\n",
    "\n",
    "# files_list_TS = []\n",
    "# files_list_2Datm = []\n",
    "# init_indices = [594001, 612001]\n",
    "# length_rec = 18000\n",
    "\n",
    "# for i in range(length_rec):\n",
    "#     index = init_indices[0] + i\n",
    "#     files_list_TS.append(DataDirs[0] + '/' + f'state3d_TS.0000{index:6d}.data')\n",
    "#     files_list_2Datm.append(DataDirs[0] + '/' + f'state2d_atm.0000{index:6d}.data')\n",
    "# for i in range(length_rec):\n",
    "#     index = init_indices[1] + i\n",
    "#     files_list_TS.append(DataDirs[1] + '/' + f'state3d_TS.0000{index:6d}.data')\n",
    "#     files_list_2Datm.append(DataDirs[1] + '/' + f'state2d_atm.0000{index:6d}.data')\n",
    "    \n",
    "# nt = len(files_list_TS)\n",
    "# thetaSurf = np.zeros((nt, ny, nx))\n",
    "# saltSurf  = np.zeros((nt, ny, nx))\n",
    "# tauX      = np.zeros((nt, ny, nx))\n",
    "# tauY      = np.zeros((nt, ny, nx))\n",
    "                     \n",
    "# for i in range(len(files_list_TS)):\n",
    "#     thetaSurf[i] = np.reshape(np.fromfile(files_list_TS[i], dtype = '>f')[:nx*ny*nz],\n",
    "#                               (nz, ny, nx))[0]\n",
    "#     saltSurf[i]  = np.reshape(np.fromfile(files_list_TS[i], dtype = '>f')[nx*ny*nz:],\n",
    "#                               (nz, ny, nx))[0]\n",
    "#     tauX[i]      = np.reshape(np.fromfile(files_list_2Datm[i], dtype = '>f')[7*nx*ny:8*nx*ny],\n",
    "#                               (ny, nx))\n",
    "#     tauY[i]      = np.reshape(np.fromfile(files_list_2Datm[i], dtype = '>f')[8*nx*ny:9*nx*ny],\n",
    "#                               (ny, nx))\n",
    "    \n",
    "# # https://docs.xarray.dev/en/stable/generated/xarray.cftime_range.html\n",
    "# # Allows to filter like this - da_thetaSurf.sel(time=da_thetaSurf.time.dt.month.isin([6, 7, 8]))\n",
    "# timeDim = xr.cftime_range(start=\"1651\", end = \"1751\", calendar=\"360_day\")[:-1]\n",
    "# latDim    = np.arange(-78.,82.,4.)\n",
    "# lonDim    = np.arange(0.,360,4.)\n",
    "\n",
    "# da_XC = xr.DataArray(\n",
    "#     data=np.tile(lonDim, (40,1)),\n",
    "#     dims=[\"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Longitude tiled\"),\n",
    "# )\n",
    "\n",
    "# da_YC = xr.DataArray(\n",
    "#     data=np.tile(latDim, (90,1)).T,\n",
    "#     dims=[\"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Latitude tiled\"),\n",
    "# )\n",
    "\n",
    "# da_thetaSurf = xr.DataArray(\n",
    "#     data=thetaSurf,\n",
    "#     dims=[\"time\", \"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         time         = timeDim,\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Surface temperature field\"),\n",
    "# )\n",
    "\n",
    "# da_saltSurf = xr.DataArray(\n",
    "#     data=saltSurf,\n",
    "#     dims=[\"time\", \"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         time         = timeDim,\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Surface salinity field\"),\n",
    "# )\n",
    "\n",
    "# da_tauX = xr.DataArray(\n",
    "#     data=tauX,\n",
    "#     dims=[\"time\", \"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         time         = timeDim,\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Surface zonal wind stress\"),\n",
    "# )\n",
    "\n",
    "# da_tauY = xr.DataArray(\n",
    "#     data=tauY,\n",
    "#     dims=[\"time\", \"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         time         = timeDim,\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Surface meridional wind stress\"),\n",
    "# )\n",
    "\n",
    "# ds = xr.Dataset()\n",
    "# ds = ds.assign(XC        = da_XC,\n",
    "#                YC        = da_YC,\n",
    "#                thetaSurf = da_thetaSurf,\n",
    "#                saltSurf  = da_saltSurf,\n",
    "#                tauX      = da_tauX,\n",
    "#                tauY      = da_tauY)\n",
    "\n",
    "# hfacc = np.reshape(np.fromfile(gridDir + '/hFacC.data', \n",
    "#                               dtype = '>f'), (nz, ny, nx))\n",
    "\n",
    "# hFacC_mask = hfacc > 0\n",
    "# hFacC_mask = hFacC_mask.astype(np.float32)\n",
    "# hFacC_mask = hFacC_mask[0]\n",
    "\n",
    "# XC = ds['XC'].data\n",
    "# YC = ds['YC'].data\n",
    "\n",
    "# latMask = YC > -20.0\n",
    "# latMask = latMask.astype(float)\n",
    "\n",
    "# maskFinal = hFacC_mask * latMask\n",
    "# NaNmaskFinal = np.copy(maskFinal)\n",
    "# NaNmaskFinal[NaNmaskFinal == 0] = np.nan\n",
    "\n",
    "# da_hFacC_mask = xr.DataArray(\n",
    "#     data=hFacC_mask,\n",
    "#     dims=[\"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"hFacC mask 2D 1 if > 0, else 0\"),\n",
    "# )\n",
    "\n",
    "# da_latMask = xr.DataArray(\n",
    "#     data=latMask,\n",
    "#     dims=[\"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Latitude Mask 1 if > -20, else 0\"),\n",
    "# )\n",
    "\n",
    "# da_maskFinal = xr.DataArray(\n",
    "#     data=maskFinal,\n",
    "#     dims=[\"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Mask 2D 1 if > 0, else 0\"),\n",
    "# )\n",
    "\n",
    "# da_NaNmaskFinal = xr.DataArray(\n",
    "#     data=NaNmaskFinal,\n",
    "#     dims=[\"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Mask 2D True if > 0, else NaN\"),\n",
    "# )\n",
    "\n",
    "# ds = ds.assign(hFacC_mask   = da_hFacC_mask,\n",
    "#           latMask      = da_latMask,\n",
    "#           maskFinal    = da_maskFinal,\n",
    "#           NaNmaskFinal = da_NaNmaskFinal)\n",
    "\n",
    "# wetpoints = np.nonzero(ds['maskFinal'].data)\n",
    "\n",
    "# ds.to_netcdf('/scratch2/shreyas/LRP_eccov4r4_data/dataGlobalLonLat4x4.nc', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd95c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/scratch2/shreyas/LRP_eccov4r4_data/dataGlobalLonLat4x4.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b9384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(ds['XC'], ds['YC'], \n",
    "           ds['NaNmaskFinal']*ds['thetaSurf'].isel(time = 0), \n",
    "           cmap = 'jet', vmax = 35)\n",
    "plt.scatter(240,50,marker = 'x', color = 'brown', label = \"Objective function loc\")\n",
    "plt.scatter(232,50,marker = 'o', color = 'black', label = \"Nearest wetpoint\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = ds[\"thetaSurf\"].sel(latitude=50.,longitude=240.)\n",
    "thetaSurfWet = ds[\"thetaSurf\"].data[:, wetpoints[0], wetpoints[1]]\n",
    "saltSurfWet  = ds[\"saltSurf\"].data[:, wetpoints[0], wetpoints[1]]\n",
    "tauXWet      = ds[\"tauX\"].data[:, wetpoints[0], wetpoints[1]]\n",
    "tauYWet      = ds[\"tauY\"].data[:, wetpoints[0], wetpoints[1]]\n",
    "tauWet       = np.concatenate((tauXWet,tauYWet), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ee3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quickSetup(X, y, numVars, lrp_methods, lagSteps, baseAnalysis, numAnalysis, **NNkwargs):\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    if lagSteps > 0:\n",
    "        K = TrainFullyConnectedNN(X[:-lagSteps], y[lagSteps:], **NNkwargs)\n",
    "        L = TrainLR(X[:-lagSteps], y[lagSteps:], y_ref = 0.0, fit_intercept = False)\n",
    "    if lagSteps == 0:\n",
    "        K = TrainFullyConnectedNN(X, y, **NNkwargs)\n",
    "        L = TrainLR(X, y, y_ref = 0.0, fit_intercept = False)\n",
    "        \n",
    "    best_model = K.quickTrain()\n",
    "    result['cost_predict_NN'] = best_model.predict(X)\n",
    "    \n",
    "    regr = L.quickTrain()\n",
    "    result['cost_predict_LR'] = regr.predict(X)\n",
    "    \n",
    "    normalizeDict = {'bool_': True, 'kind': 'MaxAbs'}\n",
    "    kwargs = {'y_ref': 0.00}\n",
    "\n",
    "    \n",
    "    \n",
    "    for method in lrp_methods:\n",
    "        \n",
    "        print(f'Analyze using {method}')\n",
    "        \n",
    "        Xplain = XAIR(best_model, method, 'classic', X[baseAnalysis:baseAnalysis+numAnalysis], normalizeDict, **kwargs)\n",
    "        a, _  = Xplain.quick_analyze()\n",
    "        perVar = int(a.shape[1]/numVars)\n",
    "        \n",
    "        rel = np.zeros((numVars, numAnalysis, ny, nx))\n",
    "        rel[:,:,:,:] = np.nan\n",
    "        \n",
    "        for numvar in range(numVars):\n",
    "            rel[numvar,:,wetpoints[0],wetpoints[1]] = a[:,numvar*perVar:(numvar+1)*perVar].T\n",
    "        result[method] = rel\n",
    "        \n",
    "    print(f'Analyze using lrp.LR')\n",
    "    \n",
    "    XL = XLR(regr, X[baseAnalysis:baseAnalysis+numAnalysis])\n",
    "    a_LR, _ = XL.quick_analyze()\n",
    "    perVar = int(a_LR.shape[1]/numVars)\n",
    "    \n",
    "    rel_LR = np.zeros((numVars, numAnalysis, ny, nx))\n",
    "    rel_LR[:,:,:,:] = np.nan\n",
    "\n",
    "    for numvar in range(numVars):\n",
    "        rel_LR[numvar,:,wetpoints[0],wetpoints[1]] = a_LR[:,numvar*perVar:(numvar+1)*perVar].T\n",
    "    result['lrp.LR'] = rel_LR\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e803d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LayersTheta = [{'size': thetaSurfWet.shape[1], 'activation': None    , 'use_bias': None},\n",
    "          {'size': 20                   , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1                    , 'activation': 'linear', 'use_bias': False}]\n",
    "LayersSalt = [{'size': saltSurfWet.shape[1], 'activation': None    , 'use_bias': None},\n",
    "          {'size': 20                   , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1                    , 'activation': 'linear', 'use_bias': False}]\n",
    "LayersTau = [{'size': tauWet.shape[1], 'activation': None    , 'use_bias': None},\n",
    "          {'size': 40                   , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1                    , 'activation': 'linear', 'use_bias': False}]\n",
    "Losses = [{'kind': 'mse', 'weight': 1.0}]\n",
    "\n",
    "LRPDict_theta = {}\n",
    "LRPDict_salt  = {}\n",
    "LRPDict_tau   = {}\n",
    "lagStepsList = [30, 60, 90, 120, 150, 180]\n",
    "\n",
    "kwargs = {'losses': Losses, 'optim': 'adam', 'metrics': ['mae'],\n",
    "            'batch_size': 10, 'epochs': 50, 'validation_split': 0.2,\n",
    "            'filename': 'model', 'dirname': os.path.abspath('')}\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "\n",
    "    print(f'Lag: {lagStepsList[i]} days, for Salt')\n",
    "    LRPDict_salt[f'LRP{lagStepsList[i]}'] = quickSetup(saltSurfWet, cost, numVars = 1, lrp_methods = ['lrp.alpha_1_beta_0', 'lrp.z'],\n",
    "                                                       lagSteps = lagStepsList[i], baseAnalysis = 0, numAnalysis = 360,\n",
    "                                                       layers = LayersSalt, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0c191",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP_a1b0 for salinity (NN trained using salinity only)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.mean(LRPDict_salt[f'LRP{lagStepsList[i]}']['lrp.alpha_1_beta_0'][0], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP_a1b0 for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP_z for salinity (NN trained using salinity only)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.mean(LRPDict_salt[f'LRP{lagStepsList[i]}']['lrp.z'][0], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP_z for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e08583",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP_LinearRegression for salinity (NN trained using salinity only)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.mean(LRPDict_salt[f'LRP{lagStepsList[i]}']['lrp.LR'][0], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP_LR for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa85328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LayersTheta = [{'size': thetaSurfWet.shape[1], 'activation': None    , 'use_bias': None},\n",
    "          {'size': 20                   , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1                    , 'activation': 'linear', 'use_bias': False}]\n",
    "LayersSalt = [{'size': saltSurfWet.shape[1], 'activation': None    , 'use_bias': None},\n",
    "          {'size': 20                   , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1                    , 'activation': 'linear', 'use_bias': False}]\n",
    "LayersTau = [{'size': tauWet.shape[1], 'activation': None    , 'use_bias': None},\n",
    "          {'size': 40                   , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1                    , 'activation': 'linear', 'use_bias': False}]\n",
    "Losses = [{'kind': 'mse', 'weight': 1.0}]\n",
    "\n",
    "LRPDict_theta = {}\n",
    "LRPDict_salt  = {}\n",
    "LRPDict_tau   = {}\n",
    "lagStepsList = [30, 60, 90, 120, 150, 180]\n",
    "\n",
    "kwargs = {'losses': Losses, 'optim': 'adam', 'metrics': ['mae'],\n",
    "            'batch_size': 10, 'epochs': 50, 'validation_split': 0.2,\n",
    "            'filename': 'model', 'dirname': os.path.abspath('')}\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    \n",
    "    print(f'Lag: {lagStepsList[i]} days, for Theta')\n",
    "    LRPDict_theta[f'LRP{lagStepsList[i]}'] = quickSetup(thetaSurfWet, cost, numVars = 1, lrp_methods = ['lrp.alpha_1_beta_0', 'lrp.z'],\n",
    "                                                        lagSteps = lagStepsList[i], baseAnalysis = 0, numAnalysis = 360,\n",
    "                                                        layers = LayersTheta, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad612b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LRPDict_theta[f'LRP30'] = quickSetup(thetaSurfWet, cost, numVars = 1, lrp_methods = ['lrp.alpha_1_beta_0', 'lrp.z'],\n",
    "                                                        lagSteps = 30, baseAnalysis = 0, numAnalysis = 360,\n",
    "                                                        layers = LayersTheta, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f02d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP_a1b0 for theta (NN trained using theta only)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.mean(LRPDict_theta[f'LRP{lagStepsList[i]}']['lrp.alpha_1_beta_0'][0], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP_a1b0 for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP_z for theta (NN trained using theta only)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.mean(LRPDict_theta[f'LRP{lagStepsList[i]}']['lrp.z'][0], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP_z for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ce9781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP_LR for theta (NN trained using theta only)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.mean(LRPDict_theta[f'LRP{lagStepsList[i]}']['lrp.LR'][0], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP_LR for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740569bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "LayersTheta = [{'size': thetaSurfWet.shape[1], 'activation': None    , 'use_bias': None},\n",
    "          {'size': 20                   , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1                    , 'activation': 'linear', 'use_bias': False}]\n",
    "LayersSalt = [{'size': saltSurfWet.shape[1], 'activation': None    , 'use_bias': None},\n",
    "          {'size': 20                   , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1                    , 'activation': 'linear', 'use_bias': False}]\n",
    "LayersTau = [{'size': tauWet.shape[1], 'activation': None    , 'use_bias': None},\n",
    "          {'size': 40                   , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1                    , 'activation': 'linear', 'use_bias': False}]\n",
    "Losses = [{'kind': 'mse', 'weight': 1.0}]\n",
    "\n",
    "LRPDict_theta = {}\n",
    "LRPDict_salt  = {}\n",
    "LRPDict_tau   = {}\n",
    "lagStepsList = [30, 60, 90, 120, 150, 180]\n",
    "\n",
    "kwargs = {'losses': Losses, 'optim': 'adam', 'metrics': ['mae'],\n",
    "            'batch_size': 10, 'epochs': 50, 'validation_split': 0.2,\n",
    "            'filename': 'model', 'dirname': os.path.abspath('')}\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "\n",
    "    print(f'Lag: {lagStepsList[i]} days, for Tau')\n",
    "    LRPDict_tau[f'LRP{lagStepsList[i]}'] = quickSetup(tauWet, cost, numVars = 2, lrp_methods = ['lrp.alpha_1_beta_0', 'lrp.z'],\n",
    "                                                      lagSteps = lagStepsList[i], baseAnalysis = 0, numAnalysis = 360, \n",
    "                                                      layers = LayersTau, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP_a1b0 for tauX (NN trained using tauX, tauY)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.mean(LRPDict_tau[f'LRP{lagStepsList[i]}']['lrp.alpha_1_beta_0'][0], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP_a1b0 for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP_z for tauX (NN trained using tauX, tauY)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.mean(LRPDict_tau[f'LRP{lagStepsList[i]}']['lrp.z'][0], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP_z for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a8ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP_LR for tauX (NN trained using tauX, tauY)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.mean(LRPDict_tau[f'LRP{lagStepsList[i]}']['lrp.LR'][0], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP_LR for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdfccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP_a1b0 for tauY (NN trained using tauX, tauY)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.mean(LRPDict_tau[f'LRP{lagStepsList[i]}']['lrp.alpha_1_beta_0'][1], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP_a1b0 for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53759251",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP_z for tauY (NN trained using tauX, tauY)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.mean(LRPDict_tau[f'LRP{lagStepsList[i]}']['lrp.z'][1], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP_z for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f65d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP_LR for tauY (NN trained using tauX, tauY)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.mean(LRPDict_tau[f'LRP{lagStepsList[i]}']['lrp.LR'][1], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP_LR for time lag: {lagStepsList[i]} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_LRP",
   "language": "python",
   "name": "py310_lrp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
