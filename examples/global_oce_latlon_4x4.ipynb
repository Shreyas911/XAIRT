{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ea14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import the required libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import xarray as xr\n",
    "import xmitgcm\n",
    "from xmitgcm import open_mdsdataset\n",
    "\n",
    "# Append to sys.path the absolute path to src/XAIRT\n",
    "path_list = os.path.abspath('').split('/')\n",
    "path_src_XAIRT = ''\n",
    "for link in path_list[:-1]:\n",
    "    path_src_XAIRT = path_src_XAIRT+link+'/'\n",
    "sys.path.append(path_src_XAIRT+'/src')\n",
    "\n",
    "# Now import module XAIRT\n",
    "from XAIRT import *\n",
    "\n",
    "# See if GPUs are available\n",
    "from keras import backend as K\n",
    "if bool(K._get_available_gpus()):\n",
    "    print(\"Running on GPU\")\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce14446-f2c0-4a41-9382-9a8a6b00f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Corresponds to grid point index (ny,nx) = (32,58)\n",
    "costLon = 240\n",
    "costLat = 50\n",
    "\n",
    "nx = 90\n",
    "ny = 40\n",
    "nz = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf87cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SAVING DATA INTO XARRAY DATASET ####\n",
    "#### SAVING XARRAY DATASET AS NC FILE ####\n",
    "\n",
    "# mainDir = '/scratch2/shreyas/global_oce_latlon_4x4'\n",
    "\n",
    "# gridDir = mainDir + '/run_spinup/GRID'\n",
    "\n",
    "# DataDirs = [mainDir + '/run_forward_50yr_dailydump_pk000059400/diags/untarred_output',\n",
    "#              mainDir + '/run_forward_50yr_dailydump_pk000061200/diags/untarred_output']\n",
    "\n",
    "# files_list_TS = []\n",
    "# files_list_2Datm = []\n",
    "# init_indices = [594001, 612001]\n",
    "# length_rec = 18000\n",
    "\n",
    "# for i in range(length_rec):\n",
    "#     index = init_indices[0] + i\n",
    "#     files_list_TS.append(DataDirs[0] + '/' + f'state3d_TS.0000{index:6d}.data')\n",
    "#     files_list_2Datm.append(DataDirs[0] + '/' + f'state2d_atm.0000{index:6d}.data')\n",
    "# for i in range(length_rec):\n",
    "#     index = init_indices[1] + i\n",
    "#     files_list_TS.append(DataDirs[1] + '/' + f'state3d_TS.0000{index:6d}.data')\n",
    "#     files_list_2Datm.append(DataDirs[1] + '/' + f'state2d_atm.0000{index:6d}.data')\n",
    "    \n",
    "# nt = len(files_list_TS)\n",
    "# thetaSurf = np.zeros((nt, ny, nx))\n",
    "# saltSurf  = np.zeros((nt, ny, nx))\n",
    "# tauX      = np.zeros((nt, ny, nx))\n",
    "# tauY      = np.zeros((nt, ny, nx))\n",
    "                     \n",
    "# for i in range(len(files_list_TS)):\n",
    "#     thetaSurf[i] = np.reshape(np.fromfile(files_list_TS[i], dtype = '>f')[:nx*ny*nz],\n",
    "#                               (nz, ny, nx))[0]\n",
    "#     saltSurf[i]  = np.reshape(np.fromfile(files_list_TS[i], dtype = '>f')[nx*ny*nz:],\n",
    "#                               (nz, ny, nx))[0]\n",
    "#     tauX[i]      = np.reshape(np.fromfile(files_list_2Datm[i], dtype = '>f')[7*nx*ny:8*nx*ny],\n",
    "#                               (ny, nx))\n",
    "#     tauY[i]      = np.reshape(np.fromfile(files_list_2Datm[i], dtype = '>f')[8*nx*ny:9*nx*ny],\n",
    "#                               (ny, nx))\n",
    "    \n",
    "# # https://docs.xarray.dev/en/stable/generated/xarray.cftime_range.html\n",
    "# # Allows to filter like this - da_thetaSurf.sel(time=da_thetaSurf.time.dt.month.isin([6, 7, 8]))\n",
    "# timeDim = xr.cftime_range(start=\"1651\", end = \"1751\", calendar=\"360_day\")[:-1]\n",
    "# latDim    = np.arange(-78.,82.,4.)\n",
    "# lonDim    = np.arange(0.,360,4.)\n",
    "\n",
    "# da_XC = xr.DataArray(\n",
    "#     data=np.tile(lonDim, (40,1)),\n",
    "#     dims=[\"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Longitude tiled\"),\n",
    "# )\n",
    "\n",
    "# da_YC = xr.DataArray(\n",
    "#     data=np.tile(latDim, (90,1)).T,\n",
    "#     dims=[\"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Latitude tiled\"),\n",
    "# )\n",
    "\n",
    "# da_thetaSurf = xr.DataArray(\n",
    "#     data=thetaSurf,\n",
    "#     dims=[\"time\", \"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         time         = timeDim,\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Surface temperature field\"),\n",
    "# )\n",
    "\n",
    "# da_saltSurf = xr.DataArray(\n",
    "#     data=saltSurf,\n",
    "#     dims=[\"time\", \"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         time         = timeDim,\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Surface salinity field\"),\n",
    "# )\n",
    "\n",
    "# da_tauX = xr.DataArray(\n",
    "#     data=tauX,\n",
    "#     dims=[\"time\", \"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         time         = timeDim,\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Surface zonal wind stress\"),\n",
    "# )\n",
    "\n",
    "# da_tauY = xr.DataArray(\n",
    "#     data=tauY,\n",
    "#     dims=[\"time\", \"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         time         = timeDim,\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Surface meridional wind stress\"),\n",
    "# )\n",
    "\n",
    "# ds = xr.Dataset()\n",
    "# ds = ds.assign(XC        = da_XC,\n",
    "#                YC        = da_YC,\n",
    "#                thetaSurf = da_thetaSurf,\n",
    "#                saltSurf  = da_saltSurf,\n",
    "#                tauX      = da_tauX,\n",
    "#                tauY      = da_tauY)\n",
    "\n",
    "# hfacc = np.reshape(np.fromfile(gridDir + '/hFacC.data', \n",
    "#                               dtype = '>f'), (nz, ny, nx))\n",
    "\n",
    "# hFacC_mask = hfacc > 0\n",
    "# hFacC_mask = hFacC_mask.astype(np.float32)\n",
    "# hFacC_mask = hFacC_mask[0]\n",
    "\n",
    "# XC = ds['XC'].data\n",
    "# YC = ds['YC'].data\n",
    "\n",
    "# latMask = YC > -20.0\n",
    "# latMask = latMask.astype(float)\n",
    "\n",
    "# maskFinal = hFacC_mask * latMask\n",
    "# NaNmaskFinal = np.copy(maskFinal)\n",
    "# NaNmaskFinal[NaNmaskFinal == 0] = np.nan\n",
    "\n",
    "# da_hFacC_mask = xr.DataArray(\n",
    "#     data=hFacC_mask,\n",
    "#     dims=[\"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"hFacC mask 2D 1 if > 0, else 0\"),\n",
    "# )\n",
    "\n",
    "# da_latMask = xr.DataArray(\n",
    "#     data=latMask,\n",
    "#     dims=[\"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Latitude Mask 1 if > -20, else 0\"),\n",
    "# )\n",
    "\n",
    "# da_maskFinal = xr.DataArray(\n",
    "#     data=maskFinal,\n",
    "#     dims=[\"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Mask 2D 1 if > 0, else 0\"),\n",
    "# )\n",
    "\n",
    "# da_NaNmaskFinal = xr.DataArray(\n",
    "#     data=NaNmaskFinal,\n",
    "#     dims=[\"latitude\", \"longitude\"],\n",
    "#     coords=dict(\n",
    "#         latitude     = latDim,\n",
    "#         longitude    = lonDim,\n",
    "#     ),\n",
    "#     attrs=dict(description=\"Mask 2D True if > 0, else NaN\"),\n",
    "# )\n",
    "\n",
    "# ds = ds.assign(hFacC_mask   = da_hFacC_mask,\n",
    "#           latMask      = da_latMask,\n",
    "#           maskFinal    = da_maskFinal,\n",
    "#           NaNmaskFinal = da_NaNmaskFinal)\n",
    "\n",
    "# wetpoints = np.nonzero(ds['maskFinal'].data)\n",
    "\n",
    "# ds.to_netcdf('/scratch2/shreyas/LRP_eccov4r4_data/dataGlobalLonLat4x4.nc', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd95c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sverdrup  - /scratch2/shreyas/LRP_eccov4r4_data\n",
    "### Lonestar6 - /work/07665/shrey911/ls6/LRP_eccov4r4_data\n",
    "\n",
    "ds = xr.open_dataset(f'/work/07665/shrey911/ls6/LRP_eccov4r4_data/dataGlobalLonLat4x4.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b9384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(ds['XC'], ds['YC'], \n",
    "           ds['NaNmaskFinal']*ds['thetaSurf'].isel(time = 0), \n",
    "           cmap = 'jet', vmax = 35)\n",
    "plt.scatter(240,50,marker = 'x', color = 'brown', label = \"Objective function loc\")\n",
    "plt.scatter(232,50,marker = 'o', color = 'black', label = \"Nearest wetpoint\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = ds[\"thetaSurf\"].sel(latitude=50.,longitude=232.)\n",
    "wetpoints = np.nonzero(ds['maskFinal'].data)\n",
    "thetaSurfWet = ds[\"thetaSurf\"].data[:, wetpoints[0], wetpoints[1]]\n",
    "saltSurfWet  = ds[\"saltSurf\"].data[:, wetpoints[0], wetpoints[1]]\n",
    "tauXWet      = ds[\"tauX\"].data[:, wetpoints[0], wetpoints[1]]\n",
    "tauYWet      = ds[\"tauY\"].data[:, wetpoints[0], wetpoints[1]]\n",
    "tauWet       = np.concatenate((tauXWet,tauYWet), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ee3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quickSetup(X, y, numVars, lrp_methods, lagSteps, baseAnalysis, numAnalysis, **NNkwargs):\n",
    "    \n",
    "    result = {}\n",
    "\n",
    "    ### Only X_norm and y_norm make sense for XLR\n",
    "    X_norm = (X-np.mean(X, axis=0))/np.std(X, axis=0)\n",
    "    y_norm = (y-np.mean(y, axis=0))/np.std(y, axis=0)\n",
    "    \n",
    "    if lagSteps > 0:\n",
    "        K = TrainFullyConnectedNN(X[:-lagSteps], y[lagSteps:], **NNkwargs)\n",
    "        L = TrainLR(X_norm[:-lagSteps], y_norm[lagSteps:], y_ref = 0.0, fit_intercept = False)\n",
    "    if lagSteps == 0:\n",
    "        K = TrainFullyConnectedNN(X, y, **NNkwargs)\n",
    "        L = TrainLR(X_norm, y_norm, y_ref = 0.0, fit_intercept = False)\n",
    "        \n",
    "    best_model = K.quickTrain()\n",
    "    result['cost_predict_NN'] = best_model.predict(X)\n",
    "    \n",
    "    regr = L.quickTrain()\n",
    "    result['cost_predict_LR'] = regr.predict(X)\n",
    "    \n",
    "    normalizeDict = {'bool_': True, 'kind': 'MaxAbs'}\n",
    "    kwargs = {'y_ref': 0.00}\n",
    "\n",
    "    \n",
    "    \n",
    "    for method in lrp_methods:\n",
    "\n",
    "        title = method['title']\n",
    "        print(f'Analyze using {title}')\n",
    "        \n",
    "        Xplain = XAIR(best_model, method, 'classic', X[baseAnalysis:baseAnalysis+numAnalysis], normalizeDict, **kwargs)\n",
    "        a, _  = Xplain.quick_analyze()\n",
    "        perVar = int(a.shape[1]/numVars)\n",
    "        \n",
    "        rel = np.zeros((numVars, numAnalysis, ny, nx))\n",
    "        rel[:,:,:,:] = np.nan\n",
    "        \n",
    "        for numvar in range(numVars):\n",
    "            rel[numvar,:,wetpoints[0],wetpoints[1]] = a[:,numvar*perVar:(numvar+1)*perVar].T\n",
    "        result[method['name']] = rel\n",
    "        \n",
    "    print(f'Analyze using LRP-LR')\n",
    "    \n",
    "    XL = XLR(regr, X_norm[baseAnalysis:baseAnalysis+numAnalysis])\n",
    "    a_LR, _ = XL.quick_analyze()\n",
    "    perVar = int(a_LR.shape[1]/numVars)\n",
    "    \n",
    "    rel_LR = np.zeros((numVars, numAnalysis, ny, nx))\n",
    "    rel_LR[:,:,:,:] = np.nan\n",
    "\n",
    "    for numvar in range(numVars):\n",
    "        rel_LR[numvar,:,wetpoints[0],wetpoints[1]] = a_LR[:,numvar*perVar:(numvar+1)*perVar].T\n",
    "    result['lrp.LR'] = rel_LR\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d54bf-7543-44f3-878a-ba40a479fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "LayersTheta = [{'size': thetaSurfWet.shape[1], 'activation': None    , 'use_bias': None},\n",
    "          {'size': 20                   , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1                    , 'activation': 'linear', 'use_bias': False}]\n",
    "LayersSalt = [{'size': saltSurfWet.shape[1], 'activation': None    , 'use_bias': None},\n",
    "          {'size': 20                   , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1                    , 'activation': 'linear', 'use_bias': False}]\n",
    "LayersTau = [{'size': tauWet.shape[1], 'activation': None    , 'use_bias': None},\n",
    "          {'size': 40                   , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1                    , 'activation': 'linear', 'use_bias': False}]\n",
    "Losses = [{'kind': 'mse', 'weight': 1.0}]\n",
    "\n",
    "LRPDict_theta = {}\n",
    "LRPDict_salt  = {}\n",
    "LRPDict_tau   = {}\n",
    "lagStepsList = [30, 60, 90, 120, 150, 180]\n",
    "\n",
    "kwargs = {'losses': Losses, 'optim': 'adam', 'metrics': ['mae'],\n",
    "            'batch_size': 10, 'epochs': 50, 'validation_split': 0.2,\n",
    "            'filename': 'model', 'dirname': os.path.abspath('')}\n",
    "\n",
    "methods = \\\n",
    "[dict(name='gradient',                     optParams = {\"postprocess\": \"abs\"}, title = 'Gradient'),\n",
    " dict(name='guided_backprop',              optParams = {}                    , title = 'Guided Backprop'),\n",
    " dict(name='lrp.z',                        optParams = {}                    , title = 'LRP-Z'),\n",
    " dict(name='lrp.epsilon',                  optParams = {\"epsilon\": 1}        , title = 'LRP-Epsilon'),\n",
    " dict(name='lrp.alpha_1_beta_0',           optParams = {}                    , title = 'LRP-Alpha-1-Beta-0'),\n",
    " dict(name='lrp.sequential_preset_a_flat', optParams = {\"epsilon\": 1}        , title = 'LRP-PresetAFlat'),\n",
    " dict(name='lrp.sequential_preset_b_flat', optParams = {\"epsilon\": 1}        , title = 'LRP-PresetBFlat'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e803d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(lagStepsList)):\n",
    "    print(f'Lag: {lagStepsList[i]} days, for Salt')\n",
    "    LRPDict_salt[f'LRP{lagStepsList[i]}'] = quickSetup(saltSurfWet, cost, numVars = 1, \n",
    "                                                       lrp_methods = methods,\n",
    "                                                       lagSteps = lagStepsList[i], baseAnalysis = 0, numAnalysis = 360,\n",
    "                                                       layers = LayersSalt, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd540f-0a8c-4e6c-9122-642ff1592596",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    fig, ax = plt.subplots(2,3)\n",
    "    pltX = 0\n",
    "    pltY = 0\n",
    "    \n",
    "    fig.suptitle(f'{method[\"title\"]} for salinity (NN trained using salinity only)', fontsize=16)\n",
    "    \n",
    "    for i in range(len(lagStepsList)):\n",
    "        pltX = int(i/3)\n",
    "        pltY = int(i%3)\n",
    "    \n",
    "        field = np.nanmean(LRPDict_salt[f'LRP{lagStepsList[i]}'][method['name']][0], axis = 0)\n",
    "        field = field / np.nanmax(np.abs(field))\n",
    "        \n",
    "        p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "        ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "        fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "        ax[pltX,pltY].set_title(f'Mean annual normalized {method[\"title\"]} for time lag: {lagStepsList[i]}')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP-LR for salinity (Model trained using salinity only)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.nanmean(LRPDict_salt[f'LRP{lagStepsList[i]}']['lrp.LR'][0], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP-LR for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa85328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(lagStepsList)):\n",
    "    \n",
    "    print(f'Lag: {lagStepsList[i]} days, for Theta')\n",
    "    LRPDict_theta[f'LRP{lagStepsList[i]}'] = quickSetup(thetaSurfWet, cost, numVars = 1, \n",
    "                                                        lrp_methods = methods,\n",
    "                                                        lagSteps = lagStepsList[i], baseAnalysis = 0, numAnalysis = 360,\n",
    "                                                        layers = LayersTheta, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5a8a3-01ff-4bd3-a540-c3a8fbcb5e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    fig, ax = plt.subplots(2,3)\n",
    "    pltX = 0\n",
    "    pltY = 0\n",
    "    fig.suptitle(f'{method[\"title\"]} for theta (NN trained using theta only)', fontsize=16)\n",
    "    \n",
    "    for i in range(len(lagStepsList)):\n",
    "        pltX = int(i/3)\n",
    "        pltY = int(i%3)\n",
    "    \n",
    "        field = np.nanmean(LRPDict_theta[f'LRP{lagStepsList[i]}'][method['name']][0], axis = 0)\n",
    "        field = field / np.nanmax(np.abs(field))\n",
    "        \n",
    "        p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "        ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "        fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "        ax[pltX,pltY].set_title(f'Mean annual normalized {method[\"title\"]} for time lag: {lagStepsList[i]}')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP-LR for theta (Model trained using theta only)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.nanmean(LRPDict_theta[f'LRP{lagStepsList[i]}']['lrp.LR'][0], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP-LR for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740569bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(lagStepsList)):\n",
    "\n",
    "    print(f'Lag: {lagStepsList[i]} days, for Tau')\n",
    "    LRPDict_tau[f'LRP{lagStepsList[i]}'] = quickSetup(tauWet, cost, numVars = 2, \n",
    "                                                      lrp_methods = methods,\n",
    "                                                      lagSteps = lagStepsList[i], baseAnalysis = 0, numAnalysis = 360, \n",
    "                                                      layers = LayersTau, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04ef52-ff8b-4b55-927e-56112fc68a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    fig, ax = plt.subplots(2,3)\n",
    "    pltX = 0\n",
    "    pltY = 0\n",
    "    fig.suptitle(f'{method[\"title\"]} for tauX (NN trained using tauX, tauY)', fontsize=16)\n",
    "    \n",
    "    for i in range(len(lagStepsList)):\n",
    "        pltX = int(i/3)\n",
    "        pltY = int(i%3)\n",
    "    \n",
    "        field = np.nanmean(LRPDict_theta[f'LRP{lagStepsList[i]}'][method['name']][0], axis = 0)\n",
    "        field = field / np.nanmax(np.abs(field))\n",
    "        \n",
    "        p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "        ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "        fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "        ax[pltX,pltY].set_title(f'Mean annual normalized {method[\"title\"]} for time lag: {lagStepsList[i]}')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP-LR for tauX (NN trained using tauX, tauY)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.nanmean(LRPDict_theta[f'LRP{lagStepsList[i]}']['lrp.LR'][0], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP-LR for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    fig, ax = plt.subplots(2,3)\n",
    "    pltX = 0\n",
    "    pltY = 0\n",
    "    fig.suptitle(f'{method[\"title\"]} for tauY (NN trained using tauX, tauY)', fontsize=16)\n",
    "    \n",
    "    for i in range(len(lagStepsList)):\n",
    "        pltX = int(i/3)\n",
    "        pltY = int(i%3)\n",
    "    \n",
    "        field = np.nanmean(LRPDict_theta[f'LRP{lagStepsList[i]}'][method['name']][1], axis = 0)\n",
    "        field = field / np.nanmax(np.abs(field))\n",
    "        \n",
    "        p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "        ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "        fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "        ax[pltX,pltY].set_title(f'Mean annual normalized {method[\"title\"]} for time lag: {lagStepsList[i]}')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "fig, ax = plt.subplots(2,3)\n",
    "pltX = 0\n",
    "pltY = 0\n",
    "fig.suptitle('LRP-LR for tauY (NN trained using tauX, tauY)', fontsize=16)\n",
    "\n",
    "for i in range(len(lagStepsList)):\n",
    "    pltX = int(i/3)\n",
    "    pltY = int(i%3)\n",
    "    \n",
    "    field = np.nanmean(LRPDict_theta[f'LRP{lagStepsList[i]}']['lrp.LR'][1], axis = 0)\n",
    "    field = field / np.nanmax(np.abs(field))\n",
    "    \n",
    "    p = ax[pltX,pltY].contourf(field, vmin = -1, vmax = 1, levels = 100, cmap = 'RdBu_r')\n",
    "    ax[pltX,pltY].scatter([58],[32], color = 'black')\n",
    "    fig.colorbar(p, ax=ax[pltX,pltY])\n",
    "    ax[pltX,pltY].set_title(f'Mean annual normalized LRP-LR for time lag: {lagStepsList[i]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f82f2-7130-4d2b-a3c9-a2b0d8ea4575",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = ds[\"thetaSurf\"].sel(latitude=50.,longitude=232.)\n",
    "scipy.signal.detrend(cost, axis=0, type='linear', bp=0, overwrite_data=True)\n",
    "\n",
    "wetpoints = np.nonzero(ds['maskFinal'].data)\n",
    "\n",
    "\n",
    "thetaSurfWet = ds[\"thetaSurf\"].data[:, wetpoints[0], wetpoints[1]]\n",
    "scipy.signal.detrend(thetaSurfWet, axis=0, type='linear', bp=0, overwrite_data=True)\n",
    "\n",
    "saltSurfWet = ds[\"saltSurf\"].data[:, wetpoints[0], wetpoints[1]]\n",
    "scipy.signal.detrend(saltSurfWet, axis=0, type='linear', bp=0, overwrite_data=True)\n",
    "\n",
    "tauXWet = ds[\"tauX\"].data[:, wetpoints[0], wetpoints[1]]\n",
    "tauYWet = ds[\"tauY\"].data[:, wetpoints[0], wetpoints[1]]\n",
    "tauWet       = np.concatenate((tauXWet,tauYWet), axis = 1)\n",
    "\n",
    "scipy.signal.detrend(tauWet, axis=0, type='linear', bp=0, overwrite_data=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_LRP",
   "language": "python",
   "name": "py310_lrp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
