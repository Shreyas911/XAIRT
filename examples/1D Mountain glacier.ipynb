{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fd7382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Import the required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Append to sys.path the absolute path to src/XAIRT\n",
    "path_list = os.path.abspath('').split('/')\n",
    "path_src_XAIRT = ''\n",
    "for link in path_list[:-1]:\n",
    "    path_src_XAIRT = path_src_XAIRT+link+'/'\n",
    "sys.path.append(path_src_XAIRT+'/src')\n",
    "\n",
    "# Now import module XAIRT\n",
    "from XAIRT import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82c18bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample #1000\r"
     ]
    }
   ],
   "source": [
    "def basal_topology_func(x):\n",
    "    b = 1.0 - 0.1*x\n",
    "    return b\n",
    "\n",
    "def solution(nx, nt, L, T, M, basal_topology_func):\n",
    "\n",
    "    if len(M) != nx + 1:\n",
    "        raise ValueError('M specified but len(M) != nx + 1')\n",
    "        \n",
    "    dx = L/nx\n",
    "    dt = T/nt\n",
    "    x = np.linspace(0,L,nx+1)\n",
    "    t = np.linspace(0,T,nt+1)\n",
    "\n",
    "    b = basal_topology_func(x)\n",
    "\n",
    "    A = 1e-16\n",
    "    rho = 920.0\n",
    "    g = 9.2 \n",
    "    n = 3\n",
    "\n",
    "    C = 2*A/(n+2) * (rho*g)**n * (1e3)**n\n",
    "\n",
    "    h = np.zeros((nx+1,nt+1))\n",
    "    H = np.zeros((nx+1,nt+1))\n",
    "    h[:,0] = b\n",
    "    h[0,:] = b[0]\n",
    "    h[-1,:] = b[-1]\n",
    "\n",
    "    H[:,0] = h[:,0] - b\n",
    "    H[0,:] = h[0,:] - b[0]\n",
    "    H[-1,:] = h[-1,:] - b[-1]\n",
    "\n",
    "    for i in range(1,len(t)):\n",
    "\n",
    "        D = C *((H[1:,i-1]+H[:nx,i-1])/2.0)**(n+2) * ((h[1:,i-1] - h[:nx,i-1])/dx)**(n-1)\n",
    "\n",
    "        phi = -D*(h[1:,i-1]-h[:nx,i-1])/dx\n",
    "\n",
    "        h[1:nx,i] = h[1:nx,i-1] + M[1:nx]*dt - dt/dx * (phi[1:]-phi[:nx-1])\n",
    "        h[1:nx,i] = (h[1:nx,i] < b[1:nx]) * b[1:nx] + (h[1:nx,i] >= b[1:nx]) * h[1:nx,i]\n",
    "        H[:,i] = np.maximum(h[:,i] - b, 0.)\n",
    "\n",
    "        if not np.any(H[:,i]>=0.0):\n",
    "            raise Exception(\"Something went wrong.\")\n",
    "            \n",
    "    Volume = np.sum(H)*dx\n",
    "    \n",
    "    return H[int(nx/3),-1], h[int(nx/2),-1], Volume\n",
    "\n",
    "L = 30.\n",
    "T = 10.\n",
    "nx = 300\n",
    "nt = 12000\n",
    "samples = 1000\n",
    "\n",
    "M_samples = 0.01*np.random.rand(samples, nx+1)\n",
    "H_samples = np.zeros((samples,1), dtype = np.float64)\n",
    "Volume_samples = np.zeros((samples,1), dtype = np.float64)\n",
    "\n",
    "for sample in range(samples):\n",
    "    if (sample+1) % 100 == 0:\n",
    "        print(f'Sample #{sample+1}', end='\\r')\n",
    "    H_samples[sample], _, Volume_samples[sample] = solution(nx, nt, L, T, M_samples[sample], basal_topology_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f166a7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index #300\r"
     ]
    }
   ],
   "source": [
    "def FD_grad(M, pert = 0.0001, normalize = True):\n",
    "    grad = np.zeros(M.shape)\n",
    "\n",
    "    H, *_ = solution(nx, nt, L, T, M, basal_topology_func)\n",
    "    \n",
    "    for i in range(len(M)):\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Index #{i+1}', end='\\r')\n",
    "            \n",
    "        M_pos = np.copy(M)\n",
    "        M_pos[i] = M_pos[i]*(1+pert)\n",
    "        H_pos, *_ = solution(nx, nt, L, T, M_pos, basal_topology_func)\n",
    "        grad[i] = (H_pos - H) / (2*pert)\n",
    "\n",
    "    grad = grad / np.max(np.abs(grad))\n",
    "    \n",
    "    return grad\n",
    "\n",
    "grad_0 = FD_grad(M_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9844b26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 05:41:59.064565: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ohpc/pub/libs/gnu7/openmpi/netcdf/4.5.0/lib:/opt/ohpc/pub/libs/gnu7/openmpi/netcdf-fortran/4.4.4/lib:/opt/ohpc/pub/libs/gnu7/openmpi/hdf5/1.10.1/lib:/opt/ohpc/pub/mpi/openmpi-gnu7/1.10.7/lib:/opt/ohpc/pub/compiler/gcc/7.3.0/lib64:/home/shreyas/lis-2.1.3/installation/lib:/share/jdk-16.0.1/lib::\n",
      "2023-08-01 05:41:59.064629: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-01 05:41:59.064671: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c5-3): /proc/driver/nvidia/version does not exist\n",
      "2023-08-01 05:41:59.065509: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-01 05:41:59.090860: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670/800 [========================>.....] - ETA: 0s - loss: 5.9574e-04 - mae: 0.0198\n",
      "Epoch 1: val_loss improved from inf to 0.00053, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 417us/sample - loss: 5.7407e-04 - mae: 0.0196 - val_loss: 5.3152e-04 - val_mae: 0.0192\n",
      "Epoch 2/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 4.5542e-04 - mae: 0.0179\n",
      "Epoch 2: val_loss improved from 0.00053 to 0.00051, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 4.6567e-04 - mae: 0.0184 - val_loss: 5.0682e-04 - val_mae: 0.0187\n",
      "Epoch 3/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 4.3784e-04 - mae: 0.0176\n",
      "Epoch 3: val_loss improved from 0.00051 to 0.00049, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 187us/sample - loss: 4.3358e-04 - mae: 0.0175 - val_loss: 4.8715e-04 - val_mae: 0.0183\n",
      "Epoch 4/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 3.7801e-04 - mae: 0.0165\n",
      "Epoch 4: val_loss did not improve from 0.00049\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 3.8787e-04 - mae: 0.0167 - val_loss: 4.9416e-04 - val_mae: 0.0180\n",
      "Epoch 5/1000\n",
      "650/800 [=======================>......] - ETA: 0s - loss: 3.6448e-04 - mae: 0.0160\n",
      "Epoch 5: val_loss improved from 0.00049 to 0.00048, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 208us/sample - loss: 3.6444e-04 - mae: 0.0161 - val_loss: 4.7782e-04 - val_mae: 0.0177\n",
      "Epoch 6/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 3.2472e-04 - mae: 0.0150\n",
      "Epoch 6: val_loss improved from 0.00048 to 0.00042, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 171us/sample - loss: 3.4333e-04 - mae: 0.0155 - val_loss: 4.1823e-04 - val_mae: 0.0171\n",
      "Epoch 7/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 3.0216e-04 - mae: 0.0146\n",
      "Epoch 7: val_loss improved from 0.00042 to 0.00040, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 202us/sample - loss: 3.0676e-04 - mae: 0.0147 - val_loss: 3.9883e-04 - val_mae: 0.0166\n",
      "Epoch 8/1000\n",
      "630/800 [======================>.......] - ETA: 0s - loss: 2.9518e-04 - mae: 0.0144\n",
      "Epoch 8: val_loss did not improve from 0.00040\n",
      "800/800 [==============================] - 0s 190us/sample - loss: 2.8839e-04 - mae: 0.0142 - val_loss: 4.0689e-04 - val_mae: 0.0163\n",
      "Epoch 9/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 2.7382e-04 - mae: 0.0138\n",
      "Epoch 9: val_loss improved from 0.00040 to 0.00036, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 199us/sample - loss: 2.6892e-04 - mae: 0.0137 - val_loss: 3.5844e-04 - val_mae: 0.0157\n",
      "Epoch 10/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 2.6136e-04 - mae: 0.0132\n",
      "Epoch 10: val_loss improved from 0.00036 to 0.00034, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 196us/sample - loss: 2.6012e-04 - mae: 0.0132 - val_loss: 3.3650e-04 - val_mae: 0.0153\n",
      "Epoch 11/1000\n",
      "670/800 [========================>.....] - ETA: 0s - loss: 2.2078e-04 - mae: 0.0123\n",
      "Epoch 11: val_loss improved from 0.00034 to 0.00033, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 203us/sample - loss: 2.1911e-04 - mae: 0.0122 - val_loss: 3.2839e-04 - val_mae: 0.0147\n",
      "Epoch 12/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.8858e-04 - mae: 0.0113\n",
      "Epoch 12: val_loss improved from 0.00033 to 0.00029, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 196us/sample - loss: 1.9096e-04 - mae: 0.0113 - val_loss: 2.9481e-04 - val_mae: 0.0144\n",
      "Epoch 13/1000\n",
      "670/800 [========================>.....] - ETA: 0s - loss: 1.7105e-04 - mae: 0.0106\n",
      "Epoch 13: val_loss did not improve from 0.00029\n",
      "800/800 [==============================] - 0s 176us/sample - loss: 1.7586e-04 - mae: 0.0108 - val_loss: 3.2815e-04 - val_mae: 0.0142\n",
      "Epoch 14/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.5824e-04 - mae: 0.0101\n",
      "Epoch 14: val_loss improved from 0.00029 to 0.00027, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 204us/sample - loss: 1.5737e-04 - mae: 0.0101 - val_loss: 2.6533e-04 - val_mae: 0.0139\n",
      "Epoch 15/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.4379e-04 - mae: 0.0098\n",
      "Epoch 15: val_loss improved from 0.00027 to 0.00024, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 197us/sample - loss: 1.4464e-04 - mae: 0.0098 - val_loss: 2.4467e-04 - val_mae: 0.0127\n",
      "Epoch 16/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.1906e-04 - mae: 0.0087\n",
      "Epoch 16: val_loss improved from 0.00024 to 0.00023, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 183us/sample - loss: 1.2422e-04 - mae: 0.0089 - val_loss: 2.2810e-04 - val_mae: 0.0122\n",
      "Epoch 17/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.1181e-04 - mae: 0.0085\n",
      "Epoch 17: val_loss improved from 0.00023 to 0.00021, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 199us/sample - loss: 1.1466e-04 - mae: 0.0086 - val_loss: 2.1301e-04 - val_mae: 0.0117\n",
      "Epoch 18/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 9.7993e-05 - mae: 0.0079\n",
      "Epoch 18: val_loss improved from 0.00021 to 0.00019, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 190us/sample - loss: 9.8690e-05 - mae: 0.0079 - val_loss: 1.9343e-04 - val_mae: 0.0116\n",
      "Epoch 19/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 9.1224e-05 - mae: 0.0076\n",
      "Epoch 19: val_loss improved from 0.00019 to 0.00018, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 175us/sample - loss: 9.3987e-05 - mae: 0.0077 - val_loss: 1.7714e-04 - val_mae: 0.0110\n",
      "Epoch 20/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 8.3116e-05 - mae: 0.0072\n",
      "Epoch 20: val_loss improved from 0.00018 to 0.00016, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 187us/sample - loss: 8.3121e-05 - mae: 0.0072 - val_loss: 1.6321e-04 - val_mae: 0.0104\n",
      "Epoch 21/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 7.7969e-05 - mae: 0.0070\n",
      "Epoch 21: val_loss improved from 0.00016 to 0.00016, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 189us/sample - loss: 7.7432e-05 - mae: 0.0070 - val_loss: 1.5810e-04 - val_mae: 0.0099\n",
      "Epoch 22/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 6.7240e-05 - mae: 0.0065\n",
      "Epoch 22: val_loss did not improve from 0.00016\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 6.6063e-05 - mae: 0.0064 - val_loss: 1.6343e-04 - val_mae: 0.0098\n",
      "Epoch 23/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 6.2615e-05 - mae: 0.0063\n",
      "Epoch 23: val_loss improved from 0.00016 to 0.00013, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 171us/sample - loss: 6.1876e-05 - mae: 0.0062 - val_loss: 1.3215e-04 - val_mae: 0.0091\n",
      "Epoch 24/1000\n",
      "670/800 [========================>.....] - ETA: 0s - loss: 5.6206e-05 - mae: 0.0059\n",
      "Epoch 24: val_loss did not improve from 0.00013\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 5.8836e-05 - mae: 0.0060 - val_loss: 1.3963e-04 - val_mae: 0.0091\n",
      "Epoch 25/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 5.3891e-05 - mae: 0.0059\n",
      "Epoch 25: val_loss improved from 0.00013 to 0.00012, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 198us/sample - loss: 5.2335e-05 - mae: 0.0058 - val_loss: 1.1852e-04 - val_mae: 0.0085\n",
      "Epoch 26/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770/800 [===========================>..] - ETA: 0s - loss: 4.9940e-05 - mae: 0.0056\n",
      "Epoch 26: val_loss improved from 0.00012 to 0.00011, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 5.0171e-05 - mae: 0.0056 - val_loss: 1.0919e-04 - val_mae: 0.0082\n",
      "Epoch 27/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 4.5392e-05 - mae: 0.0054\n",
      "Epoch 27: val_loss did not improve from 0.00011\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 4.5650e-05 - mae: 0.0054 - val_loss: 1.3207e-04 - val_mae: 0.0088\n",
      "Epoch 28/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 4.2266e-05 - mae: 0.0052\n",
      "Epoch 28: val_loss improved from 0.00011 to 0.00010, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 173us/sample - loss: 4.2313e-05 - mae: 0.0051 - val_loss: 1.0007e-04 - val_mae: 0.0082\n",
      "Epoch 29/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 4.3241e-05 - mae: 0.0052\n",
      "Epoch 29: val_loss improved from 0.00010 to 0.00009, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 184us/sample - loss: 4.3095e-05 - mae: 0.0052 - val_loss: 9.0109e-05 - val_mae: 0.0074\n",
      "Epoch 30/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 3.9840e-05 - mae: 0.0050\n",
      "Epoch 30: val_loss did not improve from 0.00009\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 4.0125e-05 - mae: 0.0050 - val_loss: 9.7898e-05 - val_mae: 0.0077\n",
      "Epoch 31/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 3.3316e-05 - mae: 0.0047\n",
      "Epoch 31: val_loss improved from 0.00009 to 0.00009, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 175us/sample - loss: 3.6468e-05 - mae: 0.0048 - val_loss: 8.6120e-05 - val_mae: 0.0076\n",
      "Epoch 32/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 3.5355e-05 - mae: 0.0048\n",
      "Epoch 32: val_loss improved from 0.00009 to 0.00008, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 207us/sample - loss: 3.5435e-05 - mae: 0.0047 - val_loss: 7.5980e-05 - val_mae: 0.0069\n",
      "Epoch 33/1000\n",
      "680/800 [========================>.....] - ETA: 0s - loss: 3.3467e-05 - mae: 0.0047\n",
      "Epoch 33: val_loss improved from 0.00008 to 0.00007, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 199us/sample - loss: 3.2552e-05 - mae: 0.0046 - val_loss: 7.2870e-05 - val_mae: 0.0069\n",
      "Epoch 34/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 3.0976e-05 - mae: 0.0045\n",
      "Epoch 34: val_loss improved from 0.00007 to 0.00007, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 206us/sample - loss: 3.0190e-05 - mae: 0.0044 - val_loss: 7.2525e-05 - val_mae: 0.0068\n",
      "Epoch 35/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 3.5198e-05 - mae: 0.0047\n",
      "Epoch 35: val_loss improved from 0.00007 to 0.00007, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 201us/sample - loss: 3.5675e-05 - mae: 0.0047 - val_loss: 6.6107e-05 - val_mae: 0.0065\n",
      "Epoch 36/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 2.7097e-05 - mae: 0.0042\n",
      "Epoch 36: val_loss improved from 0.00007 to 0.00006, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 194us/sample - loss: 2.8572e-05 - mae: 0.0043 - val_loss: 6.3199e-05 - val_mae: 0.0064\n",
      "Epoch 37/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 2.7767e-05 - mae: 0.0043\n",
      "Epoch 37: val_loss did not improve from 0.00006\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 2.8006e-05 - mae: 0.0043 - val_loss: 7.7813e-05 - val_mae: 0.0070\n",
      "Epoch 38/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 2.7666e-05 - mae: 0.0043\n",
      "Epoch 38: val_loss improved from 0.00006 to 0.00006, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 186us/sample - loss: 2.7054e-05 - mae: 0.0042 - val_loss: 5.9187e-05 - val_mae: 0.0062\n",
      "Epoch 39/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 2.6534e-05 - mae: 0.0041\n",
      "Epoch 39: val_loss did not improve from 0.00006\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 2.6459e-05 - mae: 0.0041 - val_loss: 8.2459e-05 - val_mae: 0.0073\n",
      "Epoch 40/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 2.6254e-05 - mae: 0.0041\n",
      "Epoch 40: val_loss improved from 0.00006 to 0.00006, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 185us/sample - loss: 2.6172e-05 - mae: 0.0041 - val_loss: 5.7863e-05 - val_mae: 0.0062\n",
      "Epoch 41/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 2.6856e-05 - mae: 0.0042\n",
      "Epoch 41: val_loss improved from 0.00006 to 0.00006, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 194us/sample - loss: 2.6732e-05 - mae: 0.0042 - val_loss: 5.7209e-05 - val_mae: 0.0061\n",
      "Epoch 42/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 2.6717e-05 - mae: 0.0041\n",
      "Epoch 42: val_loss did not improve from 0.00006\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 2.6675e-05 - mae: 0.0042 - val_loss: 5.7625e-05 - val_mae: 0.0063\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 2.4203e-05 - mae: 0.0040\n",
      "Epoch 43: val_loss did not improve from 0.00006\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 2.4203e-05 - mae: 0.0040 - val_loss: 8.1865e-05 - val_mae: 0.0073\n",
      "Epoch 44/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 2.7132e-05 - mae: 0.0042\n",
      "Epoch 44: val_loss improved from 0.00006 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 2.5172e-05 - mae: 0.0040 - val_loss: 5.4269e-05 - val_mae: 0.0060\n",
      "Epoch 45/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 2.6748e-05 - mae: 0.0042\n",
      "Epoch 45: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 2.6775e-05 - mae: 0.0042 - val_loss: 5.4591e-05 - val_mae: 0.0060\n",
      "Epoch 46/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 2.1102e-05 - mae: 0.0037\n",
      "Epoch 46: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 2.3378e-05 - mae: 0.0039 - val_loss: 6.1962e-05 - val_mae: 0.0065\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 2.3622e-05 - mae: 0.0039\n",
      "Epoch 47: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 179us/sample - loss: 2.3622e-05 - mae: 0.0039 - val_loss: 4.9319e-05 - val_mae: 0.0058\n",
      "Epoch 48/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 2.1972e-05 - mae: 0.0038\n",
      "Epoch 48: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 2.3557e-05 - mae: 0.0039 - val_loss: 6.0881e-05 - val_mae: 0.0063\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 2.3318e-05 - mae: 0.0039\n",
      "Epoch 49: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 187us/sample - loss: 2.3318e-05 - mae: 0.0039 - val_loss: 4.8127e-05 - val_mae: 0.0058\n",
      "Epoch 50/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 2.1536e-05 - mae: 0.0038\n",
      "Epoch 50: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 192us/sample - loss: 2.1434e-05 - mae: 0.0037 - val_loss: 4.7347e-05 - val_mae: 0.0057\n",
      "Epoch 51/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 2.2208e-05 - mae: 0.0037\n",
      "Epoch 51: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 164us/sample - loss: 2.5105e-05 - mae: 0.0040 - val_loss: 1.0679e-04 - val_mae: 0.0087\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740/800 [==========================>...] - ETA: 0s - loss: 2.8109e-05 - mae: 0.0042\n",
      "Epoch 52: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 2.7665e-05 - mae: 0.0042 - val_loss: 4.9762e-05 - val_mae: 0.0059\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 2.1812e-05 - mae: 0.0038\n",
      "Epoch 53: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 2.1812e-05 - mae: 0.0038 - val_loss: 4.5872e-05 - val_mae: 0.0057\n",
      "Epoch 54/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.9930e-05 - mae: 0.0036\n",
      "Epoch 54: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 2.0190e-05 - mae: 0.0036 - val_loss: 6.3020e-05 - val_mae: 0.0065\n",
      "Epoch 55/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 2.4605e-05 - mae: 0.0040\n",
      "Epoch 55: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 2.2804e-05 - mae: 0.0038 - val_loss: 4.5646e-05 - val_mae: 0.0056\n",
      "Epoch 56/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 2.1766e-05 - mae: 0.0038\n",
      "Epoch 56: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 2.1447e-05 - mae: 0.0038 - val_loss: 4.7160e-05 - val_mae: 0.0057\n",
      "Epoch 57/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 2.2300e-05 - mae: 0.0038\n",
      "Epoch 57: val_loss improved from 0.00005 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 189us/sample - loss: 2.1791e-05 - mae: 0.0037 - val_loss: 4.4832e-05 - val_mae: 0.0055\n",
      "Epoch 58/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 2.0592e-05 - mae: 0.0037\n",
      "Epoch 58: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 2.0532e-05 - mae: 0.0037 - val_loss: 4.9889e-05 - val_mae: 0.0058\n",
      "Epoch 59/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 2.2462e-05 - mae: 0.0038\n",
      "Epoch 59: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 2.3292e-05 - mae: 0.0039 - val_loss: 6.1440e-05 - val_mae: 0.0064\n",
      "Epoch 60/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 2.1016e-05 - mae: 0.0037\n",
      "Epoch 60: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 2.1106e-05 - mae: 0.0037 - val_loss: 4.8983e-05 - val_mae: 0.0057\n",
      "Epoch 61/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 2.0931e-05 - mae: 0.0036\n",
      "Epoch 61: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 2.1671e-05 - mae: 0.0037 - val_loss: 5.0600e-05 - val_mae: 0.0058\n",
      "Epoch 62/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 2.0941e-05 - mae: 0.0037\n",
      "Epoch 62: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 2.0847e-05 - mae: 0.0037 - val_loss: 4.5630e-05 - val_mae: 0.0056\n",
      "Epoch 63/1000\n",
      "660/800 [=======================>......] - ETA: 0s - loss: 1.8687e-05 - mae: 0.0035\n",
      "Epoch 63: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 216us/sample - loss: 1.9245e-05 - mae: 0.0035 - val_loss: 4.3582e-05 - val_mae: 0.0055\n",
      "Epoch 64/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.8906e-05 - mae: 0.0035\n",
      "Epoch 64: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 171us/sample - loss: 1.9527e-05 - mae: 0.0036 - val_loss: 4.4145e-05 - val_mae: 0.0055\n",
      "Epoch 65/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.8344e-05 - mae: 0.0035\n",
      "Epoch 65: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 1.8501e-05 - mae: 0.0035 - val_loss: 4.9565e-05 - val_mae: 0.0058\n",
      "Epoch 66/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 2.0020e-05 - mae: 0.0036\n",
      "Epoch 66: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 2.0581e-05 - mae: 0.0036 - val_loss: 4.3750e-05 - val_mae: 0.0055\n",
      "Epoch 67/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 2.0149e-05 - mae: 0.0036\n",
      "Epoch 67: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 2.0112e-05 - mae: 0.0036 - val_loss: 4.3855e-05 - val_mae: 0.0055\n",
      "Epoch 68/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8272e-05 - mae: 0.0034\n",
      "Epoch 68: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 2.1463e-05 - mae: 0.0037 - val_loss: 4.5662e-05 - val_mae: 0.0056\n",
      "Epoch 69/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.8055e-05 - mae: 0.0034\n",
      "Epoch 69: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.8361e-05 - mae: 0.0034 - val_loss: 5.1409e-05 - val_mae: 0.0059\n",
      "Epoch 70/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 2.3287e-05 - mae: 0.0039\n",
      "Epoch 70: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 2.3528e-05 - mae: 0.0039 - val_loss: 4.3296e-05 - val_mae: 0.0054\n",
      "Epoch 71/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.8217e-05 - mae: 0.0035\n",
      "Epoch 71: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 1.8777e-05 - mae: 0.0035 - val_loss: 5.0383e-05 - val_mae: 0.0058\n",
      "Epoch 72/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.9422e-05 - mae: 0.0036\n",
      "Epoch 72: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 1.8885e-05 - mae: 0.0035 - val_loss: 4.2827e-05 - val_mae: 0.0054\n",
      "Epoch 73/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.9260e-05 - mae: 0.0035\n",
      "Epoch 73: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.9249e-05 - mae: 0.0035 - val_loss: 5.8070e-05 - val_mae: 0.0062\n",
      "Epoch 74/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7204e-05 - mae: 0.0034\n",
      "Epoch 74: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 2.0883e-05 - mae: 0.0037 - val_loss: 4.3592e-05 - val_mae: 0.0054\n",
      "Epoch 75/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.9650e-05 - mae: 0.0036\n",
      "Epoch 75: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 2.1544e-05 - mae: 0.0038 - val_loss: 4.3522e-05 - val_mae: 0.0054\n",
      "Epoch 76/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.8917e-05 - mae: 0.0035\n",
      "Epoch 76: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.9453e-05 - mae: 0.0036 - val_loss: 4.7347e-05 - val_mae: 0.0057\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.8259e-05 - mae: 0.0034\n",
      "Epoch 77: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.8259e-05 - mae: 0.0034 - val_loss: 4.9150e-05 - val_mae: 0.0057\n",
      "Epoch 78/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 2.0386e-05 - mae: 0.0036\n",
      "Epoch 78: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 2.0472e-05 - mae: 0.0036 - val_loss: 4.5137e-05 - val_mae: 0.0055\n",
      "Epoch 79/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.9544e-05 - mae: 0.0036\n",
      "Epoch 79: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 174us/sample - loss: 1.9847e-05 - mae: 0.0036 - val_loss: 5.2194e-05 - val_mae: 0.0059\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/800 [=========================>....] - ETA: 0s - loss: 1.8375e-05 - mae: 0.0035\n",
      "Epoch 80: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 1.8512e-05 - mae: 0.0035 - val_loss: 4.3714e-05 - val_mae: 0.0054\n",
      "Epoch 81/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 2.1135e-05 - mae: 0.0037\n",
      "Epoch 81: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 2.0392e-05 - mae: 0.0036 - val_loss: 4.4357e-05 - val_mae: 0.0055\n",
      "Epoch 82/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.8602e-05 - mae: 0.0035\n",
      "Epoch 82: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 1.8666e-05 - mae: 0.0035 - val_loss: 4.3300e-05 - val_mae: 0.0054\n",
      "Epoch 83/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.7619e-05 - mae: 0.0034\n",
      "Epoch 83: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.7813e-05 - mae: 0.0034 - val_loss: 4.3723e-05 - val_mae: 0.0054\n",
      "Epoch 84/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6567e-05 - mae: 0.0032\n",
      "Epoch 84: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.8420e-05 - mae: 0.0034 - val_loss: 5.2498e-05 - val_mae: 0.0059\n",
      "Epoch 85/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 2.2177e-05 - mae: 0.0038\n",
      "Epoch 85: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 2.2543e-05 - mae: 0.0038 - val_loss: 4.7267e-05 - val_mae: 0.0056\n",
      "Epoch 86/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7655e-05 - mae: 0.0034\n",
      "Epoch 86: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.8545e-05 - mae: 0.0035 - val_loss: 4.4720e-05 - val_mae: 0.0055\n",
      "Epoch 87/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7623e-05 - mae: 0.0034\n",
      "Epoch 87: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 164us/sample - loss: 1.8023e-05 - mae: 0.0035 - val_loss: 4.2699e-05 - val_mae: 0.0053\n",
      "Epoch 88/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 2.1094e-05 - mae: 0.0036\n",
      "Epoch 88: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 171us/sample - loss: 2.0943e-05 - mae: 0.0036 - val_loss: 4.2720e-05 - val_mae: 0.0053\n",
      "Epoch 89/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 1.8637e-05 - mae: 0.0035\n",
      "Epoch 89: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 173us/sample - loss: 1.8597e-05 - mae: 0.0035 - val_loss: 4.2900e-05 - val_mae: 0.0054\n",
      "Epoch 90/1000\n",
      "660/800 [=======================>......] - ETA: 0s - loss: 1.9559e-05 - mae: 0.0036\n",
      "Epoch 90: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 182us/sample - loss: 1.9944e-05 - mae: 0.0036 - val_loss: 4.3521e-05 - val_mae: 0.0054\n",
      "Epoch 91/1000\n",
      "680/800 [========================>.....] - ETA: 0s - loss: 1.8670e-05 - mae: 0.0035\n",
      "Epoch 91: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 174us/sample - loss: 1.8712e-05 - mae: 0.0035 - val_loss: 4.5190e-05 - val_mae: 0.0055\n",
      "Epoch 92/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.8515e-05 - mae: 0.0035\n",
      "Epoch 92: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 1.8471e-05 - mae: 0.0035 - val_loss: 4.3368e-05 - val_mae: 0.0054\n",
      "Epoch 93/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.7538e-05 - mae: 0.0034\n",
      "Epoch 93: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 1.8055e-05 - mae: 0.0034 - val_loss: 5.3161e-05 - val_mae: 0.0060\n",
      "Epoch 94/1000\n",
      "670/800 [========================>.....] - ETA: 0s - loss: 1.8794e-05 - mae: 0.0034\n",
      "Epoch 94: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 177us/sample - loss: 1.9390e-05 - mae: 0.0035 - val_loss: 4.5119e-05 - val_mae: 0.0055\n",
      "Epoch 95/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 2.2238e-05 - mae: 0.0038\n",
      "Epoch 95: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 2.2371e-05 - mae: 0.0038 - val_loss: 4.4424e-05 - val_mae: 0.0054\n",
      "Epoch 96/1000\n",
      "680/800 [========================>.....] - ETA: 0s - loss: 2.0702e-05 - mae: 0.0037\n",
      "Epoch 96: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 2.0198e-05 - mae: 0.0036 - val_loss: 4.7706e-05 - val_mae: 0.0057\n",
      "Epoch 97/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.8491e-05 - mae: 0.0035\n",
      "Epoch 97: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 173us/sample - loss: 1.8772e-05 - mae: 0.0035 - val_loss: 6.1428e-05 - val_mae: 0.0065\n",
      "Epoch 98/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 2.2110e-05 - mae: 0.0038\n",
      "Epoch 98: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 2.2486e-05 - mae: 0.0038 - val_loss: 4.4048e-05 - val_mae: 0.0054\n",
      "Epoch 99/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 2.2931e-05 - mae: 0.0039\n",
      "Epoch 99: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 2.1721e-05 - mae: 0.0038 - val_loss: 4.4207e-05 - val_mae: 0.0054\n",
      "Epoch 100/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.7009e-05 - mae: 0.0032\n",
      "Epoch 100: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.8453e-05 - mae: 0.0034 - val_loss: 4.7097e-05 - val_mae: 0.0056\n",
      "Epoch 101/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.9384e-05 - mae: 0.0035\n",
      "Epoch 101: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.9345e-05 - mae: 0.0035 - val_loss: 4.3226e-05 - val_mae: 0.0053\n",
      "Epoch 102/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 2.1352e-05 - mae: 0.0037\n",
      "Epoch 102: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.9369e-05 - mae: 0.0035 - val_loss: 4.4894e-05 - val_mae: 0.0054\n",
      "Epoch 103/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6369e-05 - mae: 0.0033\n",
      "Epoch 103: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.7696e-05 - mae: 0.0034 - val_loss: 4.8966e-05 - val_mae: 0.0057\n",
      "Epoch 104/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9563e-05 - mae: 0.0035\n",
      "Epoch 104: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 2.0747e-05 - mae: 0.0037 - val_loss: 4.3279e-05 - val_mae: 0.0054\n",
      "Epoch 105/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8051e-05 - mae: 0.0034\n",
      "Epoch 105: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.8460e-05 - mae: 0.0035 - val_loss: 4.3853e-05 - val_mae: 0.0054\n",
      "Epoch 106/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.8421e-05 - mae: 0.0034\n",
      "Epoch 106: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 1.8209e-05 - mae: 0.0034 - val_loss: 4.5008e-05 - val_mae: 0.0055\n",
      "Epoch 107/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7289e-05 - mae: 0.0033\n",
      "Epoch 107: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.7686e-05 - mae: 0.0034 - val_loss: 4.6294e-05 - val_mae: 0.0055\n",
      "Epoch 108/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 2.0400e-05 - mae: 0.0036\n",
      "Epoch 108: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 2.0159e-05 - mae: 0.0036 - val_loss: 4.4198e-05 - val_mae: 0.0054\n",
      "Epoch 109/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770/800 [===========================>..] - ETA: 0s - loss: 2.3606e-05 - mae: 0.0039\n",
      "Epoch 109: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 2.3660e-05 - mae: 0.0039 - val_loss: 5.4496e-05 - val_mae: 0.0060\n",
      "Epoch 110/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.8244e-05 - mae: 0.0034\n",
      "Epoch 110: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.8135e-05 - mae: 0.0034 - val_loss: 4.6812e-05 - val_mae: 0.0056\n",
      "Epoch 111/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.9951e-05 - mae: 0.0036\n",
      "Epoch 111: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.9484e-05 - mae: 0.0035 - val_loss: 4.9233e-05 - val_mae: 0.0057\n",
      "Epoch 112/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 2.4398e-05 - mae: 0.0040\n",
      "Epoch 112: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 2.4170e-05 - mae: 0.0040 - val_loss: 4.4552e-05 - val_mae: 0.0054\n",
      "Epoch 113/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.8649e-05 - mae: 0.0035\n",
      "Epoch 113: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 2.0714e-05 - mae: 0.0037 - val_loss: 4.6769e-05 - val_mae: 0.0056\n",
      "Epoch 114/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7018e-05 - mae: 0.0034\n",
      "Epoch 114: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.8235e-05 - mae: 0.0035 - val_loss: 4.4767e-05 - val_mae: 0.0055\n",
      "Epoch 115/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6411e-05 - mae: 0.0032\n",
      "Epoch 115: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.8193e-05 - mae: 0.0034 - val_loss: 4.3918e-05 - val_mae: 0.0054\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.8616e-05 - mae: 0.0035\n",
      "Epoch 116: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.8616e-05 - mae: 0.0035 - val_loss: 4.3969e-05 - val_mae: 0.0054\n",
      "Epoch 117/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.7437e-05 - mae: 0.0033\n",
      "Epoch 117: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.7474e-05 - mae: 0.0034 - val_loss: 4.7526e-05 - val_mae: 0.0056\n",
      "Epoch 118/1000\n",
      "380/800 [=============>................] - ETA: 0s - loss: 1.6418e-05 - mae: 0.0033\n",
      "Epoch 118: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 2.0114e-05 - mae: 0.0036 - val_loss: 4.3679e-05 - val_mae: 0.0054\n",
      "Epoch 119/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7529e-05 - mae: 0.0034\n",
      "Epoch 119: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.9815e-05 - mae: 0.0036 - val_loss: 4.5466e-05 - val_mae: 0.0055\n",
      "Epoch 120/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6003e-05 - mae: 0.0032\n",
      "Epoch 120: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7239e-05 - mae: 0.0033 - val_loss: 4.4880e-05 - val_mae: 0.0055\n",
      "Epoch 121/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.8376e-05 - mae: 0.0035\n",
      "Epoch 121: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.8297e-05 - mae: 0.0035 - val_loss: 4.4925e-05 - val_mae: 0.0055\n",
      "Epoch 122/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9379e-05 - mae: 0.0036\n",
      "Epoch 122: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.7948e-05 - mae: 0.0034 - val_loss: 4.4313e-05 - val_mae: 0.0054\n",
      "Epoch 123/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.7978e-05 - mae: 0.0034\n",
      "Epoch 123: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.8126e-05 - mae: 0.0034 - val_loss: 4.3562e-05 - val_mae: 0.0054\n",
      "Epoch 124/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 2.2094e-05 - mae: 0.0038\n",
      "Epoch 124: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 2.2010e-05 - mae: 0.0038 - val_loss: 4.3868e-05 - val_mae: 0.0054\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 2.0861e-05 - mae: 0.0036\n",
      "Epoch 125: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 2.0861e-05 - mae: 0.0036 - val_loss: 5.1031e-05 - val_mae: 0.0058\n",
      "Epoch 126/1000\n",
      "670/800 [========================>.....] - ETA: 0s - loss: 2.0972e-05 - mae: 0.0037\n",
      "Epoch 126: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 182us/sample - loss: 2.0226e-05 - mae: 0.0036 - val_loss: 4.7659e-05 - val_mae: 0.0056\n",
      "Epoch 127/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.7625e-05 - mae: 0.0034\n",
      "Epoch 127: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.7884e-05 - mae: 0.0034 - val_loss: 4.8418e-05 - val_mae: 0.0057\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.9932e-05 - mae: 0.0036\n",
      "Epoch 128: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.9932e-05 - mae: 0.0036 - val_loss: 6.5022e-05 - val_mae: 0.0066\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 2.0218e-05 - mae: 0.0036\n",
      "Epoch 129: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 2.0218e-05 - mae: 0.0036 - val_loss: 5.3032e-05 - val_mae: 0.0060\n",
      "Epoch 130/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 2.1905e-05 - mae: 0.0037\n",
      "Epoch 130: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.9002e-05 - mae: 0.0035 - val_loss: 4.3290e-05 - val_mae: 0.0053\n",
      "Epoch 131/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7879e-05 - mae: 0.0034\n",
      "Epoch 131: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.8339e-05 - mae: 0.0034 - val_loss: 4.6460e-05 - val_mae: 0.0056\n",
      "Epoch 132/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 2.5840e-05 - mae: 0.0041\n",
      "Epoch 132: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 2.6982e-05 - mae: 0.0042 - val_loss: 4.3732e-05 - val_mae: 0.0054\n",
      "Epoch 133/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 2.0161e-05 - mae: 0.0036\n",
      "Epoch 133: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 2.0538e-05 - mae: 0.0037 - val_loss: 5.1909e-05 - val_mae: 0.0059\n",
      "Epoch 134/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.9415e-05 - mae: 0.0036\n",
      "Epoch 134: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 1.9127e-05 - mae: 0.0035 - val_loss: 4.9062e-05 - val_mae: 0.0057\n",
      "Epoch 135/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.8543e-05 - mae: 0.0035\n",
      "Epoch 135: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.8746e-05 - mae: 0.0035 - val_loss: 4.3437e-05 - val_mae: 0.0053\n",
      "Epoch 136/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7523e-05 - mae: 0.0033\n",
      "Epoch 136: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.9623e-05 - mae: 0.0035 - val_loss: 4.4066e-05 - val_mae: 0.0054\n",
      "Epoch 137/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 2.3421e-05 - mae: 0.0039\n",
      "Epoch 137: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 2.4924e-05 - mae: 0.0040 - val_loss: 4.3910e-05 - val_mae: 0.0054\n",
      "Epoch 138/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9223e-05 - mae: 0.0035\n",
      "Epoch 138: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.9482e-05 - mae: 0.0036 - val_loss: 4.7384e-05 - val_mae: 0.0056\n",
      "Epoch 139/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.8081e-05 - mae: 0.0034\n",
      "Epoch 139: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.7531e-05 - mae: 0.0033 - val_loss: 4.4576e-05 - val_mae: 0.0054\n",
      "Epoch 140/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5965e-05 - mae: 0.0032\n",
      "Epoch 140: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 2.0270e-05 - mae: 0.0036 - val_loss: 4.3757e-05 - val_mae: 0.0054\n",
      "Epoch 141/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.8025e-05 - mae: 0.0034\n",
      "Epoch 141: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8641e-05 - mae: 0.0035 - val_loss: 4.9196e-05 - val_mae: 0.0057\n",
      "Epoch 142/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7873e-05 - mae: 0.0034\n",
      "Epoch 142: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.7816e-05 - mae: 0.0034 - val_loss: 4.6545e-05 - val_mae: 0.0055\n",
      "Epoch 143/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.8329e-05 - mae: 0.0034\n",
      "Epoch 143: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.7965e-05 - mae: 0.0034 - val_loss: 4.6104e-05 - val_mae: 0.0055\n",
      "Epoch 144/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.8211e-05 - mae: 0.0034\n",
      "Epoch 144: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.7939e-05 - mae: 0.0034 - val_loss: 6.0842e-05 - val_mae: 0.0064\n",
      "Epoch 145/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.9663e-05 - mae: 0.0036\n",
      "Epoch 145: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.9611e-05 - mae: 0.0036 - val_loss: 4.3201e-05 - val_mae: 0.0053\n",
      "Epoch 146/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.9470e-05 - mae: 0.0036\n",
      "Epoch 146: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.9510e-05 - mae: 0.0036 - val_loss: 4.4888e-05 - val_mae: 0.0055\n",
      "Epoch 147/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 2.3701e-05 - mae: 0.0039\n",
      "Epoch 147: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 2.3044e-05 - mae: 0.0038 - val_loss: 4.7097e-05 - val_mae: 0.0056\n",
      "Epoch 148/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9847e-05 - mae: 0.0036\n",
      "Epoch 148: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 2.0082e-05 - mae: 0.0036 - val_loss: 5.2234e-05 - val_mae: 0.0059\n",
      "Epoch 149/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 2.0649e-05 - mae: 0.0037\n",
      "Epoch 149: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.8712e-05 - mae: 0.0035 - val_loss: 6.0124e-05 - val_mae: 0.0063\n",
      "Epoch 150/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.9762e-05 - mae: 0.0036\n",
      "Epoch 150: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.8662e-05 - mae: 0.0035 - val_loss: 4.5877e-05 - val_mae: 0.0055\n",
      "Epoch 151/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 2.0431e-05 - mae: 0.0037\n",
      "Epoch 151: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.8870e-05 - mae: 0.0035 - val_loss: 4.4362e-05 - val_mae: 0.0054\n",
      "Epoch 152/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8233e-05 - mae: 0.0035\n",
      "Epoch 152: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 2.2200e-05 - mae: 0.0038 - val_loss: 5.6870e-05 - val_mae: 0.0061\n",
      "Epoch 153/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7097e-05 - mae: 0.0033\n",
      "Epoch 153: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7912e-05 - mae: 0.0034 - val_loss: 5.0265e-05 - val_mae: 0.0058\n",
      "Epoch 154/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6636e-05 - mae: 0.0033\n",
      "Epoch 154: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.8082e-05 - mae: 0.0034 - val_loss: 4.4153e-05 - val_mae: 0.0054\n",
      "Epoch 155/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7010e-05 - mae: 0.0033\n",
      "Epoch 155: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8936e-05 - mae: 0.0035 - val_loss: 4.6935e-05 - val_mae: 0.0056\n",
      "Epoch 156/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8201e-05 - mae: 0.0034\n",
      "Epoch 156: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.9548e-05 - mae: 0.0036 - val_loss: 4.4434e-05 - val_mae: 0.0054\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.9854e-05 - mae: 0.0036\n",
      "Epoch 157: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.9854e-05 - mae: 0.0036 - val_loss: 4.4691e-05 - val_mae: 0.0054\n",
      "Epoch 158/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4429e-05 - mae: 0.0030\n",
      "Epoch 158: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.9984e-05 - mae: 0.0035 - val_loss: 4.5917e-05 - val_mae: 0.0055\n",
      "Epoch 159/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.7375e-05 - mae: 0.0034\n",
      "Epoch 159: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.7486e-05 - mae: 0.0034 - val_loss: 4.7345e-05 - val_mae: 0.0056\n",
      "Epoch 160/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.8457e-05 - mae: 0.0034\n",
      "Epoch 160: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.8673e-05 - mae: 0.0035 - val_loss: 4.8312e-05 - val_mae: 0.0056\n",
      "Epoch 161/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 2.0853e-05 - mae: 0.0037\n",
      "Epoch 161: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 2.1202e-05 - mae: 0.0037 - val_loss: 4.4199e-05 - val_mae: 0.0054\n",
      "Epoch 162/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 2.0028e-05 - mae: 0.0036\n",
      "Epoch 162: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.8655e-05 - mae: 0.0035 - val_loss: 4.6874e-05 - val_mae: 0.0056\n",
      "Epoch 163/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.9246e-05 - mae: 0.0035\n",
      "Epoch 163: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.8976e-05 - mae: 0.0035 - val_loss: 4.6835e-05 - val_mae: 0.0056\n",
      "Epoch 164/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4965e-05 - mae: 0.0031\n",
      "Epoch 164: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.7390e-05 - mae: 0.0033 - val_loss: 4.3290e-05 - val_mae: 0.0053\n",
      "Epoch 165/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6452e-05 - mae: 0.0033\n",
      "Epoch 165: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 2.0765e-05 - mae: 0.0037 - val_loss: 6.9131e-05 - val_mae: 0.0068\n",
      "Epoch 166/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8298e-05 - mae: 0.0034\n",
      "Epoch 166: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.8310e-05 - mae: 0.0034 - val_loss: 4.4245e-05 - val_mae: 0.0054\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/800 [=================>............] - ETA: 0s - loss: 1.7090e-05 - mae: 0.0033\n",
      "Epoch 167: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.9410e-05 - mae: 0.0035 - val_loss: 6.5978e-05 - val_mae: 0.0066\n",
      "Epoch 168/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.8651e-05 - mae: 0.0034\n",
      "Epoch 168: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.9778e-05 - mae: 0.0035 - val_loss: 5.4216e-05 - val_mae: 0.0060\n",
      "Epoch 169/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 2.0280e-05 - mae: 0.0036\n",
      "Epoch 169: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.9308e-05 - mae: 0.0035 - val_loss: 4.4248e-05 - val_mae: 0.0054\n",
      "Epoch 170/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.8097e-05 - mae: 0.0034\n",
      "Epoch 170: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7976e-05 - mae: 0.0034 - val_loss: 4.4049e-05 - val_mae: 0.0054\n",
      "Epoch 171/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7321e-05 - mae: 0.0034\n",
      "Epoch 171: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7849e-05 - mae: 0.0034 - val_loss: 4.3561e-05 - val_mae: 0.0054\n",
      "Epoch 172/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6594e-05 - mae: 0.0033\n",
      "Epoch 172: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7701e-05 - mae: 0.0034 - val_loss: 4.3793e-05 - val_mae: 0.0054\n",
      "Epoch 173/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6177e-05 - mae: 0.0032\n",
      "Epoch 173: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7400e-05 - mae: 0.0033 - val_loss: 4.4316e-05 - val_mae: 0.0054\n",
      "Epoch 174/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6278e-05 - mae: 0.0032\n",
      "Epoch 174: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.8625e-05 - mae: 0.0034 - val_loss: 4.3751e-05 - val_mae: 0.0054\n",
      "Epoch 175/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.9563e-05 - mae: 0.0035\n",
      "Epoch 175: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 1.7938e-05 - mae: 0.0034 - val_loss: 4.4902e-05 - val_mae: 0.0055\n",
      "Epoch 176/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.9138e-05 - mae: 0.0035\n",
      "Epoch 176: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 1.9068e-05 - mae: 0.0035 - val_loss: 4.5748e-05 - val_mae: 0.0055\n",
      "Epoch 177/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9178e-05 - mae: 0.0035\n",
      "Epoch 177: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.8475e-05 - mae: 0.0034 - val_loss: 4.5836e-05 - val_mae: 0.0055\n",
      "Epoch 178/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7575e-05 - mae: 0.0033\n",
      "Epoch 178: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.8915e-05 - mae: 0.0035 - val_loss: 4.6368e-05 - val_mae: 0.0056\n",
      "Epoch 179/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.5667e-05 - mae: 0.0032\n",
      "Epoch 179: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.7172e-05 - mae: 0.0033 - val_loss: 5.9590e-05 - val_mae: 0.0063\n",
      "Epoch 180/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.5880e-05 - mae: 0.0032\n",
      "Epoch 180: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.7706e-05 - mae: 0.0034 - val_loss: 4.4714e-05 - val_mae: 0.0054\n",
      "Epoch 181/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.5986e-05 - mae: 0.0032\n",
      "Epoch 181: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7095e-05 - mae: 0.0033 - val_loss: 4.9456e-05 - val_mae: 0.0057\n",
      "Epoch 182/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 2.0077e-05 - mae: 0.0036\n",
      "Epoch 182: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 1.9603e-05 - mae: 0.0036 - val_loss: 5.9615e-05 - val_mae: 0.0063\n",
      "Epoch 183/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.7770e-05 - mae: 0.0034\n",
      "Epoch 183: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.7639e-05 - mae: 0.0034 - val_loss: 4.7192e-05 - val_mae: 0.0056\n",
      "Epoch 184/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.1809e-05 - mae: 0.0037\n",
      "Epoch 184: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 2.0555e-05 - mae: 0.0036 - val_loss: 4.9214e-05 - val_mae: 0.0057\n",
      "Epoch 185/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7701e-05 - mae: 0.0034\n",
      "Epoch 185: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.7155e-05 - mae: 0.0033 - val_loss: 4.5121e-05 - val_mae: 0.0054\n",
      "Epoch 186/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.9140e-05 - mae: 0.0035\n",
      "Epoch 186: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.8447e-05 - mae: 0.0034 - val_loss: 4.4396e-05 - val_mae: 0.0054\n",
      "Epoch 187/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.7908e-05 - mae: 0.0034\n",
      "Epoch 187: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.8217e-05 - mae: 0.0034 - val_loss: 4.4648e-05 - val_mae: 0.0054\n",
      "Epoch 188/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 2.3800e-05 - mae: 0.0039\n",
      "Epoch 188: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 2.2999e-05 - mae: 0.0038 - val_loss: 4.3434e-05 - val_mae: 0.0054\n",
      "Epoch 189/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.8237e-05 - mae: 0.0034\n",
      "Epoch 189: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 1.8044e-05 - mae: 0.0034 - val_loss: 4.5607e-05 - val_mae: 0.0055\n",
      "Epoch 190/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.8971e-05 - mae: 0.0035\n",
      "Epoch 190: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.9597e-05 - mae: 0.0035 - val_loss: 4.3930e-05 - val_mae: 0.0054\n",
      "Epoch 191/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6242e-05 - mae: 0.0032\n",
      "Epoch 191: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.7862e-05 - mae: 0.0034 - val_loss: 4.3977e-05 - val_mae: 0.0054\n",
      "Epoch 192/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.8909e-05 - mae: 0.0036\n",
      "Epoch 192: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 1.8747e-05 - mae: 0.0035 - val_loss: 4.5855e-05 - val_mae: 0.0055\n",
      "Epoch 193/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8848e-05 - mae: 0.0034\n",
      "Epoch 193: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.9637e-05 - mae: 0.0035 - val_loss: 5.0922e-05 - val_mae: 0.0058\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 2.1624e-05 - mae: 0.0037\n",
      "Epoch 194: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 2.1624e-05 - mae: 0.0037 - val_loss: 4.7932e-05 - val_mae: 0.0056\n",
      "Epoch 195/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.6541e-05 - mae: 0.0032\n",
      "Epoch 195: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.6592e-05 - mae: 0.0032 - val_loss: 4.8151e-05 - val_mae: 0.0056\n",
      "Epoch 196/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/800 [===============>..............] - ETA: 0s - loss: 2.1795e-05 - mae: 0.0038\n",
      "Epoch 196: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.9720e-05 - mae: 0.0036 - val_loss: 4.5424e-05 - val_mae: 0.0055\n",
      "Epoch 197/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5687e-05 - mae: 0.0032\n",
      "Epoch 197: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6732e-05 - mae: 0.0033 - val_loss: 4.5241e-05 - val_mae: 0.0055\n",
      "Epoch 198/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5940e-05 - mae: 0.0032\n",
      "Epoch 198: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.6675e-05 - mae: 0.0033 - val_loss: 4.4742e-05 - val_mae: 0.0054\n",
      "Epoch 199/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 2.0222e-05 - mae: 0.0035\n",
      "Epoch 199: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 2.0254e-05 - mae: 0.0036 - val_loss: 4.3878e-05 - val_mae: 0.0054\n",
      "Epoch 200/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 2.0134e-05 - mae: 0.0036\n",
      "Epoch 200: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 2.0962e-05 - mae: 0.0036 - val_loss: 4.8455e-05 - val_mae: 0.0057\n",
      "Epoch 201/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.5926e-05 - mae: 0.0032\n",
      "Epoch 201: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.6294e-05 - mae: 0.0032 - val_loss: 4.6814e-05 - val_mae: 0.0055\n",
      "Epoch 202/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.6494e-05 - mae: 0.0032\n",
      "Epoch 202: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.6801e-05 - mae: 0.0033 - val_loss: 4.6251e-05 - val_mae: 0.0055\n",
      "Epoch 203/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7131e-05 - mae: 0.0033\n",
      "Epoch 203: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7256e-05 - mae: 0.0033 - val_loss: 4.5343e-05 - val_mae: 0.0055\n",
      "Epoch 204/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6660e-05 - mae: 0.0032\n",
      "Epoch 204: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.8882e-05 - mae: 0.0034 - val_loss: 5.5087e-05 - val_mae: 0.0060\n",
      "Epoch 205/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 2.0882e-05 - mae: 0.0037\n",
      "Epoch 205: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.9439e-05 - mae: 0.0035 - val_loss: 4.3963e-05 - val_mae: 0.0054\n",
      "Epoch 206/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6330e-05 - mae: 0.0032\n",
      "Epoch 206: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6226e-05 - mae: 0.0032 - val_loss: 4.4749e-05 - val_mae: 0.0054\n",
      "Epoch 207/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6997e-05 - mae: 0.0033\n",
      "Epoch 207: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.8657e-05 - mae: 0.0034 - val_loss: 4.9805e-05 - val_mae: 0.0057\n",
      "Epoch 208/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5839e-05 - mae: 0.0032\n",
      "Epoch 208: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.9478e-05 - mae: 0.0035 - val_loss: 4.4640e-05 - val_mae: 0.0054\n",
      "Epoch 209/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.7975e-05 - mae: 0.0034\n",
      "Epoch 209: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.8397e-05 - mae: 0.0035 - val_loss: 4.8729e-05 - val_mae: 0.0057\n",
      "Epoch 210/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7262e-05 - mae: 0.0033\n",
      "Epoch 210: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7798e-05 - mae: 0.0034 - val_loss: 4.6302e-05 - val_mae: 0.0055\n",
      "Epoch 211/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6426e-05 - mae: 0.0032\n",
      "Epoch 211: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.6637e-05 - mae: 0.0033 - val_loss: 4.4667e-05 - val_mae: 0.0054\n",
      "Epoch 212/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6951e-05 - mae: 0.0033\n",
      "Epoch 212: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7258e-05 - mae: 0.0033 - val_loss: 4.6008e-05 - val_mae: 0.0055\n",
      "Epoch 213/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.9949e-05 - mae: 0.0036\n",
      "Epoch 213: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.9354e-05 - mae: 0.0035 - val_loss: 4.4477e-05 - val_mae: 0.0054\n",
      "Epoch 214/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5815e-05 - mae: 0.0032\n",
      "Epoch 214: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7594e-05 - mae: 0.0033 - val_loss: 5.0636e-05 - val_mae: 0.0057\n",
      "Epoch 215/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9165e-05 - mae: 0.0035\n",
      "Epoch 215: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 2.2066e-05 - mae: 0.0037 - val_loss: 4.7058e-05 - val_mae: 0.0055\n",
      "Epoch 216/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4641e-05 - mae: 0.0031\n",
      "Epoch 216: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7105e-05 - mae: 0.0033 - val_loss: 4.4580e-05 - val_mae: 0.0054\n",
      "Epoch 217/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5506e-05 - mae: 0.0032\n",
      "Epoch 217: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7283e-05 - mae: 0.0033 - val_loss: 4.4510e-05 - val_mae: 0.0054\n",
      "Epoch 218/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 2.0875e-05 - mae: 0.0037\n",
      "Epoch 218: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 2.0503e-05 - mae: 0.0036 - val_loss: 5.9276e-05 - val_mae: 0.0064\n",
      "Epoch 219/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6762e-05 - mae: 0.0033\n",
      "Epoch 219: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.9473e-05 - mae: 0.0035 - val_loss: 4.8451e-05 - val_mae: 0.0057\n",
      "Epoch 220/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9705e-05 - mae: 0.0035\n",
      "Epoch 220: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 2.2012e-05 - mae: 0.0037 - val_loss: 4.7170e-05 - val_mae: 0.0056\n",
      "Epoch 221/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 2.2923e-05 - mae: 0.0037\n",
      "Epoch 221: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 2.2624e-05 - mae: 0.0037 - val_loss: 4.6139e-05 - val_mae: 0.0055\n",
      "Epoch 222/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6198e-05 - mae: 0.0032\n",
      "Epoch 222: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7838e-05 - mae: 0.0034 - val_loss: 7.2381e-05 - val_mae: 0.0069\n",
      "Epoch 223/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 2.0404e-05 - mae: 0.0036\n",
      "Epoch 223: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 2.0375e-05 - mae: 0.0036 - val_loss: 4.3830e-05 - val_mae: 0.0054\n",
      "Epoch 224/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5724e-05 - mae: 0.0031\n",
      "Epoch 224: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.8355e-05 - mae: 0.0034 - val_loss: 4.4178e-05 - val_mae: 0.0054\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410/800 [==============>...............] - ETA: 0s - loss: 2.1231e-05 - mae: 0.0037\n",
      "Epoch 225: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.8358e-05 - mae: 0.0034 - val_loss: 4.3973e-05 - val_mae: 0.0054\n",
      "Epoch 226/1000\n",
      "380/800 [=============>................] - ETA: 0s - loss: 1.6621e-05 - mae: 0.0032\n",
      "Epoch 226: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.6942e-05 - mae: 0.0033 - val_loss: 4.4433e-05 - val_mae: 0.0054\n",
      "Epoch 227/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 2.0270e-05 - mae: 0.0036\n",
      "Epoch 227: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.9960e-05 - mae: 0.0036 - val_loss: 4.4501e-05 - val_mae: 0.0054\n",
      "Epoch 228/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.6507e-05 - mae: 0.0032\n",
      "Epoch 228: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 1.6227e-05 - mae: 0.0032 - val_loss: 4.5319e-05 - val_mae: 0.0055\n",
      "Epoch 229/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.6665e-05 - mae: 0.0033\n",
      "Epoch 229: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.6282e-05 - mae: 0.0032 - val_loss: 4.5392e-05 - val_mae: 0.0054\n",
      "Epoch 230/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.9914e-05 - mae: 0.0036\n",
      "Epoch 230: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.9610e-05 - mae: 0.0035 - val_loss: 6.0376e-05 - val_mae: 0.0064\n",
      "Epoch 231/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 2.1370e-05 - mae: 0.0037\n",
      "Epoch 231: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 2.0074e-05 - mae: 0.0036 - val_loss: 4.5171e-05 - val_mae: 0.0054\n",
      "Epoch 232/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.8114e-05 - mae: 0.0034\n",
      "Epoch 232: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.8114e-05 - mae: 0.0034 - val_loss: 4.4071e-05 - val_mae: 0.0054\n",
      "Epoch 233/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.7568e-05 - mae: 0.0033\n",
      "Epoch 233: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.7794e-05 - mae: 0.0034 - val_loss: 4.4619e-05 - val_mae: 0.0054\n",
      "Epoch 234/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.5800e-05 - mae: 0.0032\n",
      "Epoch 234: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.6263e-05 - mae: 0.0032 - val_loss: 4.5783e-05 - val_mae: 0.0055\n",
      "Epoch 235/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.6120e-05 - mae: 0.0032\n",
      "Epoch 235: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.6128e-05 - mae: 0.0032 - val_loss: 4.4154e-05 - val_mae: 0.0054\n",
      "Epoch 236/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 2.0400e-05 - mae: 0.0036\n",
      "Epoch 236: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.8803e-05 - mae: 0.0034 - val_loss: 4.7201e-05 - val_mae: 0.0056\n",
      "Epoch 237/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.6047e-05 - mae: 0.0033\n",
      "Epoch 237: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.8922e-05 - mae: 0.0035 - val_loss: 4.5031e-05 - val_mae: 0.0054\n",
      "Epoch 238/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6214e-05 - mae: 0.0032\n",
      "Epoch 238: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7849e-05 - mae: 0.0034 - val_loss: 4.4738e-05 - val_mae: 0.0054\n",
      "Epoch 239/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6537e-05 - mae: 0.0033\n",
      "Epoch 239: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7484e-05 - mae: 0.0034 - val_loss: 4.4865e-05 - val_mae: 0.0054\n",
      "Epoch 240/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6553e-05 - mae: 0.0033\n",
      "Epoch 240: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.6765e-05 - mae: 0.0033 - val_loss: 4.6211e-05 - val_mae: 0.0055\n",
      "Epoch 241/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7656e-05 - mae: 0.0033\n",
      "Epoch 241: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7868e-05 - mae: 0.0034 - val_loss: 4.4931e-05 - val_mae: 0.0054\n",
      "Epoch 242/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 2.1074e-05 - mae: 0.0036\n",
      "Epoch 242: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 2.1717e-05 - mae: 0.0036 - val_loss: 4.6946e-05 - val_mae: 0.0055\n",
      "Epoch 243/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.9144e-05 - mae: 0.0035\n",
      "Epoch 243: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.8350e-05 - mae: 0.0034 - val_loss: 4.7546e-05 - val_mae: 0.0056\n",
      "Epoch 244/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5596e-05 - mae: 0.0031\n",
      "Epoch 244: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6786e-05 - mae: 0.0032 - val_loss: 4.8950e-05 - val_mae: 0.0056\n",
      "Epoch 245/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9240e-05 - mae: 0.0035\n",
      "Epoch 245: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.8516e-05 - mae: 0.0035 - val_loss: 4.4520e-05 - val_mae: 0.0054\n",
      "Epoch 246/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7559e-05 - mae: 0.0034\n",
      "Epoch 246: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.8161e-05 - mae: 0.0034 - val_loss: 5.7508e-05 - val_mae: 0.0062\n",
      "Epoch 247/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7779e-05 - mae: 0.0034\n",
      "Epoch 247: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.8066e-05 - mae: 0.0034 - val_loss: 4.4606e-05 - val_mae: 0.0054\n",
      "Epoch 248/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.9405e-05 - mae: 0.0035\n",
      "Epoch 248: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.9179e-05 - mae: 0.0035 - val_loss: 4.6344e-05 - val_mae: 0.0055\n",
      "Epoch 249/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 2.2378e-05 - mae: 0.0037\n",
      "Epoch 249: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 2.1047e-05 - mae: 0.0037 - val_loss: 4.8123e-05 - val_mae: 0.0056\n",
      "Epoch 250/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8961e-05 - mae: 0.0035\n",
      "Epoch 250: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.8400e-05 - mae: 0.0035 - val_loss: 4.5492e-05 - val_mae: 0.0054\n",
      "Epoch 251/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5385e-05 - mae: 0.0031\n",
      "Epoch 251: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.5725e-05 - mae: 0.0031 - val_loss: 4.5541e-05 - val_mae: 0.0054\n",
      "Epoch 252/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6644e-05 - mae: 0.0033\n",
      "Epoch 252: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7244e-05 - mae: 0.0033 - val_loss: 4.9087e-05 - val_mae: 0.0057\n",
      "Epoch 253/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7720e-05 - mae: 0.0034\n",
      "Epoch 253: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.7720e-05 - mae: 0.0034 - val_loss: 4.7306e-05 - val_mae: 0.0055\n",
      "Epoch 254/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/800 [===============>..............] - ETA: 0s - loss: 1.4448e-05 - mae: 0.0030\n",
      "Epoch 254: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.5371e-05 - mae: 0.0031 - val_loss: 4.8168e-05 - val_mae: 0.0056\n",
      "Epoch 255/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.8500e-05 - mae: 0.0035\n",
      "Epoch 255: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.8960e-05 - mae: 0.0035 - val_loss: 4.5245e-05 - val_mae: 0.0054\n",
      "Epoch 256/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 1.5245e-05 - mae: 0.0031\n",
      "Epoch 256: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 1.5640e-05 - mae: 0.0031 - val_loss: 4.4775e-05 - val_mae: 0.0054\n",
      "Epoch 257/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.9093e-05 - mae: 0.0035\n",
      "Epoch 257: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.8150e-05 - mae: 0.0034 - val_loss: 5.0279e-05 - val_mae: 0.0058\n",
      "Epoch 258/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7554e-05 - mae: 0.0033\n",
      "Epoch 258: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8237e-05 - mae: 0.0034 - val_loss: 5.2123e-05 - val_mae: 0.0058\n",
      "Epoch 259/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 2.1228e-05 - mae: 0.0037\n",
      "Epoch 259: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.9547e-05 - mae: 0.0035 - val_loss: 5.0720e-05 - val_mae: 0.0057\n",
      "Epoch 260/1000\n",
      "640/800 [=======================>......] - ETA: 0s - loss: 1.9418e-05 - mae: 0.0035\n",
      "Epoch 260: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 1.9307e-05 - mae: 0.0035 - val_loss: 4.7175e-05 - val_mae: 0.0055\n",
      "Epoch 261/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.6297e-05 - mae: 0.0033\n",
      "Epoch 261: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6800e-05 - mae: 0.0033 - val_loss: 4.4882e-05 - val_mae: 0.0054\n",
      "Epoch 262/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8582e-05 - mae: 0.0034\n",
      "Epoch 262: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.7267e-05 - mae: 0.0033 - val_loss: 4.5122e-05 - val_mae: 0.0054\n",
      "Epoch 263/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 2.1707e-05 - mae: 0.0037\n",
      "Epoch 263: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 2.0543e-05 - mae: 0.0036 - val_loss: 4.6085e-05 - val_mae: 0.0055\n",
      "Epoch 264/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5003e-05 - mae: 0.0031\n",
      "Epoch 264: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7852e-05 - mae: 0.0033 - val_loss: 4.6088e-05 - val_mae: 0.0055\n",
      "Epoch 265/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.7552e-05 - mae: 0.0033\n",
      "Epoch 265: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.8046e-05 - mae: 0.0034 - val_loss: 4.7522e-05 - val_mae: 0.0055\n",
      "Epoch 266/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7286e-05 - mae: 0.0033\n",
      "Epoch 266: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.7142e-05 - mae: 0.0033 - val_loss: 4.5021e-05 - val_mae: 0.0054\n",
      "Epoch 267/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.8099e-05 - mae: 0.0034\n",
      "Epoch 267: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.8082e-05 - mae: 0.0034 - val_loss: 4.7367e-05 - val_mae: 0.0055\n",
      "Epoch 268/1000\n",
      "640/800 [=======================>......] - ETA: 0s - loss: 1.6646e-05 - mae: 0.0032\n",
      "Epoch 268: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 182us/sample - loss: 1.9612e-05 - mae: 0.0035 - val_loss: 4.8893e-05 - val_mae: 0.0056\n",
      "Epoch 269/1000\n",
      "670/800 [========================>.....] - ETA: 0s - loss: 1.7531e-05 - mae: 0.0034\n",
      "Epoch 269: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 176us/sample - loss: 1.8174e-05 - mae: 0.0034 - val_loss: 4.7690e-05 - val_mae: 0.0056\n",
      "Epoch 270/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.6756e-05 - mae: 0.0033\n",
      "Epoch 270: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 164us/sample - loss: 1.7123e-05 - mae: 0.0033 - val_loss: 4.7543e-05 - val_mae: 0.0056\n",
      "Epoch 271/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.5904e-05 - mae: 0.0032\n",
      "Epoch 271: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.6525e-05 - mae: 0.0032 - val_loss: 4.7715e-05 - val_mae: 0.0055\n",
      "Epoch 272/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 2.0586e-05 - mae: 0.0036\n",
      "Epoch 272: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.8749e-05 - mae: 0.0035 - val_loss: 4.5456e-05 - val_mae: 0.0054\n",
      "Epoch 273/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.6978e-05 - mae: 0.0033\n",
      "Epoch 273: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.6798e-05 - mae: 0.0033 - val_loss: 4.7035e-05 - val_mae: 0.0055\n",
      "Epoch 274/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.6859e-05 - mae: 0.0033\n",
      "Epoch 274: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.6859e-05 - mae: 0.0033 - val_loss: 4.5643e-05 - val_mae: 0.0054\n",
      "Epoch 275/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6657e-05 - mae: 0.0032\n",
      "Epoch 275: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.7714e-05 - mae: 0.0033 - val_loss: 4.9371e-05 - val_mae: 0.0056\n",
      "Epoch 276/1000\n",
      "680/800 [========================>.....] - ETA: 0s - loss: 1.7427e-05 - mae: 0.0033\n",
      "Epoch 276: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 1.8063e-05 - mae: 0.0034 - val_loss: 4.8456e-05 - val_mae: 0.0056\n",
      "Epoch 277/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.7158e-05 - mae: 0.0033\n",
      "Epoch 277: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 176us/sample - loss: 1.6923e-05 - mae: 0.0033 - val_loss: 4.8328e-05 - val_mae: 0.0056\n",
      "Epoch 278/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 1.6248e-05 - mae: 0.0032\n",
      "Epoch 278: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 176us/sample - loss: 1.6183e-05 - mae: 0.0032 - val_loss: 4.5522e-05 - val_mae: 0.0054\n",
      "Epoch 279/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 1.7630e-05 - mae: 0.0034\n",
      "Epoch 279: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 203us/sample - loss: 1.8652e-05 - mae: 0.0035 - val_loss: 4.8664e-05 - val_mae: 0.0056\n",
      "Epoch 280/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.9156e-05 - mae: 0.0035\n",
      "Epoch 280: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 1.8785e-05 - mae: 0.0034 - val_loss: 4.9880e-05 - val_mae: 0.0057\n",
      "Epoch 281/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.9334e-05 - mae: 0.0035\n",
      "Epoch 281: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.9545e-05 - mae: 0.0035 - val_loss: 5.0775e-05 - val_mae: 0.0058\n",
      "Epoch 282/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.7660e-05 - mae: 0.0034\n",
      "Epoch 282: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 1.7994e-05 - mae: 0.0034 - val_loss: 4.5845e-05 - val_mae: 0.0055\n",
      "Epoch 283/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/800 [========================>.....] - ETA: 0s - loss: 1.5859e-05 - mae: 0.0032\n",
      "Epoch 283: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 176us/sample - loss: 1.5966e-05 - mae: 0.0032 - val_loss: 4.5648e-05 - val_mae: 0.0055\n",
      "Epoch 284/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 2.0124e-05 - mae: 0.0036\n",
      "Epoch 284: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 168us/sample - loss: 1.9615e-05 - mae: 0.0035 - val_loss: 4.6495e-05 - val_mae: 0.0055\n",
      "Epoch 285/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.6524e-05 - mae: 0.0032\n",
      "Epoch 285: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.6506e-05 - mae: 0.0032 - val_loss: 5.0983e-05 - val_mae: 0.0057\n",
      "Epoch 286/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.8437e-05 - mae: 0.0034\n",
      "Epoch 286: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 174us/sample - loss: 1.8114e-05 - mae: 0.0034 - val_loss: 4.6068e-05 - val_mae: 0.0055\n",
      "Epoch 287/1000\n",
      "670/800 [========================>.....] - ETA: 0s - loss: 2.0363e-05 - mae: 0.0036\n",
      "Epoch 287: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 184us/sample - loss: 1.9251e-05 - mae: 0.0035 - val_loss: 4.7447e-05 - val_mae: 0.0056\n",
      "Epoch 288/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 1.6251e-05 - mae: 0.0032\n",
      "Epoch 288: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 177us/sample - loss: 1.6122e-05 - mae: 0.0032 - val_loss: 4.5262e-05 - val_mae: 0.0054\n",
      "Epoch 289/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.9259e-05 - mae: 0.0034\n",
      "Epoch 289: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 1.9060e-05 - mae: 0.0034 - val_loss: 4.5327e-05 - val_mae: 0.0054\n",
      "Epoch 290/1000\n",
      "680/800 [========================>.....] - ETA: 0s - loss: 1.6151e-05 - mae: 0.0032\n",
      "Epoch 290: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 177us/sample - loss: 1.6059e-05 - mae: 0.0032 - val_loss: 4.5705e-05 - val_mae: 0.0054\n",
      "Epoch 291/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 1.6081e-05 - mae: 0.0032\n",
      "Epoch 291: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 1.6094e-05 - mae: 0.0032 - val_loss: 4.5646e-05 - val_mae: 0.0054\n",
      "Epoch 292/1000\n",
      "670/800 [========================>.....] - ETA: 0s - loss: 1.6746e-05 - mae: 0.0033\n",
      "Epoch 292: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 184us/sample - loss: 1.7574e-05 - mae: 0.0034 - val_loss: 5.0574e-05 - val_mae: 0.0058\n",
      "Epoch 293/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.8656e-05 - mae: 0.0034\n",
      "Epoch 293: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 1.8493e-05 - mae: 0.0034 - val_loss: 4.5852e-05 - val_mae: 0.0055\n",
      "Epoch 294/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.8070e-05 - mae: 0.0034\n",
      "Epoch 294: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 173us/sample - loss: 1.8448e-05 - mae: 0.0034 - val_loss: 4.9813e-05 - val_mae: 0.0056\n",
      "Epoch 295/1000\n",
      "680/800 [========================>.....] - ETA: 0s - loss: 1.7152e-05 - mae: 0.0033\n",
      "Epoch 295: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 1.6489e-05 - mae: 0.0032 - val_loss: 4.8564e-05 - val_mae: 0.0056\n",
      "Epoch 296/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 1.7194e-05 - mae: 0.0033\n",
      "Epoch 296: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 1.7828e-05 - mae: 0.0034 - val_loss: 5.0471e-05 - val_mae: 0.0058\n",
      "Epoch 297/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 1.6649e-05 - mae: 0.0032\n",
      "Epoch 297: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 1.6262e-05 - mae: 0.0032 - val_loss: 4.6959e-05 - val_mae: 0.0055\n",
      "Epoch 298/1000\n",
      "640/800 [=======================>......] - ETA: 0s - loss: 1.6835e-05 - mae: 0.0032\n",
      "Epoch 298: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 201us/sample - loss: 1.8170e-05 - mae: 0.0034 - val_loss: 5.4871e-05 - val_mae: 0.0059\n",
      "Epoch 299/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 2.0629e-05 - mae: 0.0036\n",
      "Epoch 299: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 1.9845e-05 - mae: 0.0035 - val_loss: 4.4965e-05 - val_mae: 0.0054\n",
      "Epoch 300/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 1.9367e-05 - mae: 0.0035\n",
      "Epoch 300: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 1.9515e-05 - mae: 0.0035 - val_loss: 4.6273e-05 - val_mae: 0.0055\n",
      "Epoch 301/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.8396e-05 - mae: 0.0034\n",
      "Epoch 301: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.8284e-05 - mae: 0.0034 - val_loss: 4.7899e-05 - val_mae: 0.0055\n",
      "Epoch 302/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.8998e-05 - mae: 0.0034\n",
      "Epoch 302: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.9024e-05 - mae: 0.0034 - val_loss: 4.4411e-05 - val_mae: 0.0054\n",
      "Epoch 303/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.6299e-05 - mae: 0.0032\n",
      "Epoch 303: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.6376e-05 - mae: 0.0032 - val_loss: 4.5253e-05 - val_mae: 0.0054\n",
      "Epoch 304/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.6576e-05 - mae: 0.0033\n",
      "Epoch 304: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.6666e-05 - mae: 0.0033 - val_loss: 4.4761e-05 - val_mae: 0.0054\n",
      "Epoch 305/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.9816e-05 - mae: 0.0035\n",
      "Epoch 305: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 2.0237e-05 - mae: 0.0035 - val_loss: 5.2757e-05 - val_mae: 0.0060\n",
      "Epoch 306/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.6398e-05 - mae: 0.0032\n",
      "Epoch 306: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.6879e-05 - mae: 0.0033 - val_loss: 4.4817e-05 - val_mae: 0.0054\n",
      "Epoch 307/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6690e-05 - mae: 0.0032\n",
      "Epoch 307: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6964e-05 - mae: 0.0033 - val_loss: 5.4061e-05 - val_mae: 0.0061\n",
      "Epoch 308/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5614e-05 - mae: 0.0031\n",
      "Epoch 308: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.6551e-05 - mae: 0.0032 - val_loss: 4.5262e-05 - val_mae: 0.0054\n",
      "Epoch 309/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.6751e-05 - mae: 0.0032\n",
      "Epoch 309: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.6834e-05 - mae: 0.0032 - val_loss: 4.4995e-05 - val_mae: 0.0054\n",
      "Epoch 310/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.5906e-05 - mae: 0.0032\n",
      "Epoch 310: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.6000e-05 - mae: 0.0032 - val_loss: 4.5736e-05 - val_mae: 0.0054\n",
      "Epoch 311/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.6175e-05 - mae: 0.0032\n",
      "Epoch 311: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.6997e-05 - mae: 0.0032 - val_loss: 4.6700e-05 - val_mae: 0.0055\n",
      "Epoch 312/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780/800 [============================>.] - ETA: 0s - loss: 1.6684e-05 - mae: 0.0033\n",
      "Epoch 312: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.6670e-05 - mae: 0.0033 - val_loss: 4.5180e-05 - val_mae: 0.0054\n",
      "Epoch 313/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.7777e-05 - mae: 0.0033\n",
      "Epoch 313: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 1.8349e-05 - mae: 0.0034 - val_loss: 5.0343e-05 - val_mae: 0.0057\n",
      "Epoch 314/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.6414e-05 - mae: 0.0032\n",
      "Epoch 314: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 1.6201e-05 - mae: 0.0032 - val_loss: 4.6266e-05 - val_mae: 0.0055\n",
      "Epoch 315/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.9218e-05 - mae: 0.0034\n",
      "Epoch 315: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.9233e-05 - mae: 0.0034 - val_loss: 4.6004e-05 - val_mae: 0.0054\n",
      "Epoch 316/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.8225e-05 - mae: 0.0034\n",
      "Epoch 316: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 174us/sample - loss: 1.7965e-05 - mae: 0.0034 - val_loss: 4.7985e-05 - val_mae: 0.0056\n",
      "Epoch 317/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.7120e-05 - mae: 0.0033\n",
      "Epoch 317: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 1.6957e-05 - mae: 0.0033 - val_loss: 4.5158e-05 - val_mae: 0.0054\n",
      "Epoch 318/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.6152e-05 - mae: 0.0032\n",
      "Epoch 318: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 1.6294e-05 - mae: 0.0032 - val_loss: 4.5363e-05 - val_mae: 0.0054\n",
      "Epoch 319/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.7102e-05 - mae: 0.0033\n",
      "Epoch 319: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 1.7170e-05 - mae: 0.0033 - val_loss: 4.8307e-05 - val_mae: 0.0056\n",
      "Epoch 320/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.8844e-05 - mae: 0.0035\n",
      "Epoch 320: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.9076e-05 - mae: 0.0035 - val_loss: 4.6259e-05 - val_mae: 0.0055\n",
      "Epoch 321/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 2.2265e-05 - mae: 0.0038\n",
      "Epoch 321: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.9374e-05 - mae: 0.0035 - val_loss: 4.9289e-05 - val_mae: 0.0056\n",
      "Epoch 322/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 2.1428e-05 - mae: 0.0037\n",
      "Epoch 322: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 2.0562e-05 - mae: 0.0036 - val_loss: 4.5299e-05 - val_mae: 0.0054\n",
      "Epoch 323/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.5239e-05 - mae: 0.0031\n",
      "Epoch 323: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.5239e-05 - mae: 0.0031 - val_loss: 4.5235e-05 - val_mae: 0.0054\n",
      "Epoch 324/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6436e-05 - mae: 0.0032\n",
      "Epoch 324: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.8801e-05 - mae: 0.0034 - val_loss: 4.6169e-05 - val_mae: 0.0055\n",
      "Epoch 325/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.5964e-05 - mae: 0.0031\n",
      "Epoch 325: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.6021e-05 - mae: 0.0032 - val_loss: 4.5626e-05 - val_mae: 0.0054\n",
      "Epoch 326/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.5929e-05 - mae: 0.0032\n",
      "Epoch 326: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.6202e-05 - mae: 0.0032 - val_loss: 4.9990e-05 - val_mae: 0.0057\n",
      "Epoch 327/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7096e-05 - mae: 0.0033\n",
      "Epoch 327: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.7096e-05 - mae: 0.0033 - val_loss: 4.4996e-05 - val_mae: 0.0054\n",
      "Epoch 328/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.5555e-05 - mae: 0.0031\n",
      "Epoch 328: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 1.6165e-05 - mae: 0.0032 - val_loss: 4.5850e-05 - val_mae: 0.0054\n",
      "Epoch 329/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.8396e-05 - mae: 0.0034   \n",
      "Epoch 329: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 1.8681e-05 - mae: 0.0034 - val_loss: 4.6050e-05 - val_mae: 0.0055\n",
      "Epoch 330/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.5844e-05 - mae: 0.0032\n",
      "Epoch 330: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 164us/sample - loss: 1.5831e-05 - mae: 0.0032 - val_loss: 4.5194e-05 - val_mae: 0.0054\n",
      "Epoch 331/1000\n",
      "670/800 [========================>.....] - ETA: 0s - loss: 1.6121e-05 - mae: 0.0032\n",
      "Epoch 331: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 1.5872e-05 - mae: 0.0032 - val_loss: 4.7751e-05 - val_mae: 0.0056\n",
      "Epoch 332/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 1.6632e-05 - mae: 0.0032\n",
      "Epoch 332: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 1.6551e-05 - mae: 0.0032 - val_loss: 4.7616e-05 - val_mae: 0.0056\n",
      "Epoch 333/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7492e-05 - mae: 0.0033\n",
      "Epoch 333: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.9338e-05 - mae: 0.0035 - val_loss: 4.9189e-05 - val_mae: 0.0057\n",
      "Epoch 334/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.8976e-05 - mae: 0.0035\n",
      "Epoch 334: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.7896e-05 - mae: 0.0034 - val_loss: 4.6282e-05 - val_mae: 0.0055\n",
      "Epoch 335/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.5869e-05 - mae: 0.0032\n",
      "Epoch 335: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.5869e-05 - mae: 0.0032 - val_loss: 4.8678e-05 - val_mae: 0.0056\n",
      "Epoch 336/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.7015e-05 - mae: 0.0033\n",
      "Epoch 336: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 1.6959e-05 - mae: 0.0033 - val_loss: 4.4739e-05 - val_mae: 0.0054\n",
      "Epoch 337/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 1.6759e-05 - mae: 0.0032\n",
      "Epoch 337: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 1.6562e-05 - mae: 0.0032 - val_loss: 4.5174e-05 - val_mae: 0.0054\n",
      "Epoch 338/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5462e-05 - mae: 0.0031\n",
      "Epoch 338: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.6504e-05 - mae: 0.0032 - val_loss: 4.5182e-05 - val_mae: 0.0054\n",
      "Epoch 339/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.5648e-05 - mae: 0.0032\n",
      "Epoch 339: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.8953e-05 - mae: 0.0034 - val_loss: 4.9948e-05 - val_mae: 0.0057\n",
      "Epoch 340/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6982e-05 - mae: 0.0032\n",
      "Epoch 340: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6599e-05 - mae: 0.0032 - val_loss: 5.0710e-05 - val_mae: 0.0057\n",
      "Epoch 341/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7462e-05 - mae: 0.0033\n",
      "Epoch 341: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6182e-05 - mae: 0.0032 - val_loss: 4.6645e-05 - val_mae: 0.0055\n",
      "Epoch 342/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.6137e-05 - mae: 0.0032\n",
      "Epoch 342: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.8837e-05 - mae: 0.0035 - val_loss: 5.7126e-05 - val_mae: 0.0062\n",
      "Epoch 343/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.8854e-05 - mae: 0.0034\n",
      "Epoch 343: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.8015e-05 - mae: 0.0034 - val_loss: 4.8455e-05 - val_mae: 0.0056\n",
      "Epoch 344/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7742e-05 - mae: 0.0033\n",
      "Epoch 344: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.8619e-05 - mae: 0.0034 - val_loss: 5.7878e-05 - val_mae: 0.0061\n",
      "Epoch 345/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 2.1569e-05 - mae: 0.0037\n",
      "Epoch 345: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 2.1726e-05 - mae: 0.0037 - val_loss: 6.0711e-05 - val_mae: 0.0065\n",
      "Epoch 346/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 2.0482e-05 - mae: 0.0036\n",
      "Epoch 346: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 2.0619e-05 - mae: 0.0036 - val_loss: 4.5220e-05 - val_mae: 0.0054\n",
      "Epoch 347/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.9756e-05 - mae: 0.0036\n",
      "Epoch 347: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.9756e-05 - mae: 0.0036 - val_loss: 5.4048e-05 - val_mae: 0.0061\n",
      "Epoch 348/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.8805e-05 - mae: 0.0035\n",
      "Epoch 348: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 1.8159e-05 - mae: 0.0034 - val_loss: 4.5702e-05 - val_mae: 0.0055\n",
      "Epoch 349/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.6926e-05 - mae: 0.0032\n",
      "Epoch 349: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 1.6585e-05 - mae: 0.0032 - val_loss: 4.5819e-05 - val_mae: 0.0055\n",
      "Epoch 350/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.7170e-05 - mae: 0.0032\n",
      "Epoch 350: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.7619e-05 - mae: 0.0033 - val_loss: 4.9443e-05 - val_mae: 0.0057\n",
      "Epoch 351/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 1.8037e-05 - mae: 0.0034\n",
      "Epoch 351: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 1.7964e-05 - mae: 0.0034 - val_loss: 5.0707e-05 - val_mae: 0.0057\n",
      "Epoch 352/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.7166e-05 - mae: 0.0033\n",
      "Epoch 352: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.6936e-05 - mae: 0.0033 - val_loss: 4.5539e-05 - val_mae: 0.0054\n",
      "Epoch 353/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.5507e-05 - mae: 0.0031\n",
      "Epoch 353: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.5417e-05 - mae: 0.0031 - val_loss: 4.5834e-05 - val_mae: 0.0054\n",
      "Epoch 354/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5292e-05 - mae: 0.0031\n",
      "Epoch 354: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.5918e-05 - mae: 0.0031 - val_loss: 4.7058e-05 - val_mae: 0.0055\n",
      "Epoch 355/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7807e-05 - mae: 0.0033\n",
      "Epoch 355: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.7807e-05 - mae: 0.0033 - val_loss: 5.8992e-05 - val_mae: 0.0061\n",
      "Epoch 356/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.6645e-05 - mae: 0.0032\n",
      "Epoch 356: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.6891e-05 - mae: 0.0032 - val_loss: 4.5928e-05 - val_mae: 0.0054\n",
      "Epoch 357/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6075e-05 - mae: 0.0032\n",
      "Epoch 357: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.6223e-05 - mae: 0.0032 - val_loss: 4.5863e-05 - val_mae: 0.0054\n",
      "Epoch 358/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.4862e-05 - mae: 0.0031\n",
      "Epoch 358: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.5074e-05 - mae: 0.0031 - val_loss: 4.7003e-05 - val_mae: 0.0055\n",
      "Epoch 359/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.8711e-05 - mae: 0.0035\n",
      "Epoch 359: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.7583e-05 - mae: 0.0034 - val_loss: 5.1099e-05 - val_mae: 0.0057\n",
      "Epoch 360/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.7385e-05 - mae: 0.0033\n",
      "Epoch 360: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.8883e-05 - mae: 0.0035 - val_loss: 4.8280e-05 - val_mae: 0.0056\n",
      "Epoch 361/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.9253e-05 - mae: 0.0035\n",
      "Epoch 361: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.9210e-05 - mae: 0.0035 - val_loss: 4.6940e-05 - val_mae: 0.0055\n",
      "Epoch 362/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5637e-05 - mae: 0.0031\n",
      "Epoch 362: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.5647e-05 - mae: 0.0031 - val_loss: 4.6347e-05 - val_mae: 0.0055\n",
      "Epoch 363/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6501e-05 - mae: 0.0032\n",
      "Epoch 363: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.9108e-05 - mae: 0.0034 - val_loss: 6.0578e-05 - val_mae: 0.0065\n",
      "Epoch 364/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.6931e-05 - mae: 0.0032\n",
      "Epoch 364: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 1.7171e-05 - mae: 0.0033 - val_loss: 4.7826e-05 - val_mae: 0.0056\n",
      "Epoch 365/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.7695e-05 - mae: 0.0033\n",
      "Epoch 365: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.8872e-05 - mae: 0.0035 - val_loss: 4.8194e-05 - val_mae: 0.0056\n",
      "Epoch 366/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4385e-05 - mae: 0.0030\n",
      "Epoch 366: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.5084e-05 - mae: 0.0031 - val_loss: 4.4864e-05 - val_mae: 0.0054\n",
      "Epoch 367/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.5929e-05 - mae: 0.0031\n",
      "Epoch 367: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.5995e-05 - mae: 0.0032 - val_loss: 4.9186e-05 - val_mae: 0.0056\n",
      "Epoch 368/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4209e-05 - mae: 0.0030\n",
      "Epoch 368: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.5777e-05 - mae: 0.0031 - val_loss: 4.5426e-05 - val_mae: 0.0054\n",
      "Epoch 369/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5543e-05 - mae: 0.0031\n",
      "Epoch 369: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7145e-05 - mae: 0.0033 - val_loss: 6.1418e-05 - val_mae: 0.0065\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/800 [================>.............] - ETA: 0s - loss: 1.9527e-05 - mae: 0.0035\n",
      "Epoch 370: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.8375e-05 - mae: 0.0034 - val_loss: 4.5265e-05 - val_mae: 0.0054\n",
      "Epoch 371/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5422e-05 - mae: 0.0031\n",
      "Epoch 371: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6155e-05 - mae: 0.0031 - val_loss: 5.2540e-05 - val_mae: 0.0058\n",
      "Epoch 372/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.6408e-05 - mae: 0.0032\n",
      "Epoch 372: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 1.6517e-05 - mae: 0.0032 - val_loss: 4.7614e-05 - val_mae: 0.0055\n",
      "Epoch 373/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7058e-05 - mae: 0.0033\n",
      "Epoch 373: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.7058e-05 - mae: 0.0033 - val_loss: 4.6402e-05 - val_mae: 0.0055\n",
      "Epoch 374/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.5024e-05 - mae: 0.0030\n",
      "Epoch 374: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.5698e-05 - mae: 0.0031 - val_loss: 4.7706e-05 - val_mae: 0.0055\n",
      "Epoch 375/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4128e-05 - mae: 0.0030\n",
      "Epoch 375: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.5620e-05 - mae: 0.0032 - val_loss: 4.6050e-05 - val_mae: 0.0054\n",
      "Epoch 376/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6133e-05 - mae: 0.0032\n",
      "Epoch 376: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.5563e-05 - mae: 0.0031 - val_loss: 5.1977e-05 - val_mae: 0.0058\n",
      "Epoch 377/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6453e-05 - mae: 0.0032\n",
      "Epoch 377: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.9979e-05 - mae: 0.0035 - val_loss: 5.0221e-05 - val_mae: 0.0057\n",
      "Epoch 378/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.8328e-05 - mae: 0.0035\n",
      "Epoch 378: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.7926e-05 - mae: 0.0034 - val_loss: 4.5894e-05 - val_mae: 0.0054\n",
      "Epoch 379/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4316e-05 - mae: 0.0029\n",
      "Epoch 379: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.5252e-05 - mae: 0.0031 - val_loss: 4.8357e-05 - val_mae: 0.0056\n",
      "Epoch 380/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.9407e-05 - mae: 0.0034\n",
      "Epoch 380: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.9552e-05 - mae: 0.0035 - val_loss: 5.9418e-05 - val_mae: 0.0064\n",
      "Epoch 381/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7407e-05 - mae: 0.0034\n",
      "Epoch 381: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7767e-05 - mae: 0.0033 - val_loss: 4.6020e-05 - val_mae: 0.0055\n",
      "Epoch 382/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.6766e-05 - mae: 0.0033\n",
      "Epoch 382: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.6820e-05 - mae: 0.0033 - val_loss: 4.7757e-05 - val_mae: 0.0056\n",
      "Epoch 383/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8817e-05 - mae: 0.0034\n",
      "Epoch 383: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7405e-05 - mae: 0.0033 - val_loss: 4.6378e-05 - val_mae: 0.0055\n",
      "Epoch 384/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6481e-05 - mae: 0.0032\n",
      "Epoch 384: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.6335e-05 - mae: 0.0032 - val_loss: 5.1328e-05 - val_mae: 0.0059\n",
      "Epoch 385/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.4202e-05 - mae: 0.0030\n",
      "Epoch 385: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7284e-05 - mae: 0.0033 - val_loss: 4.5382e-05 - val_mae: 0.0054\n",
      "Epoch 386/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4517e-05 - mae: 0.0030\n",
      "Epoch 386: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.5756e-05 - mae: 0.0031 - val_loss: 4.5355e-05 - val_mae: 0.0054\n",
      "Epoch 387/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.4600e-05 - mae: 0.0030\n",
      "Epoch 387: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.4523e-05 - mae: 0.0030 - val_loss: 5.0416e-05 - val_mae: 0.0057\n",
      "Epoch 388/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5900e-05 - mae: 0.0032\n",
      "Epoch 388: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6429e-05 - mae: 0.0032 - val_loss: 4.5244e-05 - val_mae: 0.0054\n",
      "Epoch 389/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.6652e-05 - mae: 0.0032\n",
      "Epoch 389: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.6646e-05 - mae: 0.0032 - val_loss: 4.5961e-05 - val_mae: 0.0054\n",
      "Epoch 390/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.6365e-05 - mae: 0.0032\n",
      "Epoch 390: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 1.6737e-05 - mae: 0.0032 - val_loss: 5.4919e-05 - val_mae: 0.0061\n",
      "Epoch 391/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.7087e-05 - mae: 0.0033\n",
      "Epoch 391: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 1.7674e-05 - mae: 0.0034 - val_loss: 5.0036e-05 - val_mae: 0.0056\n",
      "Epoch 392/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.7147e-05 - mae: 0.0033\n",
      "Epoch 392: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.7045e-05 - mae: 0.0033 - val_loss: 5.4124e-05 - val_mae: 0.0059\n",
      "Epoch 393/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.6158e-05 - mae: 0.0032\n",
      "Epoch 393: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.6158e-05 - mae: 0.0032 - val_loss: 4.6722e-05 - val_mae: 0.0054\n",
      "Epoch 394/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.3596e-05 - mae: 0.0029\n",
      "Epoch 394: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.7413e-05 - mae: 0.0033 - val_loss: 4.5597e-05 - val_mae: 0.0054\n",
      "Epoch 395/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.6714e-05 - mae: 0.0032\n",
      "Epoch 395: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.6379e-05 - mae: 0.0032 - val_loss: 4.5310e-05 - val_mae: 0.0054\n",
      "Epoch 396/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.4875e-05 - mae: 0.0031\n",
      "Epoch 396: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.4856e-05 - mae: 0.0031 - val_loss: 5.4906e-05 - val_mae: 0.0059\n",
      "Epoch 397/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.8041e-05 - mae: 0.0034\n",
      "Epoch 397: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.6416e-05 - mae: 0.0032 - val_loss: 4.5894e-05 - val_mae: 0.0054\n",
      "Epoch 398/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4522e-05 - mae: 0.0029\n",
      "Epoch 398: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6036e-05 - mae: 0.0031 - val_loss: 4.6628e-05 - val_mae: 0.0055\n",
      "Epoch 399/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6193e-05 - mae: 0.0032\n",
      "Epoch 399: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.7907e-05 - mae: 0.0034 - val_loss: 4.5289e-05 - val_mae: 0.0054\n",
      "Epoch 400/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.6240e-05 - mae: 0.0032\n",
      "Epoch 400: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.7363e-05 - mae: 0.0033 - val_loss: 4.5182e-05 - val_mae: 0.0054\n",
      "Epoch 401/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8925e-05 - mae: 0.0035\n",
      "Epoch 401: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.7110e-05 - mae: 0.0033 - val_loss: 4.5657e-05 - val_mae: 0.0054\n",
      "Epoch 402/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.6383e-05 - mae: 0.0032\n",
      "Epoch 402: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.6338e-05 - mae: 0.0032 - val_loss: 5.6353e-05 - val_mae: 0.0062\n",
      "Epoch 403/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5980e-05 - mae: 0.0032\n",
      "Epoch 403: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.7275e-05 - mae: 0.0033 - val_loss: 4.5875e-05 - val_mae: 0.0054\n",
      "Epoch 404/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.6178e-05 - mae: 0.0032\n",
      "Epoch 404: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.5964e-05 - mae: 0.0032 - val_loss: 4.6279e-05 - val_mae: 0.0055\n",
      "Epoch 405/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.7183e-05 - mae: 0.0033\n",
      "Epoch 405: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 1.7298e-05 - mae: 0.0033 - val_loss: 4.6717e-05 - val_mae: 0.0055\n",
      "Epoch 406/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.9611e-05 - mae: 0.0035\n",
      "Epoch 406: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.9140e-05 - mae: 0.0035 - val_loss: 4.7933e-05 - val_mae: 0.0055\n",
      "Epoch 407/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.7308e-05 - mae: 0.0033\n",
      "Epoch 407: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 1.7173e-05 - mae: 0.0032 - val_loss: 4.6324e-05 - val_mae: 0.0054\n",
      "Epoch 408/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.4578e-05 - mae: 0.0030\n",
      "Epoch 408: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.7252e-05 - mae: 0.0033 - val_loss: 5.1344e-05 - val_mae: 0.0057\n",
      "Epoch 409/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6961e-05 - mae: 0.0032\n",
      "Epoch 409: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.6232e-05 - mae: 0.0032 - val_loss: 4.6303e-05 - val_mae: 0.0054\n",
      "Epoch 410/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.7807e-05 - mae: 0.0033\n",
      "Epoch 410: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.7910e-05 - mae: 0.0034 - val_loss: 4.5231e-05 - val_mae: 0.0054\n",
      "Epoch 411/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.4690e-05 - mae: 0.0030\n",
      "Epoch 411: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 1.4983e-05 - mae: 0.0030 - val_loss: 4.7219e-05 - val_mae: 0.0055\n",
      "Epoch 412/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 2.0320e-05 - mae: 0.0035\n",
      "Epoch 412: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.7744e-05 - mae: 0.0033 - val_loss: 4.7732e-05 - val_mae: 0.0056\n",
      "Epoch 413/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7417e-05 - mae: 0.0032\n",
      "Epoch 413: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.6581e-05 - mae: 0.0032 - val_loss: 5.0906e-05 - val_mae: 0.0057\n",
      "Epoch 414/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 2.2557e-05 - mae: 0.0039\n",
      "Epoch 414: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 2.0244e-05 - mae: 0.0036 - val_loss: 4.6534e-05 - val_mae: 0.0055\n",
      "Epoch 415/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6974e-05 - mae: 0.0033\n",
      "Epoch 415: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.6325e-05 - mae: 0.0032 - val_loss: 4.5888e-05 - val_mae: 0.0054\n",
      "Epoch 416/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4054e-05 - mae: 0.0030\n",
      "Epoch 416: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6439e-05 - mae: 0.0032 - val_loss: 4.9361e-05 - val_mae: 0.0056\n",
      "Epoch 417/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 2.1121e-05 - mae: 0.0036\n",
      "Epoch 417: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 164us/sample - loss: 2.1279e-05 - mae: 0.0036 - val_loss: 4.6703e-05 - val_mae: 0.0055\n",
      "Epoch 418/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.9065e-05 - mae: 0.0034\n",
      "Epoch 418: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.9065e-05 - mae: 0.0034 - val_loss: 4.7037e-05 - val_mae: 0.0054\n",
      "Epoch 419/1000\n",
      "670/800 [========================>.....] - ETA: 0s - loss: 1.5334e-05 - mae: 0.0031\n",
      "Epoch 419: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 1.5909e-05 - mae: 0.0032 - val_loss: 4.9130e-05 - val_mae: 0.0056\n",
      "Epoch 420/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.6239e-05 - mae: 0.0032\n",
      "Epoch 420: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 1.6224e-05 - mae: 0.0032 - val_loss: 4.5717e-05 - val_mae: 0.0054\n",
      "Epoch 421/1000\n",
      "660/800 [=======================>......] - ETA: 0s - loss: 1.4241e-05 - mae: 0.0029\n",
      "Epoch 421: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 182us/sample - loss: 1.4677e-05 - mae: 0.0030 - val_loss: 4.6618e-05 - val_mae: 0.0054\n",
      "Epoch 422/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.5244e-05 - mae: 0.0031\n",
      "Epoch 422: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 164us/sample - loss: 1.5197e-05 - mae: 0.0031 - val_loss: 4.6881e-05 - val_mae: 0.0055\n",
      "Epoch 423/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 1.8781e-05 - mae: 0.0034\n",
      "Epoch 423: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 201us/sample - loss: 1.9734e-05 - mae: 0.0035 - val_loss: 5.3323e-05 - val_mae: 0.0058\n",
      "Epoch 424/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.5393e-05 - mae: 0.0031\n",
      "Epoch 424: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.5611e-05 - mae: 0.0031 - val_loss: 4.6419e-05 - val_mae: 0.0054\n",
      "Epoch 425/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 1.6075e-05 - mae: 0.0032\n",
      "Epoch 425: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 1.6503e-05 - mae: 0.0032 - val_loss: 6.0623e-05 - val_mae: 0.0062\n",
      "Epoch 426/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.8355e-05 - mae: 0.0034\n",
      "Epoch 426: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 180us/sample - loss: 1.8713e-05 - mae: 0.0034 - val_loss: 4.8906e-05 - val_mae: 0.0056\n",
      "Epoch 427/1000\n",
      "680/800 [========================>.....] - ETA: 0s - loss: 1.6818e-05 - mae: 0.0033\n",
      "Epoch 427: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 1.6878e-05 - mae: 0.0033 - val_loss: 4.6305e-05 - val_mae: 0.0054\n",
      "Epoch 428/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/800 [===========================>..] - ETA: 0s - loss: 1.7261e-05 - mae: 0.0033\n",
      "Epoch 428: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.7030e-05 - mae: 0.0033 - val_loss: 4.6854e-05 - val_mae: 0.0055\n",
      "Epoch 429/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.5136e-05 - mae: 0.0031\n",
      "Epoch 429: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.5131e-05 - mae: 0.0031 - val_loss: 4.6376e-05 - val_mae: 0.0055\n",
      "Epoch 430/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 2.3113e-05 - mae: 0.0038\n",
      "Epoch 430: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 2.1312e-05 - mae: 0.0037 - val_loss: 5.8177e-05 - val_mae: 0.0061\n",
      "Epoch 431/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5134e-05 - mae: 0.0030\n",
      "Epoch 431: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.6269e-05 - mae: 0.0032 - val_loss: 4.7461e-05 - val_mae: 0.0055\n",
      "Epoch 432/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6287e-05 - mae: 0.0032\n",
      "Epoch 432: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6469e-05 - mae: 0.0032 - val_loss: 4.7305e-05 - val_mae: 0.0055\n",
      "Epoch 433/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6725e-05 - mae: 0.0032\n",
      "Epoch 433: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7161e-05 - mae: 0.0033 - val_loss: 4.7266e-05 - val_mae: 0.0055\n",
      "Epoch 434/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5706e-05 - mae: 0.0031\n",
      "Epoch 434: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.7085e-05 - mae: 0.0033 - val_loss: 5.0777e-05 - val_mae: 0.0057\n",
      "Epoch 435/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4852e-05 - mae: 0.0031\n",
      "Epoch 435: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.7370e-05 - mae: 0.0033 - val_loss: 4.7624e-05 - val_mae: 0.0056\n",
      "Epoch 436/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.4909e-05 - mae: 0.0031\n",
      "Epoch 436: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.5920e-05 - mae: 0.0032 - val_loss: 4.5293e-05 - val_mae: 0.0054\n",
      "Epoch 437/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3117e-05 - mae: 0.0029\n",
      "Epoch 437: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.5360e-05 - mae: 0.0031 - val_loss: 4.7185e-05 - val_mae: 0.0055\n",
      "Epoch 438/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.7017e-05 - mae: 0.0033\n",
      "Epoch 438: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 1.6893e-05 - mae: 0.0032 - val_loss: 4.6404e-05 - val_mae: 0.0055\n",
      "Epoch 439/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6117e-05 - mae: 0.0032\n",
      "Epoch 439: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.6658e-05 - mae: 0.0032 - val_loss: 4.5999e-05 - val_mae: 0.0054\n",
      "Epoch 440/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.9196e-05 - mae: 0.0035\n",
      "Epoch 440: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.9086e-05 - mae: 0.0035 - val_loss: 4.5465e-05 - val_mae: 0.0054\n",
      "Epoch 441/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.6615e-05 - mae: 0.0032\n",
      "Epoch 441: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.6521e-05 - mae: 0.0032 - val_loss: 4.6354e-05 - val_mae: 0.0054\n",
      "Epoch 442/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.5569e-05 - mae: 0.0031\n",
      "Epoch 442: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.5530e-05 - mae: 0.0031 - val_loss: 4.9084e-05 - val_mae: 0.0057\n",
      "Epoch 443/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6390e-05 - mae: 0.0032\n",
      "Epoch 443: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.5704e-05 - mae: 0.0031 - val_loss: 5.0559e-05 - val_mae: 0.0056\n",
      "Epoch 444/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5850e-05 - mae: 0.0031\n",
      "Epoch 444: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.6062e-05 - mae: 0.0032 - val_loss: 4.5995e-05 - val_mae: 0.0054\n",
      "Epoch 445/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5529e-05 - mae: 0.0032\n",
      "Epoch 445: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.5736e-05 - mae: 0.0032 - val_loss: 4.6205e-05 - val_mae: 0.0054\n",
      "Epoch 446/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4223e-05 - mae: 0.0030\n",
      "Epoch 446: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.5455e-05 - mae: 0.0031 - val_loss: 4.7346e-05 - val_mae: 0.0055\n",
      "Epoch 447/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5696e-05 - mae: 0.0031\n",
      "Epoch 447: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.5573e-05 - mae: 0.0031 - val_loss: 4.8655e-05 - val_mae: 0.0056\n",
      "Epoch 448/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7881e-05 - mae: 0.0034\n",
      "Epoch 448: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.8528e-05 - mae: 0.0034 - val_loss: 4.7001e-05 - val_mae: 0.0055\n",
      "Epoch 449/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.6250e-05 - mae: 0.0032\n",
      "Epoch 449: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.6672e-05 - mae: 0.0032 - val_loss: 4.8100e-05 - val_mae: 0.0056\n",
      "Epoch 450/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.4470e-05 - mae: 0.0030\n",
      "Epoch 450: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.4744e-05 - mae: 0.0030 - val_loss: 4.6638e-05 - val_mae: 0.0055\n",
      "Epoch 451/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4815e-05 - mae: 0.0031\n",
      "Epoch 451: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.4988e-05 - mae: 0.0030 - val_loss: 4.7950e-05 - val_mae: 0.0055\n",
      "Epoch 452/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7313e-05 - mae: 0.0033\n",
      "Epoch 452: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.7313e-05 - mae: 0.0033 - val_loss: 4.6352e-05 - val_mae: 0.0054\n",
      "Epoch 453/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.9855e-05 - mae: 0.0036\n",
      "Epoch 453: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.9245e-05 - mae: 0.0035 - val_loss: 4.6353e-05 - val_mae: 0.0054\n",
      "Epoch 454/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.7685e-05 - mae: 0.0033\n",
      "Epoch 454: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 1.7298e-05 - mae: 0.0033 - val_loss: 4.6100e-05 - val_mae: 0.0054\n",
      "Epoch 455/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.7125e-05 - mae: 0.0032\n",
      "Epoch 455: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.5890e-05 - mae: 0.0031 - val_loss: 4.6812e-05 - val_mae: 0.0055\n",
      "Epoch 456/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6009e-05 - mae: 0.0032\n",
      "Epoch 456: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.5255e-05 - mae: 0.0031 - val_loss: 4.6274e-05 - val_mae: 0.0054\n",
      "Epoch 457/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4739e-05 - mae: 0.0030\n",
      "Epoch 457: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.5841e-05 - mae: 0.0031 - val_loss: 4.5958e-05 - val_mae: 0.0054\n",
      "Epoch 458/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.6416e-05 - mae: 0.0032\n",
      "Epoch 458: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.6683e-05 - mae: 0.0032 - val_loss: 4.6381e-05 - val_mae: 0.0054\n",
      "Epoch 459/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.7601e-05 - mae: 0.0034\n",
      "Epoch 459: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 1.8194e-05 - mae: 0.0034 - val_loss: 4.7510e-05 - val_mae: 0.0056\n",
      "Epoch 460/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 1.5017e-05 - mae: 0.0031\n",
      "Epoch 460: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 175us/sample - loss: 1.5228e-05 - mae: 0.0031 - val_loss: 4.5800e-05 - val_mae: 0.0054\n",
      "Epoch 461/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.5177e-05 - mae: 0.0031\n",
      "Epoch 461: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 171us/sample - loss: 1.5585e-05 - mae: 0.0031 - val_loss: 4.5918e-05 - val_mae: 0.0054\n",
      "Epoch 462/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.5131e-05 - mae: 0.0031\n",
      "Epoch 462: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 168us/sample - loss: 1.5629e-05 - mae: 0.0031 - val_loss: 4.9502e-05 - val_mae: 0.0056\n",
      "Epoch 463/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6898e-05 - mae: 0.0032\n",
      "Epoch 463: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.7429e-05 - mae: 0.0033 - val_loss: 4.5703e-05 - val_mae: 0.0054\n",
      "Epoch 464/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.7465e-05 - mae: 0.0033\n",
      "Epoch 464: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.5602e-05 - mae: 0.0031 - val_loss: 4.6178e-05 - val_mae: 0.0054\n",
      "Epoch 465/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.8095e-05 - mae: 0.0034\n",
      "Epoch 465: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.8158e-05 - mae: 0.0034 - val_loss: 4.5868e-05 - val_mae: 0.0054\n",
      "Epoch 466/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.6719e-05 - mae: 0.0032\n",
      "Epoch 466: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.7161e-05 - mae: 0.0033 - val_loss: 5.0064e-05 - val_mae: 0.0056\n",
      "Epoch 467/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.3942e-05 - mae: 0.0029\n",
      "Epoch 467: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.6424e-05 - mae: 0.0032 - val_loss: 4.7639e-05 - val_mae: 0.0056\n",
      "Epoch 468/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5341e-05 - mae: 0.0031\n",
      "Epoch 468: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6334e-05 - mae: 0.0032 - val_loss: 4.6004e-05 - val_mae: 0.0054\n",
      "Epoch 469/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3198e-05 - mae: 0.0029\n",
      "Epoch 469: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.4545e-05 - mae: 0.0030 - val_loss: 4.5858e-05 - val_mae: 0.0054\n",
      "Epoch 470/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7129e-05 - mae: 0.0033\n",
      "Epoch 470: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.7129e-05 - mae: 0.0033 - val_loss: 4.5846e-05 - val_mae: 0.0054\n",
      "Epoch 471/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.5701e-05 - mae: 0.0031\n",
      "Epoch 471: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.5866e-05 - mae: 0.0031 - val_loss: 4.5956e-05 - val_mae: 0.0054\n",
      "Epoch 472/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6969e-05 - mae: 0.0033\n",
      "Epoch 472: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6951e-05 - mae: 0.0032 - val_loss: 4.6173e-05 - val_mae: 0.0054\n",
      "Epoch 473/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6106e-05 - mae: 0.0031\n",
      "Epoch 473: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7583e-05 - mae: 0.0033 - val_loss: 7.9833e-05 - val_mae: 0.0072\n",
      "Epoch 474/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.8505e-05 - mae: 0.0033\n",
      "Epoch 474: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.9004e-05 - mae: 0.0034 - val_loss: 5.6304e-05 - val_mae: 0.0060\n",
      "Epoch 475/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 2.0617e-05 - mae: 0.0037\n",
      "Epoch 475: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.7814e-05 - mae: 0.0033 - val_loss: 4.6046e-05 - val_mae: 0.0054\n",
      "Epoch 476/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5030e-05 - mae: 0.0031\n",
      "Epoch 476: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.5706e-05 - mae: 0.0031 - val_loss: 4.8138e-05 - val_mae: 0.0056\n",
      "Epoch 477/1000\n",
      "370/800 [============>.................] - ETA: 0s - loss: 1.3837e-05 - mae: 0.0029\n",
      "Epoch 477: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.4376e-05 - mae: 0.0029 - val_loss: 4.7931e-05 - val_mae: 0.0056\n",
      "Epoch 478/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6531e-05 - mae: 0.0032\n",
      "Epoch 478: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6975e-05 - mae: 0.0033 - val_loss: 4.7233e-05 - val_mae: 0.0055\n",
      "Epoch 479/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4886e-05 - mae: 0.0031\n",
      "Epoch 479: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.5185e-05 - mae: 0.0031 - val_loss: 4.6596e-05 - val_mae: 0.0055\n",
      "Epoch 480/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4283e-05 - mae: 0.0029\n",
      "Epoch 480: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.5035e-05 - mae: 0.0030 - val_loss: 4.5720e-05 - val_mae: 0.0054\n",
      "Epoch 481/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.5168e-05 - mae: 0.0030\n",
      "Epoch 481: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.4911e-05 - mae: 0.0030 - val_loss: 4.5940e-05 - val_mae: 0.0054\n",
      "Epoch 482/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6737e-05 - mae: 0.0032\n",
      "Epoch 482: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.7126e-05 - mae: 0.0033 - val_loss: 4.7920e-05 - val_mae: 0.0055\n",
      "Epoch 483/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.4815e-05 - mae: 0.0030\n",
      "Epoch 483: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.5026e-05 - mae: 0.0031 - val_loss: 4.5751e-05 - val_mae: 0.0054\n",
      "Epoch 484/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.8304e-05 - mae: 0.0034\n",
      "Epoch 484: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.8187e-05 - mae: 0.0034 - val_loss: 5.3342e-05 - val_mae: 0.0058\n",
      "Epoch 485/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.4782e-05 - mae: 0.0031\n",
      "Epoch 485: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 1.4967e-05 - mae: 0.0031 - val_loss: 5.0727e-05 - val_mae: 0.0057\n",
      "Epoch 486/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4052e-05 - mae: 0.0030\n",
      "Epoch 486: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.5676e-05 - mae: 0.0031 - val_loss: 4.8156e-05 - val_mae: 0.0055\n",
      "Epoch 487/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.6190e-05 - mae: 0.0032\n",
      "Epoch 487: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 174us/sample - loss: 1.6499e-05 - mae: 0.0032 - val_loss: 5.0323e-05 - val_mae: 0.0058\n",
      "Epoch 488/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 1.6854e-05 - mae: 0.0032\n",
      "Epoch 488: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 1.7302e-05 - mae: 0.0033 - val_loss: 5.7198e-05 - val_mae: 0.0062\n",
      "Epoch 489/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.7937e-05 - mae: 0.0034\n",
      "Epoch 489: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 168us/sample - loss: 1.8425e-05 - mae: 0.0034 - val_loss: 4.6109e-05 - val_mae: 0.0054\n",
      "Epoch 490/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4486e-05 - mae: 0.0030\n",
      "Epoch 490: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.5033e-05 - mae: 0.0030 - val_loss: 5.1540e-05 - val_mae: 0.0057\n",
      "Epoch 491/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4488e-05 - mae: 0.0029\n",
      "Epoch 491: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.5663e-05 - mae: 0.0031 - val_loss: 4.6387e-05 - val_mae: 0.0054\n",
      "Epoch 492/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.5180e-05 - mae: 0.0031\n",
      "Epoch 492: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.5173e-05 - mae: 0.0031 - val_loss: 4.8552e-05 - val_mae: 0.0056\n",
      "Epoch 493/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.5397e-05 - mae: 0.0031\n",
      "Epoch 493: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.5525e-05 - mae: 0.0031 - val_loss: 4.9543e-05 - val_mae: 0.0057\n",
      "Epoch 494/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.5733e-05 - mae: 0.0031\n",
      "Epoch 494: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.5693e-05 - mae: 0.0031 - val_loss: 4.6393e-05 - val_mae: 0.0054\n",
      "Epoch 495/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3732e-05 - mae: 0.0029\n",
      "Epoch 495: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.5078e-05 - mae: 0.0030 - val_loss: 4.9839e-05 - val_mae: 0.0056\n",
      "Epoch 496/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7342e-05 - mae: 0.0033\n",
      "Epoch 496: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.6715e-05 - mae: 0.0032 - val_loss: 4.6713e-05 - val_mae: 0.0054\n",
      "Epoch 497/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4557e-05 - mae: 0.0030\n",
      "Epoch 497: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.5386e-05 - mae: 0.0031 - val_loss: 4.5971e-05 - val_mae: 0.0054\n",
      "Epoch 498/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3721e-05 - mae: 0.0029\n",
      "Epoch 498: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.5798e-05 - mae: 0.0031 - val_loss: 4.8660e-05 - val_mae: 0.0056\n",
      "Epoch 499/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7530e-05 - mae: 0.0033\n",
      "Epoch 499: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7134e-05 - mae: 0.0033 - val_loss: 4.5785e-05 - val_mae: 0.0054\n",
      "Epoch 500/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.4946e-05 - mae: 0.0030\n",
      "Epoch 500: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.4854e-05 - mae: 0.0030 - val_loss: 4.7970e-05 - val_mae: 0.0056\n",
      "Epoch 501/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6542e-05 - mae: 0.0032\n",
      "Epoch 501: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.5848e-05 - mae: 0.0032 - val_loss: 4.6375e-05 - val_mae: 0.0054\n",
      "Epoch 502/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.6008e-05 - mae: 0.0031\n",
      "Epoch 502: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.6040e-05 - mae: 0.0031 - val_loss: 4.6336e-05 - val_mae: 0.0054\n",
      "Epoch 503/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7315e-05 - mae: 0.0033\n",
      "Epoch 503: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.6263e-05 - mae: 0.0032 - val_loss: 4.6573e-05 - val_mae: 0.0055\n",
      "Epoch 504/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.8833e-05 - mae: 0.0034\n",
      "Epoch 504: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.8819e-05 - mae: 0.0034 - val_loss: 5.5546e-05 - val_mae: 0.0061\n",
      "Epoch 505/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5653e-05 - mae: 0.0032\n",
      "Epoch 505: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.7047e-05 - mae: 0.0033 - val_loss: 4.7007e-05 - val_mae: 0.0055\n",
      "Epoch 506/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6172e-05 - mae: 0.0031\n",
      "Epoch 506: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.6224e-05 - mae: 0.0032 - val_loss: 4.7663e-05 - val_mae: 0.0056\n",
      "Epoch 507/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6274e-05 - mae: 0.0032\n",
      "Epoch 507: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.5507e-05 - mae: 0.0031 - val_loss: 4.9670e-05 - val_mae: 0.0057\n",
      "Epoch 508/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6066e-05 - mae: 0.0031\n",
      "Epoch 508: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.5244e-05 - mae: 0.0031 - val_loss: 4.6103e-05 - val_mae: 0.0054\n",
      "Epoch 509/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5528e-05 - mae: 0.0031\n",
      "Epoch 509: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6788e-05 - mae: 0.0032 - val_loss: 6.6953e-05 - val_mae: 0.0065\n",
      "Epoch 510/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.9539e-05 - mae: 0.0036\n",
      "Epoch 510: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.8291e-05 - mae: 0.0034 - val_loss: 7.2883e-05 - val_mae: 0.0068\n",
      "Epoch 511/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.9477e-05 - mae: 0.0036\n",
      "Epoch 511: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.7634e-05 - mae: 0.0034 - val_loss: 5.0156e-05 - val_mae: 0.0056\n",
      "Epoch 512/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.5637e-05 - mae: 0.0031\n",
      "Epoch 512: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.6545e-05 - mae: 0.0032 - val_loss: 4.6425e-05 - val_mae: 0.0054\n",
      "Epoch 513/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.6909e-05 - mae: 0.0033\n",
      "Epoch 513: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 1.7119e-05 - mae: 0.0033 - val_loss: 5.7010e-05 - val_mae: 0.0062\n",
      "Epoch 514/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5405e-05 - mae: 0.0031\n",
      "Epoch 514: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.5848e-05 - mae: 0.0032 - val_loss: 4.6073e-05 - val_mae: 0.0054\n",
      "Epoch 515/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4654e-05 - mae: 0.0031\n",
      "Epoch 515: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8006e-05 - mae: 0.0034 - val_loss: 5.0497e-05 - val_mae: 0.0056\n",
      "Epoch 516/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.6208e-05 - mae: 0.0032\n",
      "Epoch 516: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.6064e-05 - mae: 0.0031 - val_loss: 5.0604e-05 - val_mae: 0.0057\n",
      "Epoch 517/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6980e-05 - mae: 0.0032\n",
      "Epoch 517: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7909e-05 - mae: 0.0033 - val_loss: 4.6218e-05 - val_mae: 0.0054\n",
      "Epoch 518/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.3809e-05 - mae: 0.0029\n",
      "Epoch 518: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.5926e-05 - mae: 0.0031 - val_loss: 4.6550e-05 - val_mae: 0.0055\n",
      "Epoch 519/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.4417e-05 - mae: 0.0030\n",
      "Epoch 519: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.5588e-05 - mae: 0.0031 - val_loss: 4.6444e-05 - val_mae: 0.0054\n",
      "Epoch 520/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6236e-05 - mae: 0.0032\n",
      "Epoch 520: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6163e-05 - mae: 0.0032 - val_loss: 4.6243e-05 - val_mae: 0.0054\n",
      "Epoch 521/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.4623e-05 - mae: 0.0030\n",
      "Epoch 521: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.4686e-05 - mae: 0.0030 - val_loss: 4.5898e-05 - val_mae: 0.0054\n",
      "Epoch 522/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.2802e-05 - mae: 0.0028\n",
      "Epoch 522: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.3974e-05 - mae: 0.0029 - val_loss: 4.6141e-05 - val_mae: 0.0054\n",
      "Epoch 523/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.3960e-05 - mae: 0.0029\n",
      "Epoch 523: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 1.4212e-05 - mae: 0.0030 - val_loss: 5.3214e-05 - val_mae: 0.0058\n",
      "Epoch 524/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.7373e-05 - mae: 0.0033\n",
      "Epoch 524: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 1.7540e-05 - mae: 0.0033 - val_loss: 5.6112e-05 - val_mae: 0.0062\n",
      "Epoch 525/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6622e-05 - mae: 0.0033\n",
      "Epoch 525: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.5923e-05 - mae: 0.0032 - val_loss: 4.5803e-05 - val_mae: 0.0054\n",
      "Epoch 526/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5684e-05 - mae: 0.0032\n",
      "Epoch 526: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.5110e-05 - mae: 0.0031 - val_loss: 5.1676e-05 - val_mae: 0.0057\n",
      "Epoch 527/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.6003e-05 - mae: 0.0031\n",
      "Epoch 527: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.5890e-05 - mae: 0.0031 - val_loss: 4.5634e-05 - val_mae: 0.0054\n",
      "Epoch 528/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.6192e-05 - mae: 0.0031\n",
      "Epoch 528: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7570e-05 - mae: 0.0033 - val_loss: 4.6382e-05 - val_mae: 0.0055\n",
      "Epoch 529/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.5384e-05 - mae: 0.0031\n",
      "Epoch 529: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.5387e-05 - mae: 0.0031 - val_loss: 4.8428e-05 - val_mae: 0.0056\n",
      "Epoch 530/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7516e-05 - mae: 0.0033\n",
      "Epoch 530: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.9461e-05 - mae: 0.0035 - val_loss: 4.6595e-05 - val_mae: 0.0055\n",
      "Epoch 531/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6498e-05 - mae: 0.0032\n",
      "Epoch 531: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.5530e-05 - mae: 0.0031 - val_loss: 4.6559e-05 - val_mae: 0.0055\n",
      "Epoch 532/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4391e-05 - mae: 0.0030\n",
      "Epoch 532: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.4984e-05 - mae: 0.0031 - val_loss: 4.9078e-05 - val_mae: 0.0057\n",
      "Epoch 533/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6555e-05 - mae: 0.0032\n",
      "Epoch 533: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.5094e-05 - mae: 0.0030 - val_loss: 4.7781e-05 - val_mae: 0.0055\n",
      "Epoch 534/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9748e-05 - mae: 0.0035\n",
      "Epoch 534: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.8894e-05 - mae: 0.0034 - val_loss: 4.5836e-05 - val_mae: 0.0054\n",
      "Epoch 535/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9837e-05 - mae: 0.0036\n",
      "Epoch 535: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.7744e-05 - mae: 0.0034 - val_loss: 4.6031e-05 - val_mae: 0.0054\n",
      "Epoch 536/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.3829e-05 - mae: 0.0030\n",
      "Epoch 536: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.4344e-05 - mae: 0.0030 - val_loss: 4.6561e-05 - val_mae: 0.0054\n",
      "Epoch 537/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5088e-05 - mae: 0.0031\n",
      "Epoch 537: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.5824e-05 - mae: 0.0031 - val_loss: 4.7578e-05 - val_mae: 0.0056\n",
      "Epoch 538/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.3823e-05 - mae: 0.0029\n",
      "Epoch 538: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.5045e-05 - mae: 0.0031 - val_loss: 4.6421e-05 - val_mae: 0.0055\n",
      "Epoch 539/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5159e-05 - mae: 0.0031\n",
      "Epoch 539: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.8105e-05 - mae: 0.0034 - val_loss: 5.2528e-05 - val_mae: 0.0060\n",
      "Epoch 540/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4846e-05 - mae: 0.0030\n",
      "Epoch 540: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.4158e-05 - mae: 0.0030 - val_loss: 4.5999e-05 - val_mae: 0.0054\n",
      "Epoch 541/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5952e-05 - mae: 0.0032\n",
      "Epoch 541: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.5529e-05 - mae: 0.0031 - val_loss: 4.7419e-05 - val_mae: 0.0055\n",
      "Epoch 542/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4221e-05 - mae: 0.0030\n",
      "Epoch 542: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.5302e-05 - mae: 0.0031 - val_loss: 4.6009e-05 - val_mae: 0.0054\n",
      "Epoch 543/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.3755e-05 - mae: 0.0029\n",
      "Epoch 543: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.4642e-05 - mae: 0.0030 - val_loss: 4.6349e-05 - val_mae: 0.0054\n",
      "Epoch 544/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4307e-05 - mae: 0.0029\n",
      "Epoch 544: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.5271e-05 - mae: 0.0031 - val_loss: 4.6093e-05 - val_mae: 0.0054\n",
      "Epoch 545/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 2.1693e-05 - mae: 0.0037\n",
      "Epoch 545: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.7764e-05 - mae: 0.0033 - val_loss: 4.6032e-05 - val_mae: 0.0054\n",
      "Epoch 546/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6981e-05 - mae: 0.0033\n",
      "Epoch 546: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.5948e-05 - mae: 0.0032 - val_loss: 5.1056e-05 - val_mae: 0.0056\n",
      "Epoch 547/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6441e-05 - mae: 0.0032\n",
      "Epoch 547: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.6795e-05 - mae: 0.0033 - val_loss: 4.6471e-05 - val_mae: 0.0054\n",
      "Epoch 548/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5303e-05 - mae: 0.0031\n",
      "Epoch 548: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.5788e-05 - mae: 0.0031 - val_loss: 4.6987e-05 - val_mae: 0.0055\n",
      "Epoch 549/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5052e-05 - mae: 0.0031\n",
      "Epoch 549: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.4518e-05 - mae: 0.0030 - val_loss: 4.7811e-05 - val_mae: 0.0056\n",
      "Epoch 550/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6638e-05 - mae: 0.0032\n",
      "Epoch 550: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.4959e-05 - mae: 0.0030 - val_loss: 4.5695e-05 - val_mae: 0.0054\n",
      "Epoch 551/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.6479e-05 - mae: 0.0032\n",
      "Epoch 551: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.6086e-05 - mae: 0.0032 - val_loss: 5.0564e-05 - val_mae: 0.0056\n",
      "Epoch 552/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.7902e-05 - mae: 0.0033\n",
      "Epoch 552: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6939e-05 - mae: 0.0032 - val_loss: 4.6510e-05 - val_mae: 0.0054\n",
      "Epoch 553/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4604e-05 - mae: 0.0030\n",
      "Epoch 553: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.5005e-05 - mae: 0.0030 - val_loss: 4.6741e-05 - val_mae: 0.0054\n",
      "Epoch 554/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.8057e-05 - mae: 0.0034\n",
      "Epoch 554: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.8502e-05 - mae: 0.0034 - val_loss: 4.6715e-05 - val_mae: 0.0055\n",
      "Epoch 555/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5356e-05 - mae: 0.0031\n",
      "Epoch 555: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.4891e-05 - mae: 0.0030 - val_loss: 4.9976e-05 - val_mae: 0.0057\n",
      "Epoch 556/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.6356e-05 - mae: 0.0032\n",
      "Epoch 556: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.5884e-05 - mae: 0.0031 - val_loss: 4.7358e-05 - val_mae: 0.0055\n",
      "Epoch 557/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5680e-05 - mae: 0.0031\n",
      "Epoch 557: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.5814e-05 - mae: 0.0031 - val_loss: 4.8092e-05 - val_mae: 0.0056\n",
      "Epoch 558/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5548e-05 - mae: 0.0031\n",
      "Epoch 558: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.6553e-05 - mae: 0.0032 - val_loss: 4.7168e-05 - val_mae: 0.0055\n",
      "Epoch 559/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6513e-05 - mae: 0.0032\n",
      "Epoch 559: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.5347e-05 - mae: 0.0031 - val_loss: 4.6633e-05 - val_mae: 0.0054\n",
      "Epoch 560/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4344e-05 - mae: 0.0029\n",
      "Epoch 560: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.5386e-05 - mae: 0.0030 - val_loss: 4.6614e-05 - val_mae: 0.0055\n",
      "Epoch 561/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.6654e-05 - mae: 0.0033\n",
      "Epoch 561: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 164us/sample - loss: 1.6570e-05 - mae: 0.0032 - val_loss: 4.9326e-05 - val_mae: 0.0057\n",
      "Epoch 562/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5524e-05 - mae: 0.0031\n",
      "Epoch 562: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.6074e-05 - mae: 0.0032 - val_loss: 4.6461e-05 - val_mae: 0.0054\n",
      "Epoch 563/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.6234e-05 - mae: 0.0032\n",
      "Epoch 563: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.6508e-05 - mae: 0.0032 - val_loss: 6.2009e-05 - val_mae: 0.0065\n",
      "Epoch 564/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.8222e-05 - mae: 0.0033\n",
      "Epoch 564: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.8395e-05 - mae: 0.0034 - val_loss: 5.8087e-05 - val_mae: 0.0063\n",
      "Epoch 565/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6142e-05 - mae: 0.0031\n",
      "Epoch 565: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7122e-05 - mae: 0.0032 - val_loss: 5.6960e-05 - val_mae: 0.0060\n",
      "Epoch 566/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.6133e-05 - mae: 0.0032\n",
      "Epoch 566: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 1.6085e-05 - mae: 0.0032 - val_loss: 6.9109e-05 - val_mae: 0.0066\n",
      "Epoch 567/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 2.0899e-05 - mae: 0.0036\n",
      "Epoch 567: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.8208e-05 - mae: 0.0034 - val_loss: 5.2523e-05 - val_mae: 0.0057\n",
      "Epoch 568/1000\n",
      "380/800 [=============>................] - ETA: 0s - loss: 1.6082e-05 - mae: 0.0032\n",
      "Epoch 568: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.5999e-05 - mae: 0.0032 - val_loss: 4.7965e-05 - val_mae: 0.0055\n",
      "Epoch 569/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7536e-05 - mae: 0.0033\n",
      "Epoch 569: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.7532e-05 - mae: 0.0033 - val_loss: 5.9309e-05 - val_mae: 0.0061\n",
      "Epoch 570/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4878e-05 - mae: 0.0030\n",
      "Epoch 570: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.5388e-05 - mae: 0.0031 - val_loss: 5.0635e-05 - val_mae: 0.0058\n",
      "Epoch 571/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.8543e-05 - mae: 0.0035\n",
      "Epoch 571: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.7969e-05 - mae: 0.0034 - val_loss: 5.0152e-05 - val_mae: 0.0058\n",
      "Epoch 572/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.4359e-05 - mae: 0.0029\n",
      "Epoch 572: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.4320e-05 - mae: 0.0029 - val_loss: 4.6480e-05 - val_mae: 0.0055\n",
      "Epoch 573/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/800 [===========================>..] - ETA: 0s - loss: 1.5525e-05 - mae: 0.0031\n",
      "Epoch 573: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.5315e-05 - mae: 0.0030 - val_loss: 4.6312e-05 - val_mae: 0.0054\n",
      "Epoch 574/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.5319e-05 - mae: 0.0031\n",
      "Epoch 574: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 1.5241e-05 - mae: 0.0031 - val_loss: 4.7311e-05 - val_mae: 0.0055\n",
      "Epoch 575/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.4886e-05 - mae: 0.0031\n",
      "Epoch 575: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 1.4811e-05 - mae: 0.0031 - val_loss: 4.7648e-05 - val_mae: 0.0055\n",
      "Epoch 576/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.4690e-05 - mae: 0.0030\n",
      "Epoch 576: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 1.5209e-05 - mae: 0.0031 - val_loss: 5.6530e-05 - val_mae: 0.0059\n",
      "Epoch 577/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7138e-05 - mae: 0.0032\n",
      "Epoch 577: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.7138e-05 - mae: 0.0032 - val_loss: 4.6259e-05 - val_mae: 0.0054\n",
      "Epoch 578/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7960e-05 - mae: 0.0033\n",
      "Epoch 578: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6629e-05 - mae: 0.0032 - val_loss: 4.8684e-05 - val_mae: 0.0056\n",
      "Epoch 579/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.5377e-05 - mae: 0.0031\n",
      "Epoch 579: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.5341e-05 - mae: 0.0031 - val_loss: 5.2535e-05 - val_mae: 0.0057\n",
      "Epoch 580/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.5309e-05 - mae: 0.0031\n",
      "Epoch 580: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.6157e-05 - mae: 0.0031 - val_loss: 4.7517e-05 - val_mae: 0.0055\n",
      "Epoch 581/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.3556e-05 - mae: 0.0028\n",
      "Epoch 581: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.4234e-05 - mae: 0.0029 - val_loss: 6.1281e-05 - val_mae: 0.0062\n",
      "Epoch 582/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.8043e-05 - mae: 0.0034\n",
      "Epoch 582: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6924e-05 - mae: 0.0033 - val_loss: 4.8285e-05 - val_mae: 0.0056\n",
      "Epoch 583/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4305e-05 - mae: 0.0029\n",
      "Epoch 583: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.5762e-05 - mae: 0.0031 - val_loss: 4.6690e-05 - val_mae: 0.0055\n",
      "Epoch 584/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4763e-05 - mae: 0.0031\n",
      "Epoch 584: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.3912e-05 - mae: 0.0030 - val_loss: 4.8255e-05 - val_mae: 0.0056\n",
      "Epoch 585/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.5754e-05 - mae: 0.0031\n",
      "Epoch 585: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.5106e-05 - mae: 0.0031 - val_loss: 5.3630e-05 - val_mae: 0.0060\n",
      "Epoch 586/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8598e-05 - mae: 0.0034\n",
      "Epoch 586: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8244e-05 - mae: 0.0033 - val_loss: 5.2713e-05 - val_mae: 0.0057\n",
      "Epoch 587/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6790e-05 - mae: 0.0032\n",
      "Epoch 587: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6274e-05 - mae: 0.0032 - val_loss: 4.7051e-05 - val_mae: 0.0055\n",
      "Epoch 588/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3535e-05 - mae: 0.0028\n",
      "Epoch 588: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.5055e-05 - mae: 0.0030 - val_loss: 5.2722e-05 - val_mae: 0.0060\n",
      "Epoch 589/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.5690e-05 - mae: 0.0031\n",
      "Epoch 589: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.5549e-05 - mae: 0.0031 - val_loss: 4.6567e-05 - val_mae: 0.0055\n",
      "Epoch 590/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.5120e-05 - mae: 0.0030\n",
      "Epoch 590: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 1.5219e-05 - mae: 0.0031 - val_loss: 6.2672e-05 - val_mae: 0.0066\n",
      "Epoch 591/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.6310e-05 - mae: 0.0032\n",
      "Epoch 591: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.6432e-05 - mae: 0.0032 - val_loss: 4.7013e-05 - val_mae: 0.0055\n",
      "Epoch 592/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.8663e-05 - mae: 0.0034\n",
      "Epoch 592: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.8914e-05 - mae: 0.0034 - val_loss: 4.5802e-05 - val_mae: 0.0054\n",
      "Epoch 593/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.5522e-05 - mae: 0.0031\n",
      "Epoch 593: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 1.5897e-05 - mae: 0.0031 - val_loss: 5.2294e-05 - val_mae: 0.0058\n",
      "Epoch 594/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.3187e-05 - mae: 0.0028\n",
      "Epoch 594: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.3377e-05 - mae: 0.0028 - val_loss: 4.6216e-05 - val_mae: 0.0054\n",
      "Epoch 595/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.4015e-05 - mae: 0.0029\n",
      "Epoch 595: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 1.4531e-05 - mae: 0.0030 - val_loss: 4.6575e-05 - val_mae: 0.0055\n",
      "Epoch 596/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.6418e-05 - mae: 0.0031\n",
      "Epoch 596: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.6186e-05 - mae: 0.0031 - val_loss: 4.7931e-05 - val_mae: 0.0055\n",
      "Epoch 597/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.8227e-05 - mae: 0.0034\n",
      "Epoch 597: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 1.8162e-05 - mae: 0.0034 - val_loss: 4.6332e-05 - val_mae: 0.0054\n",
      "Epoch 598/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4147e-05 - mae: 0.0029\n",
      "Epoch 598: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.4725e-05 - mae: 0.0030 - val_loss: 4.6552e-05 - val_mae: 0.0055\n",
      "Epoch 599/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.4733e-05 - mae: 0.0030\n",
      "Epoch 599: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.5192e-05 - mae: 0.0031 - val_loss: 4.9447e-05 - val_mae: 0.0057\n",
      "Epoch 600/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.3904e-05 - mae: 0.0029\n",
      "Epoch 600: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.4506e-05 - mae: 0.0030 - val_loss: 4.7135e-05 - val_mae: 0.0055\n",
      "Epoch 601/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.4314e-05 - mae: 0.0029\n",
      "Epoch 601: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.4448e-05 - mae: 0.0030 - val_loss: 4.7717e-05 - val_mae: 0.0056\n",
      "Epoch 602/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6655e-05 - mae: 0.0032\n",
      "Epoch 602: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.6340e-05 - mae: 0.0032 - val_loss: 5.6652e-05 - val_mae: 0.0059\n",
      "Epoch 603/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4848e-05 - mae: 0.0030\n",
      "Epoch 603: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.4986e-05 - mae: 0.0030 - val_loss: 4.7230e-05 - val_mae: 0.0055\n",
      "Epoch 604/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4585e-05 - mae: 0.0030\n",
      "Epoch 604: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.3852e-05 - mae: 0.0029 - val_loss: 4.7106e-05 - val_mae: 0.0055\n",
      "Epoch 605/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.2235e-05 - mae: 0.0027\n",
      "Epoch 605: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.4558e-05 - mae: 0.0030 - val_loss: 4.7236e-05 - val_mae: 0.0055\n",
      "Epoch 606/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.2474e-05 - mae: 0.0028\n",
      "Epoch 606: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.5735e-05 - mae: 0.0031 - val_loss: 5.4085e-05 - val_mae: 0.0058\n",
      "Epoch 607/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6314e-05 - mae: 0.0032\n",
      "Epoch 607: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.7302e-05 - mae: 0.0033 - val_loss: 4.7775e-05 - val_mae: 0.0055\n",
      "Epoch 608/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4211e-05 - mae: 0.0029\n",
      "Epoch 608: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.5677e-05 - mae: 0.0031 - val_loss: 4.9610e-05 - val_mae: 0.0056\n",
      "Epoch 609/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.5756e-05 - mae: 0.0031\n",
      "Epoch 609: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 1.5784e-05 - mae: 0.0031 - val_loss: 4.7300e-05 - val_mae: 0.0055\n",
      "Epoch 610/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.5251e-05 - mae: 0.0031\n",
      "Epoch 610: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.5235e-05 - mae: 0.0031 - val_loss: 5.3925e-05 - val_mae: 0.0058\n",
      "Epoch 611/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7193e-05 - mae: 0.0033\n",
      "Epoch 611: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.5865e-05 - mae: 0.0031 - val_loss: 5.3222e-05 - val_mae: 0.0058\n",
      "Epoch 612/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.5502e-05 - mae: 0.0031\n",
      "Epoch 612: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.5502e-05 - mae: 0.0031 - val_loss: 5.0641e-05 - val_mae: 0.0056\n",
      "Epoch 613/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4594e-05 - mae: 0.0030\n",
      "Epoch 613: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.5182e-05 - mae: 0.0031 - val_loss: 4.7682e-05 - val_mae: 0.0056\n",
      "Epoch 614/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.9209e-05 - mae: 0.0034\n",
      "Epoch 614: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.7410e-05 - mae: 0.0032 - val_loss: 4.7194e-05 - val_mae: 0.0055\n",
      "Epoch 615/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.2982e-05 - mae: 0.0028\n",
      "Epoch 615: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.4931e-05 - mae: 0.0030 - val_loss: 4.7474e-05 - val_mae: 0.0055\n",
      "Epoch 616/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4489e-05 - mae: 0.0030\n",
      "Epoch 616: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.5043e-05 - mae: 0.0030 - val_loss: 4.6365e-05 - val_mae: 0.0054\n",
      "Epoch 617/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5071e-05 - mae: 0.0030\n",
      "Epoch 617: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.6422e-05 - mae: 0.0032 - val_loss: 4.6637e-05 - val_mae: 0.0055\n",
      "Epoch 618/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7185e-05 - mae: 0.0032\n",
      "Epoch 618: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.6847e-05 - mae: 0.0032 - val_loss: 5.2322e-05 - val_mae: 0.0059\n",
      "Epoch 619/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5777e-05 - mae: 0.0031\n",
      "Epoch 619: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.5464e-05 - mae: 0.0030 - val_loss: 6.1339e-05 - val_mae: 0.0062\n",
      "Epoch 620/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6141e-05 - mae: 0.0032\n",
      "Epoch 620: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6438e-05 - mae: 0.0032 - val_loss: 4.9067e-05 - val_mae: 0.0056\n",
      "Epoch 621/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.5076e-05 - mae: 0.0030\n",
      "Epoch 621: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.5076e-05 - mae: 0.0030 - val_loss: 5.5295e-05 - val_mae: 0.0059\n",
      "Epoch 622/1000\n",
      "680/800 [========================>.....] - ETA: 0s - loss: 1.4872e-05 - mae: 0.0030\n",
      "Epoch 622: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 175us/sample - loss: 1.4671e-05 - mae: 0.0030 - val_loss: 4.6564e-05 - val_mae: 0.0055\n",
      "Epoch 623/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.5244e-05 - mae: 0.0031\n",
      "Epoch 623: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 1.5686e-05 - mae: 0.0031 - val_loss: 4.9208e-05 - val_mae: 0.0057\n",
      "Epoch 624/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6169e-05 - mae: 0.0032\n",
      "Epoch 624: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.6720e-05 - mae: 0.0032 - val_loss: 4.8256e-05 - val_mae: 0.0055\n",
      "Epoch 625/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.4805e-05 - mae: 0.0030\n",
      "Epoch 625: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.4610e-05 - mae: 0.0030 - val_loss: 4.7229e-05 - val_mae: 0.0055\n",
      "Epoch 626/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.5275e-05 - mae: 0.0031\n",
      "Epoch 626: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.5206e-05 - mae: 0.0031 - val_loss: 4.7577e-05 - val_mae: 0.0056\n",
      "Epoch 627/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.5767e-05 - mae: 0.0031\n",
      "Epoch 627: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.6009e-05 - mae: 0.0031 - val_loss: 5.1161e-05 - val_mae: 0.0058\n",
      "Epoch 628/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.5507e-05 - mae: 0.0031\n",
      "Epoch 628: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.6061e-05 - mae: 0.0031 - val_loss: 4.6846e-05 - val_mae: 0.0055\n",
      "Epoch 629/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.4692e-05 - mae: 0.0030\n",
      "Epoch 629: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.4797e-05 - mae: 0.0030 - val_loss: 5.1494e-05 - val_mae: 0.0057\n",
      "Epoch 630/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.7121e-05 - mae: 0.0033\n",
      "Epoch 630: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.7026e-05 - mae: 0.0033 - val_loss: 4.9171e-05 - val_mae: 0.0056\n",
      "Epoch 631/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3566e-05 - mae: 0.0029\n",
      "Epoch 631: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.4555e-05 - mae: 0.0030 - val_loss: 4.6972e-05 - val_mae: 0.0055\n",
      "Epoch 632/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3333e-05 - mae: 0.0028\n",
      "Epoch 632: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.5308e-05 - mae: 0.0031 - val_loss: 5.2945e-05 - val_mae: 0.0058\n",
      "Epoch 633/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 1.5093e-05 - mae: 0.0031\n",
      "Epoch 633: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 1.5476e-05 - mae: 0.0031 - val_loss: 5.4648e-05 - val_mae: 0.0058\n",
      "Epoch 634/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.4553e-05 - mae: 0.0030\n",
      "Epoch 634: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.4774e-05 - mae: 0.0030 - val_loss: 4.7408e-05 - val_mae: 0.0055\n",
      "Epoch 635/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 1.5682e-05 - mae: 0.0031\n",
      "Epoch 635: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 1.5832e-05 - mae: 0.0031 - val_loss: 5.0315e-05 - val_mae: 0.0058\n",
      "Epoch 636/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.5269e-05 - mae: 0.0030\n",
      "Epoch 636: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.5388e-05 - mae: 0.0030 - val_loss: 5.3244e-05 - val_mae: 0.0060\n",
      "Epoch 637/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6363e-05 - mae: 0.0031\n",
      "Epoch 637: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.5021e-05 - mae: 0.0030 - val_loss: 5.3795e-05 - val_mae: 0.0058\n",
      "Epoch 638/1000\n",
      "680/800 [========================>.....] - ETA: 0s - loss: 1.5710e-05 - mae: 0.0031\n",
      "Epoch 638: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 178us/sample - loss: 1.5748e-05 - mae: 0.0031 - val_loss: 4.7269e-05 - val_mae: 0.0055\n",
      "Epoch 639/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.7509e-05 - mae: 0.0033\n",
      "Epoch 639: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 1.7422e-05 - mae: 0.0032 - val_loss: 4.7310e-05 - val_mae: 0.0056\n",
      "Epoch 640/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.4691e-05 - mae: 0.0030\n",
      "Epoch 640: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 1.4532e-05 - mae: 0.0030 - val_loss: 4.6955e-05 - val_mae: 0.0055\n",
      "Epoch 641/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.4228e-05 - mae: 0.0029\n",
      "Epoch 641: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 1.4450e-05 - mae: 0.0030 - val_loss: 5.5011e-05 - val_mae: 0.0059\n",
      "Epoch 642/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.5722e-05 - mae: 0.0031\n",
      "Epoch 642: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 1.5574e-05 - mae: 0.0031 - val_loss: 4.6769e-05 - val_mae: 0.0055\n",
      "Epoch 643/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.4379e-05 - mae: 0.0030\n",
      "Epoch 643: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 1.4682e-05 - mae: 0.0030 - val_loss: 4.7061e-05 - val_mae: 0.0055\n",
      "Epoch 644/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.3878e-05 - mae: 0.0029\n",
      "Epoch 644: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.3785e-05 - mae: 0.0029 - val_loss: 4.6626e-05 - val_mae: 0.0055\n",
      "Epoch 645/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.5997e-05 - mae: 0.0032\n",
      "Epoch 645: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 171us/sample - loss: 1.5802e-05 - mae: 0.0032 - val_loss: 4.9487e-05 - val_mae: 0.0057\n",
      "Epoch 646/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.5261e-05 - mae: 0.0031\n",
      "Epoch 646: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 168us/sample - loss: 1.5213e-05 - mae: 0.0030 - val_loss: 4.8529e-05 - val_mae: 0.0056\n",
      "Epoch 647/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4343e-05 - mae: 0.0030\n",
      "Epoch 647: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.5706e-05 - mae: 0.0031 - val_loss: 4.8118e-05 - val_mae: 0.0055\n",
      "Epoch 648/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.3554e-05 - mae: 0.0028\n",
      "Epoch 648: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.5562e-05 - mae: 0.0031 - val_loss: 4.6724e-05 - val_mae: 0.0055\n",
      "Epoch 649/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.4495e-05 - mae: 0.0030\n",
      "Epoch 649: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.4633e-05 - mae: 0.0030 - val_loss: 4.6941e-05 - val_mae: 0.0055\n",
      "Epoch 650/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.3569e-05 - mae: 0.0029\n",
      "Epoch 650: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.3665e-05 - mae: 0.0029 - val_loss: 4.8114e-05 - val_mae: 0.0055\n",
      "Epoch 651/1000\n",
      "380/800 [=============>................] - ETA: 0s - loss: 1.4800e-05 - mae: 0.0031\n",
      "Epoch 651: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.4971e-05 - mae: 0.0030 - val_loss: 5.1165e-05 - val_mae: 0.0056\n",
      "Epoch 652/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5799e-05 - mae: 0.0032\n",
      "Epoch 652: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6511e-05 - mae: 0.0032 - val_loss: 4.7593e-05 - val_mae: 0.0056\n",
      "Epoch 653/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.5106e-05 - mae: 0.0030\n",
      "Epoch 653: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.5157e-05 - mae: 0.0030 - val_loss: 4.9353e-05 - val_mae: 0.0056\n",
      "Epoch 654/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.3739e-05 - mae: 0.0029\n",
      "Epoch 654: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 1.4046e-05 - mae: 0.0029 - val_loss: 7.2594e-05 - val_mae: 0.0068\n",
      "Epoch 655/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6585e-05 - mae: 0.0032\n",
      "Epoch 655: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.6095e-05 - mae: 0.0032 - val_loss: 4.7261e-05 - val_mae: 0.0055\n",
      "Epoch 656/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.7123e-05 - mae: 0.0033\n",
      "Epoch 656: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.7007e-05 - mae: 0.0033 - val_loss: 4.8038e-05 - val_mae: 0.0055\n",
      "Epoch 657/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.3776e-05 - mae: 0.0029\n",
      "Epoch 657: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 174us/sample - loss: 1.4082e-05 - mae: 0.0029 - val_loss: 4.7695e-05 - val_mae: 0.0056\n",
      "Epoch 658/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.6465e-05 - mae: 0.0032\n",
      "Epoch 658: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 1.6314e-05 - mae: 0.0031 - val_loss: 4.7289e-05 - val_mae: 0.0055\n",
      "Epoch 659/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.7158e-05 - mae: 0.0032\n",
      "Epoch 659: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.7058e-05 - mae: 0.0032 - val_loss: 4.6695e-05 - val_mae: 0.0055\n",
      "Epoch 660/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/800 [============================>.] - ETA: 0s - loss: 1.5989e-05 - mae: 0.0032\n",
      "Epoch 660: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.5890e-05 - mae: 0.0031 - val_loss: 4.6955e-05 - val_mae: 0.0055\n",
      "Epoch 661/1000\n",
      "640/800 [=======================>......] - ETA: 0s - loss: 1.4026e-05 - mae: 0.0029\n",
      "Epoch 661: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 185us/sample - loss: 1.4682e-05 - mae: 0.0030 - val_loss: 5.1731e-05 - val_mae: 0.0057\n",
      "Epoch 662/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.6545e-05 - mae: 0.0032\n",
      "Epoch 662: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.6581e-05 - mae: 0.0032 - val_loss: 4.9541e-05 - val_mae: 0.0056\n",
      "Epoch 663/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.3525e-05 - mae: 0.0029\n",
      "Epoch 663: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.6564e-05 - mae: 0.0032 - val_loss: 4.9179e-05 - val_mae: 0.0057\n",
      "Epoch 664/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7830e-05 - mae: 0.0033\n",
      "Epoch 664: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7297e-05 - mae: 0.0033 - val_loss: 4.9702e-05 - val_mae: 0.0056\n",
      "Epoch 665/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.5614e-05 - mae: 0.0031\n",
      "Epoch 665: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.5965e-05 - mae: 0.0032 - val_loss: 4.8312e-05 - val_mae: 0.0056\n",
      "Epoch 666/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.6288e-05 - mae: 0.0032\n",
      "Epoch 666: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 1.6282e-05 - mae: 0.0032 - val_loss: 4.7424e-05 - val_mae: 0.0056\n",
      "Epoch 667/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4069e-05 - mae: 0.0030\n",
      "Epoch 667: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.4215e-05 - mae: 0.0030 - val_loss: 4.6821e-05 - val_mae: 0.0055\n",
      "Epoch 668/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5696e-05 - mae: 0.0031\n",
      "Epoch 668: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.5221e-05 - mae: 0.0030 - val_loss: 4.7183e-05 - val_mae: 0.0055\n",
      "Epoch 669/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.4947e-05 - mae: 0.0030\n",
      "Epoch 669: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.4982e-05 - mae: 0.0030 - val_loss: 4.7935e-05 - val_mae: 0.0055\n",
      "Epoch 670/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.3317e-05 - mae: 0.0028\n",
      "Epoch 670: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.3842e-05 - mae: 0.0029 - val_loss: 5.4857e-05 - val_mae: 0.0058\n",
      "Epoch 671/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.3947e-05 - mae: 0.0029\n",
      "Epoch 671: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.4499e-05 - mae: 0.0030 - val_loss: 4.7219e-05 - val_mae: 0.0055\n",
      "Epoch 672/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4686e-05 - mae: 0.0030\n",
      "Epoch 672: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.4254e-05 - mae: 0.0029 - val_loss: 4.8898e-05 - val_mae: 0.0057\n",
      "Epoch 673/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.2876e-05 - mae: 0.0028\n",
      "Epoch 673: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.5045e-05 - mae: 0.0030 - val_loss: 5.3371e-05 - val_mae: 0.0058\n",
      "Epoch 674/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4582e-05 - mae: 0.0030\n",
      "Epoch 674: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.4170e-05 - mae: 0.0029 - val_loss: 4.7389e-05 - val_mae: 0.0055\n",
      "Epoch 675/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3592e-05 - mae: 0.0029\n",
      "Epoch 675: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.4303e-05 - mae: 0.0029 - val_loss: 4.7936e-05 - val_mae: 0.0055\n",
      "Epoch 676/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.2331e-05 - mae: 0.0027\n",
      "Epoch 676: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.4639e-05 - mae: 0.0030 - val_loss: 4.7239e-05 - val_mae: 0.0055\n",
      "Epoch 677/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.6445e-05 - mae: 0.0032\n",
      "Epoch 677: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.6402e-05 - mae: 0.0032 - val_loss: 4.7094e-05 - val_mae: 0.0055\n",
      "Epoch 678/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.4631e-05 - mae: 0.0030\n",
      "Epoch 678: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.5158e-05 - mae: 0.0031 - val_loss: 7.5553e-05 - val_mae: 0.0069\n",
      "Epoch 679/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5323e-05 - mae: 0.0030\n",
      "Epoch 679: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.4707e-05 - mae: 0.0030 - val_loss: 5.5721e-05 - val_mae: 0.0059\n",
      "Epoch 680/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4520e-05 - mae: 0.0030\n",
      "Epoch 680: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6532e-05 - mae: 0.0032 - val_loss: 6.7645e-05 - val_mae: 0.0065\n",
      "Epoch 681/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7729e-05 - mae: 0.0034\n",
      "Epoch 681: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.6579e-05 - mae: 0.0032 - val_loss: 4.6585e-05 - val_mae: 0.0055\n",
      "Epoch 682/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.7903e-05 - mae: 0.0033\n",
      "Epoch 682: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.5965e-05 - mae: 0.0031 - val_loss: 5.3254e-05 - val_mae: 0.0058\n",
      "Epoch 683/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.4867e-05 - mae: 0.0030\n",
      "Epoch 683: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.4491e-05 - mae: 0.0030 - val_loss: 4.8179e-05 - val_mae: 0.0055\n",
      "Epoch 684/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.3401e-05 - mae: 0.0029\n",
      "Epoch 684: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.4852e-05 - mae: 0.0030 - val_loss: 4.7313e-05 - val_mae: 0.0055\n",
      "Epoch 685/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3191e-05 - mae: 0.0028\n",
      "Epoch 685: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6318e-05 - mae: 0.0032 - val_loss: 4.6910e-05 - val_mae: 0.0055\n",
      "Epoch 686/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6702e-05 - mae: 0.0032\n",
      "Epoch 686: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.5309e-05 - mae: 0.0031 - val_loss: 4.7580e-05 - val_mae: 0.0055\n",
      "Epoch 687/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.3724e-05 - mae: 0.0029\n",
      "Epoch 687: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.4970e-05 - mae: 0.0030 - val_loss: 4.6867e-05 - val_mae: 0.0055\n",
      "Epoch 688/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7536e-05 - mae: 0.0033\n",
      "Epoch 688: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.6970e-05 - mae: 0.0032 - val_loss: 4.8437e-05 - val_mae: 0.0056\n",
      "Epoch 689/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/800 [==============>...............] - ETA: 0s - loss: 1.3806e-05 - mae: 0.0029\n",
      "Epoch 689: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.4819e-05 - mae: 0.0030 - val_loss: 4.9084e-05 - val_mae: 0.0057\n",
      "Epoch 690/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5267e-05 - mae: 0.0031\n",
      "Epoch 690: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.4771e-05 - mae: 0.0030 - val_loss: 4.7255e-05 - val_mae: 0.0055\n",
      "Epoch 691/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.3405e-05 - mae: 0.0028\n",
      "Epoch 691: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.5266e-05 - mae: 0.0030 - val_loss: 4.7514e-05 - val_mae: 0.0055\n",
      "Epoch 692/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.4182e-05 - mae: 0.0029\n",
      "Epoch 692: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.4218e-05 - mae: 0.0029 - val_loss: 4.7334e-05 - val_mae: 0.0055\n",
      "Epoch 693/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 1.4479e-05 - mae: 0.0030\n",
      "Epoch 693: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 192us/sample - loss: 1.4334e-05 - mae: 0.0029 - val_loss: 4.6921e-05 - val_mae: 0.0055\n",
      "Epoch 694/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.3310e-05 - mae: 0.0029\n",
      "Epoch 694: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 1.3813e-05 - mae: 0.0029 - val_loss: 4.8809e-05 - val_mae: 0.0057\n",
      "Epoch 695/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.5868e-05 - mae: 0.0031\n",
      "Epoch 695: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.5952e-05 - mae: 0.0031 - val_loss: 5.2260e-05 - val_mae: 0.0057\n",
      "Epoch 696/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.2370e-05 - mae: 0.0027\n",
      "Epoch 696: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.3827e-05 - mae: 0.0029 - val_loss: 4.7597e-05 - val_mae: 0.0056\n",
      "Epoch 697/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3263e-05 - mae: 0.0028\n",
      "Epoch 697: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.3639e-05 - mae: 0.0028 - val_loss: 4.7556e-05 - val_mae: 0.0055\n",
      "Epoch 698/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5104e-05 - mae: 0.0031\n",
      "Epoch 698: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.5166e-05 - mae: 0.0030 - val_loss: 4.7498e-05 - val_mae: 0.0055\n",
      "Epoch 699/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.4530e-05 - mae: 0.0030\n",
      "Epoch 699: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7092e-05 - mae: 0.0032 - val_loss: 5.5079e-05 - val_mae: 0.0059\n",
      "Epoch 700/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4503e-05 - mae: 0.0030\n",
      "Epoch 700: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.3985e-05 - mae: 0.0029 - val_loss: 4.7523e-05 - val_mae: 0.0055\n",
      "Epoch 701/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.4528e-05 - mae: 0.0030\n",
      "Epoch 701: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6274e-05 - mae: 0.0031 - val_loss: 5.0465e-05 - val_mae: 0.0058\n",
      "Epoch 702/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4968e-05 - mae: 0.0030\n",
      "Epoch 702: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.5224e-05 - mae: 0.0031 - val_loss: 5.2288e-05 - val_mae: 0.0057\n",
      "Epoch 703/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4685e-05 - mae: 0.0030\n",
      "Epoch 703: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.3902e-05 - mae: 0.0029 - val_loss: 4.7614e-05 - val_mae: 0.0055\n",
      "Epoch 704/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.4551e-05 - mae: 0.0030\n",
      "Epoch 704: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 1.4894e-05 - mae: 0.0030 - val_loss: 4.7837e-05 - val_mae: 0.0055\n",
      "Epoch 705/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.4013e-05 - mae: 0.0029\n",
      "Epoch 705: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 1.3719e-05 - mae: 0.0029 - val_loss: 4.8243e-05 - val_mae: 0.0055\n",
      "Epoch 706/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 1.6156e-05 - mae: 0.0032\n",
      "Epoch 706: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 1.7137e-05 - mae: 0.0032 - val_loss: 4.8077e-05 - val_mae: 0.0055\n",
      "Epoch 707/1000\n",
      "580/800 [====================>.........] - ETA: 0s - loss: 1.3926e-05 - mae: 0.0029\n",
      "Epoch 707: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 1.4379e-05 - mae: 0.0030 - val_loss: 4.7517e-05 - val_mae: 0.0055\n",
      "Epoch 708/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.3983e-05 - mae: 0.0029\n",
      "Epoch 708: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.4340e-05 - mae: 0.0030 - val_loss: 4.7550e-05 - val_mae: 0.0055\n",
      "Epoch 709/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.3920e-05 - mae: 0.0029\n",
      "Epoch 709: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.4980e-05 - mae: 0.0030 - val_loss: 5.0509e-05 - val_mae: 0.0057\n",
      "Epoch 710/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4816e-05 - mae: 0.0030\n",
      "Epoch 710: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.4271e-05 - mae: 0.0030 - val_loss: 5.1149e-05 - val_mae: 0.0057\n",
      "Epoch 711/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5637e-05 - mae: 0.0032\n",
      "Epoch 711: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.5187e-05 - mae: 0.0031 - val_loss: 4.7171e-05 - val_mae: 0.0055\n",
      "Epoch 712/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5974e-05 - mae: 0.0032\n",
      "Epoch 712: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.5704e-05 - mae: 0.0031 - val_loss: 5.4264e-05 - val_mae: 0.0061\n",
      "Epoch 713/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.8085e-05 - mae: 0.0035\n",
      "Epoch 713: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.6894e-05 - mae: 0.0033 - val_loss: 5.1819e-05 - val_mae: 0.0059\n",
      "Epoch 714/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.5039e-05 - mae: 0.0031\n",
      "Epoch 714: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 168us/sample - loss: 1.5045e-05 - mae: 0.0031 - val_loss: 6.0486e-05 - val_mae: 0.0064\n",
      "Epoch 715/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.8409e-05 - mae: 0.0034\n",
      "Epoch 715: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 171us/sample - loss: 1.8378e-05 - mae: 0.0034 - val_loss: 4.7182e-05 - val_mae: 0.0055\n",
      "Epoch 716/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.3747e-05 - mae: 0.0029\n",
      "Epoch 716: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 1.3810e-05 - mae: 0.0029 - val_loss: 4.9215e-05 - val_mae: 0.0056\n",
      "Epoch 717/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.5333e-05 - mae: 0.0031\n",
      "Epoch 717: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.5349e-05 - mae: 0.0031 - val_loss: 4.7040e-05 - val_mae: 0.0055\n",
      "Epoch 718/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730/800 [==========================>...] - ETA: 0s - loss: 1.5489e-05 - mae: 0.0031\n",
      "Epoch 718: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 164us/sample - loss: 1.5549e-05 - mae: 0.0031 - val_loss: 4.7133e-05 - val_mae: 0.0055\n",
      "Epoch 719/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.6383e-05 - mae: 0.0032\n",
      "Epoch 719: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 1.6311e-05 - mae: 0.0032 - val_loss: 5.5023e-05 - val_mae: 0.0059\n",
      "Epoch 720/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.4656e-05 - mae: 0.0030\n",
      "Epoch 720: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.4630e-05 - mae: 0.0030 - val_loss: 4.8698e-05 - val_mae: 0.0057\n",
      "Epoch 721/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.3189e-05 - mae: 0.0028\n",
      "Epoch 721: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 172us/sample - loss: 1.3724e-05 - mae: 0.0029 - val_loss: 5.8860e-05 - val_mae: 0.0061\n",
      "Epoch 722/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 1.6260e-05 - mae: 0.0032\n",
      "Epoch 722: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 179us/sample - loss: 1.6098e-05 - mae: 0.0032 - val_loss: 5.4677e-05 - val_mae: 0.0061\n",
      "Epoch 723/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.5713e-05 - mae: 0.0030\n",
      "Epoch 723: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 171us/sample - loss: 1.6091e-05 - mae: 0.0031 - val_loss: 4.7781e-05 - val_mae: 0.0055\n",
      "Epoch 724/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 1.5884e-05 - mae: 0.0031\n",
      "Epoch 724: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 175us/sample - loss: 1.5553e-05 - mae: 0.0031 - val_loss: 4.7983e-05 - val_mae: 0.0056\n",
      "Epoch 725/1000\n",
      "730/800 [==========================>...] - ETA: 0s - loss: 1.4168e-05 - mae: 0.0029\n",
      "Epoch 725: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 1.4061e-05 - mae: 0.0029 - val_loss: 5.1682e-05 - val_mae: 0.0057\n",
      "Epoch 726/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.3451e-05 - mae: 0.0029\n",
      "Epoch 726: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.3412e-05 - mae: 0.0028 - val_loss: 5.8892e-05 - val_mae: 0.0060\n",
      "Epoch 727/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.5731e-05 - mae: 0.0031\n",
      "Epoch 727: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 1.5486e-05 - mae: 0.0031 - val_loss: 4.7539e-05 - val_mae: 0.0055\n",
      "Epoch 728/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 1.4531e-05 - mae: 0.0029\n",
      "Epoch 728: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 176us/sample - loss: 1.4368e-05 - mae: 0.0029 - val_loss: 4.7742e-05 - val_mae: 0.0056\n",
      "Epoch 729/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.4280e-05 - mae: 0.0030\n",
      "Epoch 729: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.3694e-05 - mae: 0.0029 - val_loss: 5.0639e-05 - val_mae: 0.0057\n",
      "Epoch 730/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3534e-05 - mae: 0.0028\n",
      "Epoch 730: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.3887e-05 - mae: 0.0029 - val_loss: 5.0209e-05 - val_mae: 0.0057\n",
      "Epoch 731/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.4684e-05 - mae: 0.0030\n",
      "Epoch 731: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 1.5119e-05 - mae: 0.0030 - val_loss: 4.7720e-05 - val_mae: 0.0055\n",
      "Epoch 732/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.1927e-05 - mae: 0.0027\n",
      "Epoch 732: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.4374e-05 - mae: 0.0030 - val_loss: 4.9665e-05 - val_mae: 0.0058\n",
      "Epoch 733/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.4076e-05 - mae: 0.0029\n",
      "Epoch 733: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 1.3827e-05 - mae: 0.0029 - val_loss: 5.1630e-05 - val_mae: 0.0057\n",
      "Epoch 734/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.6084e-05 - mae: 0.0031\n",
      "Epoch 734: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 163us/sample - loss: 1.6031e-05 - mae: 0.0031 - val_loss: 4.8367e-05 - val_mae: 0.0055\n",
      "Epoch 735/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.2301e-05 - mae: 0.0027\n",
      "Epoch 735: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.3715e-05 - mae: 0.0029 - val_loss: 5.0323e-05 - val_mae: 0.0058\n",
      "Epoch 736/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4525e-05 - mae: 0.0030\n",
      "Epoch 736: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.4289e-05 - mae: 0.0029 - val_loss: 5.0582e-05 - val_mae: 0.0056\n",
      "Epoch 737/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3420e-05 - mae: 0.0028\n",
      "Epoch 737: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6037e-05 - mae: 0.0031 - val_loss: 4.8490e-05 - val_mae: 0.0057\n",
      "Epoch 738/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4085e-05 - mae: 0.0030\n",
      "Epoch 738: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.4126e-05 - mae: 0.0029 - val_loss: 5.5745e-05 - val_mae: 0.0059\n",
      "Epoch 739/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6395e-05 - mae: 0.0031\n",
      "Epoch 739: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6362e-05 - mae: 0.0031 - val_loss: 4.8463e-05 - val_mae: 0.0056\n",
      "Epoch 740/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.4665e-05 - mae: 0.0030\n",
      "Epoch 740: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 1.4589e-05 - mae: 0.0030 - val_loss: 5.0792e-05 - val_mae: 0.0057\n",
      "Epoch 741/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.3344e-05 - mae: 0.0029\n",
      "Epoch 741: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 1.3546e-05 - mae: 0.0029 - val_loss: 5.2746e-05 - val_mae: 0.0060\n",
      "Epoch 742/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.2733e-05 - mae: 0.0028\n",
      "Epoch 742: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.4182e-05 - mae: 0.0030 - val_loss: 5.3994e-05 - val_mae: 0.0060\n",
      "Epoch 743/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4129e-05 - mae: 0.0028\n",
      "Epoch 743: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.4941e-05 - mae: 0.0030 - val_loss: 5.1148e-05 - val_mae: 0.0057\n",
      "Epoch 744/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6533e-05 - mae: 0.0032\n",
      "Epoch 744: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6573e-05 - mae: 0.0032 - val_loss: 5.0557e-05 - val_mae: 0.0058\n",
      "Epoch 745/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.4087e-05 - mae: 0.0030\n",
      "Epoch 745: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.4688e-05 - mae: 0.0030 - val_loss: 4.8188e-05 - val_mae: 0.0056\n",
      "Epoch 746/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6057e-05 - mae: 0.0031\n",
      "Epoch 746: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.6240e-05 - mae: 0.0032 - val_loss: 5.1750e-05 - val_mae: 0.0057\n",
      "Epoch 747/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/800 [==============>...............] - ETA: 0s - loss: 1.3464e-05 - mae: 0.0028\n",
      "Epoch 747: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.4307e-05 - mae: 0.0029 - val_loss: 5.0352e-05 - val_mae: 0.0058\n",
      "Epoch 748/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5241e-05 - mae: 0.0031\n",
      "Epoch 748: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.4587e-05 - mae: 0.0030 - val_loss: 4.9939e-05 - val_mae: 0.0056\n",
      "Epoch 749/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.5228e-05 - mae: 0.0031\n",
      "Epoch 749: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.5158e-05 - mae: 0.0031 - val_loss: 4.7690e-05 - val_mae: 0.0055\n",
      "Epoch 750/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.4396e-05 - mae: 0.0030\n",
      "Epoch 750: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.4458e-05 - mae: 0.0030 - val_loss: 4.7663e-05 - val_mae: 0.0056\n",
      "Epoch 751/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.3659e-05 - mae: 0.0029\n",
      "Epoch 751: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.4381e-05 - mae: 0.0030 - val_loss: 4.7301e-05 - val_mae: 0.0055\n",
      "Epoch 752/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4615e-05 - mae: 0.0030\n",
      "Epoch 752: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.5376e-05 - mae: 0.0031 - val_loss: 6.7244e-05 - val_mae: 0.0065\n",
      "Epoch 753/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4535e-05 - mae: 0.0030\n",
      "Epoch 753: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.5887e-05 - mae: 0.0032 - val_loss: 4.8378e-05 - val_mae: 0.0055\n",
      "Epoch 754/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.3734e-05 - mae: 0.0029\n",
      "Epoch 754: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.3734e-05 - mae: 0.0029 - val_loss: 4.7804e-05 - val_mae: 0.0056\n",
      "Epoch 755/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6492e-05 - mae: 0.0032\n",
      "Epoch 755: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.6727e-05 - mae: 0.0032 - val_loss: 4.8202e-05 - val_mae: 0.0056\n",
      "Epoch 756/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.4150e-05 - mae: 0.0029\n",
      "Epoch 756: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.3681e-05 - mae: 0.0029 - val_loss: 4.7280e-05 - val_mae: 0.0056\n",
      "Epoch 757/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4064e-05 - mae: 0.0029\n",
      "Epoch 757: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.4832e-05 - mae: 0.0030 - val_loss: 4.7540e-05 - val_mae: 0.0055\n",
      "Epoch 758/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.3095e-05 - mae: 0.0028\n",
      "Epoch 758: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 170us/sample - loss: 1.3565e-05 - mae: 0.0029 - val_loss: 5.1254e-05 - val_mae: 0.0057\n",
      "Epoch 759/1000\n",
      "680/800 [========================>.....] - ETA: 0s - loss: 1.4568e-05 - mae: 0.0030\n",
      "Epoch 759: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 168us/sample - loss: 1.4213e-05 - mae: 0.0029 - val_loss: 4.7863e-05 - val_mae: 0.0055\n",
      "Epoch 760/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4616e-05 - mae: 0.0029\n",
      "Epoch 760: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.3751e-05 - mae: 0.0029 - val_loss: 4.8211e-05 - val_mae: 0.0056\n",
      "Epoch 761/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.3935e-05 - mae: 0.0029\n",
      "Epoch 761: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.5831e-05 - mae: 0.0031 - val_loss: 5.0032e-05 - val_mae: 0.0056\n",
      "Epoch 762/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3720e-05 - mae: 0.0029\n",
      "Epoch 762: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.4240e-05 - mae: 0.0029 - val_loss: 4.8075e-05 - val_mae: 0.0055\n",
      "Epoch 763/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.3300e-05 - mae: 0.0028\n",
      "Epoch 763: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.4207e-05 - mae: 0.0029 - val_loss: 4.7781e-05 - val_mae: 0.0055\n",
      "Epoch 764/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6477e-05 - mae: 0.0032\n",
      "Epoch 764: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.5637e-05 - mae: 0.0031 - val_loss: 4.7475e-05 - val_mae: 0.0055\n",
      "Epoch 765/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.6413e-05 - mae: 0.0032\n",
      "Epoch 765: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.5219e-05 - mae: 0.0030 - val_loss: 4.7571e-05 - val_mae: 0.0056\n",
      "Epoch 766/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4024e-05 - mae: 0.0029\n",
      "Epoch 766: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.5019e-05 - mae: 0.0030 - val_loss: 4.8007e-05 - val_mae: 0.0056\n",
      "Epoch 767/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.2492e-05 - mae: 0.0027\n",
      "Epoch 767: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.3175e-05 - mae: 0.0028 - val_loss: 4.7872e-05 - val_mae: 0.0056\n",
      "Epoch 768/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4197e-05 - mae: 0.0029\n",
      "Epoch 768: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.3942e-05 - mae: 0.0029 - val_loss: 4.7711e-05 - val_mae: 0.0055\n",
      "Epoch 769/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4956e-05 - mae: 0.0031\n",
      "Epoch 769: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.4938e-05 - mae: 0.0030 - val_loss: 4.9257e-05 - val_mae: 0.0057\n",
      "Epoch 770/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.3460e-05 - mae: 0.0029\n",
      "Epoch 770: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.3890e-05 - mae: 0.0029 - val_loss: 4.7578e-05 - val_mae: 0.0055\n",
      "Epoch 771/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.3418e-05 - mae: 0.0029\n",
      "Epoch 771: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.3630e-05 - mae: 0.0029 - val_loss: 4.7807e-05 - val_mae: 0.0056\n",
      "Epoch 772/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4053e-05 - mae: 0.0029\n",
      "Epoch 772: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.3795e-05 - mae: 0.0029 - val_loss: 4.8537e-05 - val_mae: 0.0056\n",
      "Epoch 773/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4805e-05 - mae: 0.0029\n",
      "Epoch 773: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.4767e-05 - mae: 0.0030 - val_loss: 5.0869e-05 - val_mae: 0.0057\n",
      "Epoch 774/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5668e-05 - mae: 0.0031\n",
      "Epoch 774: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.5608e-05 - mae: 0.0031 - val_loss: 4.8382e-05 - val_mae: 0.0056\n",
      "Epoch 775/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4541e-05 - mae: 0.0029\n",
      "Epoch 775: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.5921e-05 - mae: 0.0031 - val_loss: 4.9171e-05 - val_mae: 0.0056\n",
      "Epoch 776/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3502e-05 - mae: 0.0029\n",
      "Epoch 776: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.4389e-05 - mae: 0.0029 - val_loss: 4.7439e-05 - val_mae: 0.0055\n",
      "Epoch 777/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3308e-05 - mae: 0.0028\n",
      "Epoch 777: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6133e-05 - mae: 0.0031 - val_loss: 4.9187e-05 - val_mae: 0.0056\n",
      "Epoch 778/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5475e-05 - mae: 0.0031\n",
      "Epoch 778: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.5429e-05 - mae: 0.0030 - val_loss: 5.8365e-05 - val_mae: 0.0060\n",
      "Epoch 779/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.3679e-05 - mae: 0.0029\n",
      "Epoch 779: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.4317e-05 - mae: 0.0029 - val_loss: 4.9106e-05 - val_mae: 0.0056\n",
      "Epoch 780/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4207e-05 - mae: 0.0030\n",
      "Epoch 780: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.4007e-05 - mae: 0.0029 - val_loss: 5.4271e-05 - val_mae: 0.0058\n",
      "Epoch 781/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7400e-05 - mae: 0.0032\n",
      "Epoch 781: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.5573e-05 - mae: 0.0031 - val_loss: 5.2725e-05 - val_mae: 0.0058\n",
      "Epoch 782/1000\n",
      "700/800 [=========================>....] - ETA: 0s - loss: 1.4508e-05 - mae: 0.0029\n",
      "Epoch 782: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 1.4185e-05 - mae: 0.0029 - val_loss: 4.7978e-05 - val_mae: 0.0056\n",
      "Epoch 783/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.6098e-05 - mae: 0.0032\n",
      "Epoch 783: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.5695e-05 - mae: 0.0031 - val_loss: 5.6331e-05 - val_mae: 0.0062\n",
      "Epoch 784/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.6660e-05 - mae: 0.0032\n",
      "Epoch 784: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 161us/sample - loss: 1.6566e-05 - mae: 0.0032 - val_loss: 5.0407e-05 - val_mae: 0.0056\n",
      "Epoch 785/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.5359e-05 - mae: 0.0031\n",
      "Epoch 785: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.5354e-05 - mae: 0.0031 - val_loss: 4.8398e-05 - val_mae: 0.0056\n",
      "Epoch 786/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6601e-05 - mae: 0.0032\n",
      "Epoch 786: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.5685e-05 - mae: 0.0031 - val_loss: 6.2114e-05 - val_mae: 0.0062\n",
      "Epoch 787/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6319e-05 - mae: 0.0032\n",
      "Epoch 787: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.4968e-05 - mae: 0.0030 - val_loss: 5.0926e-05 - val_mae: 0.0057\n",
      "Epoch 788/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3871e-05 - mae: 0.0029\n",
      "Epoch 788: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.4015e-05 - mae: 0.0029 - val_loss: 4.8030e-05 - val_mae: 0.0056\n",
      "Epoch 789/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.5754e-05 - mae: 0.0031\n",
      "Epoch 789: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.5435e-05 - mae: 0.0031 - val_loss: 4.8400e-05 - val_mae: 0.0056\n",
      "Epoch 790/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5242e-05 - mae: 0.0030\n",
      "Epoch 790: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.5295e-05 - mae: 0.0031 - val_loss: 5.0437e-05 - val_mae: 0.0056\n",
      "Epoch 791/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.3441e-05 - mae: 0.0029\n",
      "Epoch 791: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.4141e-05 - mae: 0.0029 - val_loss: 4.8535e-05 - val_mae: 0.0055\n",
      "Epoch 792/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4943e-05 - mae: 0.0031\n",
      "Epoch 792: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.4046e-05 - mae: 0.0030 - val_loss: 4.9033e-05 - val_mae: 0.0056\n",
      "Epoch 793/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.4868e-05 - mae: 0.0030\n",
      "Epoch 793: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 1.4871e-05 - mae: 0.0030 - val_loss: 4.9042e-05 - val_mae: 0.0057\n",
      "Epoch 794/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.3529e-05 - mae: 0.0028\n",
      "Epoch 794: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 1.3350e-05 - mae: 0.0028 - val_loss: 4.8516e-05 - val_mae: 0.0055\n",
      "Epoch 795/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3390e-05 - mae: 0.0029\n",
      "Epoch 795: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.3680e-05 - mae: 0.0029 - val_loss: 4.8063e-05 - val_mae: 0.0055\n",
      "Epoch 796/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.2198e-05 - mae: 0.0027\n",
      "Epoch 796: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.5031e-05 - mae: 0.0030 - val_loss: 5.0604e-05 - val_mae: 0.0056\n",
      "Epoch 797/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4742e-05 - mae: 0.0030\n",
      "Epoch 797: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.5655e-05 - mae: 0.0031 - val_loss: 5.1518e-05 - val_mae: 0.0059\n",
      "Epoch 798/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4630e-05 - mae: 0.0030\n",
      "Epoch 798: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.3889e-05 - mae: 0.0029 - val_loss: 4.7894e-05 - val_mae: 0.0055\n",
      "Epoch 799/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.2543e-05 - mae: 0.0028\n",
      "Epoch 799: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.3922e-05 - mae: 0.0029 - val_loss: 4.7862e-05 - val_mae: 0.0056\n",
      "Epoch 800/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.3366e-05 - mae: 0.0028\n",
      "Epoch 800: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.4276e-05 - mae: 0.0030 - val_loss: 4.8121e-05 - val_mae: 0.0056\n",
      "Epoch 801/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5310e-05 - mae: 0.0031\n",
      "Epoch 801: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.4106e-05 - mae: 0.0029 - val_loss: 4.8244e-05 - val_mae: 0.0056\n",
      "Epoch 802/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.4512e-05 - mae: 0.0030\n",
      "Epoch 802: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.5036e-05 - mae: 0.0030 - val_loss: 4.8342e-05 - val_mae: 0.0056\n",
      "Epoch 803/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.3873e-05 - mae: 0.0029\n",
      "Epoch 803: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.6473e-05 - mae: 0.0031 - val_loss: 5.8750e-05 - val_mae: 0.0061\n",
      "Epoch 804/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6631e-05 - mae: 0.0032\n",
      "Epoch 804: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.5981e-05 - mae: 0.0031 - val_loss: 5.1406e-05 - val_mae: 0.0059\n",
      "Epoch 805/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/800 [================>.............] - ETA: 0s - loss: 1.4671e-05 - mae: 0.0030\n",
      "Epoch 805: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.4667e-05 - mae: 0.0030 - val_loss: 4.9364e-05 - val_mae: 0.0057\n",
      "Epoch 806/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3658e-05 - mae: 0.0029\n",
      "Epoch 806: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.4265e-05 - mae: 0.0030 - val_loss: 4.8820e-05 - val_mae: 0.0056\n",
      "Epoch 807/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.2830e-05 - mae: 0.0028\n",
      "Epoch 807: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.3514e-05 - mae: 0.0029 - val_loss: 4.9289e-05 - val_mae: 0.0057\n",
      "Epoch 808/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4466e-05 - mae: 0.0030\n",
      "Epoch 808: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.3898e-05 - mae: 0.0029 - val_loss: 5.1591e-05 - val_mae: 0.0057\n",
      "Epoch 809/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4654e-05 - mae: 0.0030\n",
      "Epoch 809: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.4180e-05 - mae: 0.0030 - val_loss: 4.8886e-05 - val_mae: 0.0056\n",
      "Epoch 810/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.3012e-05 - mae: 0.0028\n",
      "Epoch 810: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.5412e-05 - mae: 0.0031 - val_loss: 4.7887e-05 - val_mae: 0.0055\n",
      "Epoch 811/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.3744e-05 - mae: 0.0029\n",
      "Epoch 811: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.3623e-05 - mae: 0.0028 - val_loss: 4.7817e-05 - val_mae: 0.0056\n",
      "Epoch 812/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.2405e-05 - mae: 0.0028\n",
      "Epoch 812: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.3957e-05 - mae: 0.0029 - val_loss: 5.1046e-05 - val_mae: 0.0059\n",
      "Epoch 813/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5225e-05 - mae: 0.0031\n",
      "Epoch 813: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.5292e-05 - mae: 0.0031 - val_loss: 5.0622e-05 - val_mae: 0.0057\n",
      "Epoch 814/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4176e-05 - mae: 0.0029\n",
      "Epoch 814: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.4368e-05 - mae: 0.0029 - val_loss: 4.8642e-05 - val_mae: 0.0057\n",
      "Epoch 815/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.5781e-05 - mae: 0.0031\n",
      "Epoch 815: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.5520e-05 - mae: 0.0031 - val_loss: 4.8942e-05 - val_mae: 0.0057\n",
      "Epoch 816/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 2.3074e-05 - mae: 0.0038\n",
      "Epoch 816: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.8101e-05 - mae: 0.0033 - val_loss: 5.0846e-05 - val_mae: 0.0058\n",
      "Epoch 817/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.3407e-05 - mae: 0.0028\n",
      "Epoch 817: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.4206e-05 - mae: 0.0030 - val_loss: 4.8600e-05 - val_mae: 0.0056\n",
      "Epoch 818/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4576e-05 - mae: 0.0030\n",
      "Epoch 818: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.4380e-05 - mae: 0.0030 - val_loss: 4.9907e-05 - val_mae: 0.0056\n",
      "Epoch 819/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4400e-05 - mae: 0.0030\n",
      "Epoch 819: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.4164e-05 - mae: 0.0029 - val_loss: 4.8918e-05 - val_mae: 0.0056\n",
      "Epoch 820/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3089e-05 - mae: 0.0028\n",
      "Epoch 820: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.3990e-05 - mae: 0.0029 - val_loss: 5.4700e-05 - val_mae: 0.0059\n",
      "Epoch 821/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.4097e-05 - mae: 0.0029\n",
      "Epoch 821: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.4066e-05 - mae: 0.0029 - val_loss: 4.8362e-05 - val_mae: 0.0056\n",
      "Epoch 822/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6267e-05 - mae: 0.0032\n",
      "Epoch 822: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.4485e-05 - mae: 0.0030 - val_loss: 4.9585e-05 - val_mae: 0.0056\n",
      "Epoch 823/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.5847e-05 - mae: 0.0031\n",
      "Epoch 823: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.5847e-05 - mae: 0.0031 - val_loss: 4.9233e-05 - val_mae: 0.0057\n",
      "Epoch 824/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.3881e-05 - mae: 0.0029\n",
      "Epoch 824: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.4529e-05 - mae: 0.0029 - val_loss: 4.9820e-05 - val_mae: 0.0056\n",
      "Epoch 825/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.5509e-05 - mae: 0.0031\n",
      "Epoch 825: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.5509e-05 - mae: 0.0031 - val_loss: 5.3094e-05 - val_mae: 0.0060\n",
      "Epoch 826/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.4697e-05 - mae: 0.0030\n",
      "Epoch 826: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.4697e-05 - mae: 0.0030 - val_loss: 5.0275e-05 - val_mae: 0.0058\n",
      "Epoch 827/1000\n",
      "710/800 [=========================>....] - ETA: 0s - loss: 1.2796e-05 - mae: 0.0028\n",
      "Epoch 827: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 167us/sample - loss: 1.3135e-05 - mae: 0.0028 - val_loss: 4.8318e-05 - val_mae: 0.0056\n",
      "Epoch 828/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.3135e-05 - mae: 0.0028\n",
      "Epoch 828: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.4420e-05 - mae: 0.0029 - val_loss: 4.8333e-05 - val_mae: 0.0056\n",
      "Epoch 829/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.3063e-05 - mae: 0.0028\n",
      "Epoch 829: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.4311e-05 - mae: 0.0029 - val_loss: 4.9176e-05 - val_mae: 0.0056\n",
      "Epoch 830/1000\n",
      "750/800 [===========================>..] - ETA: 0s - loss: 1.3546e-05 - mae: 0.0029\n",
      "Epoch 830: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 165us/sample - loss: 1.3578e-05 - mae: 0.0029 - val_loss: 5.1671e-05 - val_mae: 0.0059\n",
      "Epoch 831/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.7007e-05 - mae: 0.0032\n",
      "Epoch 831: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 1.7055e-05 - mae: 0.0032 - val_loss: 5.0278e-05 - val_mae: 0.0057\n",
      "Epoch 832/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4164e-05 - mae: 0.0030\n",
      "Epoch 832: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.4814e-05 - mae: 0.0030 - val_loss: 4.8917e-05 - val_mae: 0.0057\n",
      "Epoch 833/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4001e-05 - mae: 0.0029\n",
      "Epoch 833: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.4452e-05 - mae: 0.0030 - val_loss: 4.8678e-05 - val_mae: 0.0057\n",
      "Epoch 834/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/800 [=================>............] - ETA: 0s - loss: 1.2969e-05 - mae: 0.0028\n",
      "Epoch 834: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.3264e-05 - mae: 0.0028 - val_loss: 4.8262e-05 - val_mae: 0.0056\n",
      "Epoch 835/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.2247e-05 - mae: 0.0027\n",
      "Epoch 835: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.3363e-05 - mae: 0.0028 - val_loss: 5.8077e-05 - val_mae: 0.0063\n",
      "Epoch 836/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4507e-05 - mae: 0.0029\n",
      "Epoch 836: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.4059e-05 - mae: 0.0029 - val_loss: 5.0942e-05 - val_mae: 0.0057\n",
      "Epoch 837/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5708e-05 - mae: 0.0031\n",
      "Epoch 837: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7378e-05 - mae: 0.0032 - val_loss: 4.8702e-05 - val_mae: 0.0056\n",
      "Epoch 838/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4321e-05 - mae: 0.0029\n",
      "Epoch 838: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.3685e-05 - mae: 0.0028 - val_loss: 4.8291e-05 - val_mae: 0.0056\n",
      "Epoch 839/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.3348e-05 - mae: 0.0028\n",
      "Epoch 839: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.2985e-05 - mae: 0.0028 - val_loss: 5.2109e-05 - val_mae: 0.0057\n",
      "Epoch 840/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5842e-05 - mae: 0.0031\n",
      "Epoch 840: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.5775e-05 - mae: 0.0031 - val_loss: 5.0081e-05 - val_mae: 0.0058\n",
      "Epoch 841/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.6237e-05 - mae: 0.0032\n",
      "Epoch 841: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.6350e-05 - mae: 0.0032 - val_loss: 5.1308e-05 - val_mae: 0.0057\n",
      "Epoch 842/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4349e-05 - mae: 0.0030\n",
      "Epoch 842: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.3738e-05 - mae: 0.0029 - val_loss: 4.8829e-05 - val_mae: 0.0056\n",
      "Epoch 843/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.2612e-05 - mae: 0.0028\n",
      "Epoch 843: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.3949e-05 - mae: 0.0029 - val_loss: 4.9031e-05 - val_mae: 0.0056\n",
      "Epoch 844/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.1746e-05 - mae: 0.0027\n",
      "Epoch 844: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.3240e-05 - mae: 0.0028 - val_loss: 5.0641e-05 - val_mae: 0.0058\n",
      "Epoch 845/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7541e-05 - mae: 0.0033\n",
      "Epoch 845: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.5990e-05 - mae: 0.0032 - val_loss: 4.8356e-05 - val_mae: 0.0056\n",
      "Epoch 846/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4254e-05 - mae: 0.0029\n",
      "Epoch 846: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.4027e-05 - mae: 0.0029 - val_loss: 4.8880e-05 - val_mae: 0.0056\n",
      "Epoch 847/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.1438e-05 - mae: 0.0026\n",
      "Epoch 847: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.2952e-05 - mae: 0.0028 - val_loss: 5.7387e-05 - val_mae: 0.0063\n",
      "Epoch 848/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.5756e-05 - mae: 0.0031\n",
      "Epoch 848: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.5710e-05 - mae: 0.0031 - val_loss: 5.0480e-05 - val_mae: 0.0056\n",
      "Epoch 849/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.2820e-05 - mae: 0.0028\n",
      "Epoch 849: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.4235e-05 - mae: 0.0029 - val_loss: 4.9661e-05 - val_mae: 0.0056\n",
      "Epoch 850/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4090e-05 - mae: 0.0030\n",
      "Epoch 850: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.3651e-05 - mae: 0.0029 - val_loss: 4.9060e-05 - val_mae: 0.0057\n",
      "Epoch 851/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.2500e-05 - mae: 0.0027\n",
      "Epoch 851: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.3204e-05 - mae: 0.0028 - val_loss: 4.8676e-05 - val_mae: 0.0056\n",
      "Epoch 852/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.2520e-05 - mae: 0.0028\n",
      "Epoch 852: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.4177e-05 - mae: 0.0029 - val_loss: 5.3932e-05 - val_mae: 0.0058\n",
      "Epoch 853/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.2323e-05 - mae: 0.0027\n",
      "Epoch 853: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.3696e-05 - mae: 0.0029 - val_loss: 5.0498e-05 - val_mae: 0.0056\n",
      "Epoch 854/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.8549e-05 - mae: 0.0035\n",
      "Epoch 854: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6254e-05 - mae: 0.0032 - val_loss: 4.8912e-05 - val_mae: 0.0056\n",
      "Epoch 855/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3698e-05 - mae: 0.0028\n",
      "Epoch 855: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.3868e-05 - mae: 0.0029 - val_loss: 5.1304e-05 - val_mae: 0.0057\n",
      "Epoch 856/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4296e-05 - mae: 0.0030\n",
      "Epoch 856: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.5270e-05 - mae: 0.0030 - val_loss: 6.1653e-05 - val_mae: 0.0065\n",
      "Epoch 857/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7483e-05 - mae: 0.0033\n",
      "Epoch 857: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.6141e-05 - mae: 0.0032 - val_loss: 5.0205e-05 - val_mae: 0.0056\n",
      "Epoch 858/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.3563e-05 - mae: 0.0028\n",
      "Epoch 858: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.4739e-05 - mae: 0.0030 - val_loss: 4.9079e-05 - val_mae: 0.0056\n",
      "Epoch 859/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4087e-05 - mae: 0.0030\n",
      "Epoch 859: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.4766e-05 - mae: 0.0030 - val_loss: 4.9042e-05 - val_mae: 0.0056\n",
      "Epoch 860/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.2789e-05 - mae: 0.0028\n",
      "Epoch 860: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.3826e-05 - mae: 0.0028 - val_loss: 5.3129e-05 - val_mae: 0.0058\n",
      "Epoch 861/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3933e-05 - mae: 0.0029\n",
      "Epoch 861: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.5439e-05 - mae: 0.0031 - val_loss: 5.0846e-05 - val_mae: 0.0056\n",
      "Epoch 862/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.2427e-05 - mae: 0.0027\n",
      "Epoch 862: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 1.3224e-05 - mae: 0.0028 - val_loss: 5.0089e-05 - val_mae: 0.0058\n",
      "Epoch 863/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520/800 [==================>...........] - ETA: 0s - loss: 1.5089e-05 - mae: 0.0030\n",
      "Epoch 863: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.5879e-05 - mae: 0.0031 - val_loss: 4.9830e-05 - val_mae: 0.0056\n",
      "Epoch 864/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.6645e-05 - mae: 0.0032\n",
      "Epoch 864: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.6812e-05 - mae: 0.0033 - val_loss: 4.8778e-05 - val_mae: 0.0057\n",
      "Epoch 865/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.2520e-05 - mae: 0.0027\n",
      "Epoch 865: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.3297e-05 - mae: 0.0028 - val_loss: 5.7030e-05 - val_mae: 0.0062\n",
      "Epoch 866/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.4297e-05 - mae: 0.0030\n",
      "Epoch 866: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 1.4663e-05 - mae: 0.0030 - val_loss: 5.0524e-05 - val_mae: 0.0058\n",
      "Epoch 867/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.3179e-05 - mae: 0.0028\n",
      "Epoch 867: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.3227e-05 - mae: 0.0028 - val_loss: 4.8708e-05 - val_mae: 0.0056\n",
      "Epoch 868/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.1026e-05 - mae: 0.0026\n",
      "Epoch 868: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.3641e-05 - mae: 0.0028 - val_loss: 4.9370e-05 - val_mae: 0.0057\n",
      "Epoch 869/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.2702e-05 - mae: 0.0028\n",
      "Epoch 869: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.3923e-05 - mae: 0.0029 - val_loss: 5.0311e-05 - val_mae: 0.0058\n",
      "Epoch 870/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5658e-05 - mae: 0.0031\n",
      "Epoch 870: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.5667e-05 - mae: 0.0031 - val_loss: 5.2869e-05 - val_mae: 0.0057\n",
      "Epoch 871/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4929e-05 - mae: 0.0031\n",
      "Epoch 871: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.4334e-05 - mae: 0.0030 - val_loss: 5.0511e-05 - val_mae: 0.0058\n",
      "Epoch 872/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5409e-05 - mae: 0.0031\n",
      "Epoch 872: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.5342e-05 - mae: 0.0031 - val_loss: 4.8416e-05 - val_mae: 0.0056\n",
      "Epoch 873/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4980e-05 - mae: 0.0031\n",
      "Epoch 873: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.4452e-05 - mae: 0.0030 - val_loss: 5.8680e-05 - val_mae: 0.0064\n",
      "Epoch 874/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9274e-05 - mae: 0.0035\n",
      "Epoch 874: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7911e-05 - mae: 0.0034 - val_loss: 5.4944e-05 - val_mae: 0.0061\n",
      "Epoch 875/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4392e-05 - mae: 0.0030\n",
      "Epoch 875: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.3932e-05 - mae: 0.0029 - val_loss: 4.8268e-05 - val_mae: 0.0055\n",
      "Epoch 876/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3190e-05 - mae: 0.0028\n",
      "Epoch 876: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.3398e-05 - mae: 0.0028 - val_loss: 4.9374e-05 - val_mae: 0.0055\n",
      "Epoch 877/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.3635e-05 - mae: 0.0029\n",
      "Epoch 877: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.3924e-05 - mae: 0.0029 - val_loss: 4.9244e-05 - val_mae: 0.0056\n",
      "Epoch 878/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3896e-05 - mae: 0.0029\n",
      "Epoch 878: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.3331e-05 - mae: 0.0028 - val_loss: 4.9457e-05 - val_mae: 0.0057\n",
      "Epoch 879/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4499e-05 - mae: 0.0029\n",
      "Epoch 879: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.7008e-05 - mae: 0.0033 - val_loss: 4.8191e-05 - val_mae: 0.0056\n",
      "Epoch 880/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.3770e-05 - mae: 0.0029\n",
      "Epoch 880: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.3263e-05 - mae: 0.0028 - val_loss: 5.2535e-05 - val_mae: 0.0057\n",
      "Epoch 881/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.3286e-05 - mae: 0.0029\n",
      "Epoch 881: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.4915e-05 - mae: 0.0030 - val_loss: 4.8381e-05 - val_mae: 0.0056\n",
      "Epoch 882/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4083e-05 - mae: 0.0029\n",
      "Epoch 882: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.3934e-05 - mae: 0.0029 - val_loss: 4.9001e-05 - val_mae: 0.0057\n",
      "Epoch 883/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3420e-05 - mae: 0.0028\n",
      "Epoch 883: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.3448e-05 - mae: 0.0028 - val_loss: 4.8303e-05 - val_mae: 0.0056\n",
      "Epoch 884/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.3846e-05 - mae: 0.0029\n",
      "Epoch 884: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.5032e-05 - mae: 0.0030 - val_loss: 5.1462e-05 - val_mae: 0.0057\n",
      "Epoch 885/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.1001e-05 - mae: 0.0026\n",
      "Epoch 885: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.4245e-05 - mae: 0.0029 - val_loss: 5.5864e-05 - val_mae: 0.0062\n",
      "Epoch 886/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5350e-05 - mae: 0.0031\n",
      "Epoch 886: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.5140e-05 - mae: 0.0031 - val_loss: 5.3828e-05 - val_mae: 0.0061\n",
      "Epoch 887/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.4008e-05 - mae: 0.0029\n",
      "Epoch 887: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.4366e-05 - mae: 0.0029 - val_loss: 5.1165e-05 - val_mae: 0.0056\n",
      "Epoch 888/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.4156e-05 - mae: 0.0029\n",
      "Epoch 888: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.5433e-05 - mae: 0.0031 - val_loss: 5.0858e-05 - val_mae: 0.0056\n",
      "Epoch 889/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.3909e-05 - mae: 0.0029\n",
      "Epoch 889: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.4591e-05 - mae: 0.0030 - val_loss: 4.9051e-05 - val_mae: 0.0057\n",
      "Epoch 890/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4451e-05 - mae: 0.0030\n",
      "Epoch 890: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.4254e-05 - mae: 0.0029 - val_loss: 4.8717e-05 - val_mae: 0.0056\n",
      "Epoch 891/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.2990e-05 - mae: 0.0028\n",
      "Epoch 891: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.2539e-05 - mae: 0.0027 - val_loss: 5.2738e-05 - val_mae: 0.0057\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/800 [==================>...........] - ETA: 0s - loss: 1.4451e-05 - mae: 0.0030\n",
      "Epoch 892: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.3909e-05 - mae: 0.0029 - val_loss: 4.9125e-05 - val_mae: 0.0056\n",
      "Epoch 893/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.3076e-05 - mae: 0.0029\n",
      "Epoch 893: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.3412e-05 - mae: 0.0029 - val_loss: 4.8755e-05 - val_mae: 0.0056\n",
      "Epoch 894/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.3513e-05 - mae: 0.0028\n",
      "Epoch 894: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.3268e-05 - mae: 0.0028 - val_loss: 5.0102e-05 - val_mae: 0.0056\n",
      "Epoch 895/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.2079e-05 - mae: 0.0027\n",
      "Epoch 895: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.2766e-05 - mae: 0.0028 - val_loss: 5.0145e-05 - val_mae: 0.0056\n",
      "Epoch 896/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.3571e-05 - mae: 0.0029\n",
      "Epoch 896: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 1.3451e-05 - mae: 0.0029 - val_loss: 4.9394e-05 - val_mae: 0.0056\n",
      "Epoch 897/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.4474e-05 - mae: 0.0029\n",
      "Epoch 897: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.4644e-05 - mae: 0.0030 - val_loss: 4.9027e-05 - val_mae: 0.0056\n",
      "Epoch 898/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.4171e-05 - mae: 0.0029\n",
      "Epoch 898: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 1.4206e-05 - mae: 0.0029 - val_loss: 5.4961e-05 - val_mae: 0.0061\n",
      "Epoch 899/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.4806e-05 - mae: 0.0030\n",
      "Epoch 899: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.4771e-05 - mae: 0.0030 - val_loss: 5.3067e-05 - val_mae: 0.0060\n",
      "Epoch 900/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.3702e-05 - mae: 0.0028\n",
      "Epoch 900: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.3673e-05 - mae: 0.0029 - val_loss: 4.8985e-05 - val_mae: 0.0056\n",
      "Epoch 901/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.2057e-05 - mae: 0.0026\n",
      "Epoch 901: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.3056e-05 - mae: 0.0028 - val_loss: 4.9296e-05 - val_mae: 0.0056\n",
      "Epoch 902/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.4375e-05 - mae: 0.0029\n",
      "Epoch 902: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 1.4710e-05 - mae: 0.0030 - val_loss: 4.9642e-05 - val_mae: 0.0057\n",
      "Epoch 903/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.3364e-05 - mae: 0.0028\n",
      "Epoch 903: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 1.3479e-05 - mae: 0.0029 - val_loss: 4.9088e-05 - val_mae: 0.0057\n",
      "Epoch 904/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 1.6815e-05 - mae: 0.0033\n",
      "Epoch 904: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 1.5755e-05 - mae: 0.0031 - val_loss: 5.0085e-05 - val_mae: 0.0056\n",
      "Epoch 905/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.1490e-05 - mae: 0.0026\n",
      "Epoch 905: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.3760e-05 - mae: 0.0029 - val_loss: 5.3950e-05 - val_mae: 0.0058\n",
      "Epoch 906/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5563e-05 - mae: 0.0030\n",
      "Epoch 906: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.5061e-05 - mae: 0.0030 - val_loss: 5.1259e-05 - val_mae: 0.0059\n",
      "Epoch 907/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.2114e-05 - mae: 0.0027\n",
      "Epoch 907: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.2836e-05 - mae: 0.0028 - val_loss: 4.8659e-05 - val_mae: 0.0056\n",
      "Epoch 908/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.3300e-05 - mae: 0.0028\n",
      "Epoch 908: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.3693e-05 - mae: 0.0029 - val_loss: 6.2483e-05 - val_mae: 0.0063\n",
      "Epoch 909/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5260e-05 - mae: 0.0030\n",
      "Epoch 909: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.4765e-05 - mae: 0.0030 - val_loss: 4.9387e-05 - val_mae: 0.0056\n",
      "Epoch 910/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.2524e-05 - mae: 0.0027\n",
      "Epoch 910: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.2618e-05 - mae: 0.0027 - val_loss: 5.0944e-05 - val_mae: 0.0056\n",
      "Epoch 911/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.3571e-05 - mae: 0.0029\n",
      "Epoch 911: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.3990e-05 - mae: 0.0029 - val_loss: 4.9909e-05 - val_mae: 0.0056\n",
      "Epoch 912/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4078e-05 - mae: 0.0029\n",
      "Epoch 912: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.2985e-05 - mae: 0.0027 - val_loss: 4.9169e-05 - val_mae: 0.0056\n",
      "Epoch 913/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3610e-05 - mae: 0.0029\n",
      "Epoch 913: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.3903e-05 - mae: 0.0029 - val_loss: 4.9151e-05 - val_mae: 0.0057\n",
      "Epoch 914/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.2346e-05 - mae: 0.0027\n",
      "Epoch 914: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.4775e-05 - mae: 0.0030 - val_loss: 5.0808e-05 - val_mae: 0.0056\n",
      "Epoch 915/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6713e-05 - mae: 0.0032\n",
      "Epoch 915: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.5216e-05 - mae: 0.0031 - val_loss: 4.9321e-05 - val_mae: 0.0057\n",
      "Epoch 916/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.2245e-05 - mae: 0.0027\n",
      "Epoch 916: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.3328e-05 - mae: 0.0029 - val_loss: 5.1523e-05 - val_mae: 0.0057\n",
      "Epoch 917/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.2267e-05 - mae: 0.0027\n",
      "Epoch 917: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.3273e-05 - mae: 0.0028 - val_loss: 5.0770e-05 - val_mae: 0.0057\n",
      "Epoch 918/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.2417e-05 - mae: 0.0027\n",
      "Epoch 918: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.3794e-05 - mae: 0.0029 - val_loss: 4.8910e-05 - val_mae: 0.0056\n",
      "Epoch 919/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5326e-05 - mae: 0.0030\n",
      "Epoch 919: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.4435e-05 - mae: 0.0029 - val_loss: 5.5136e-05 - val_mae: 0.0059\n",
      "Epoch 920/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3210e-05 - mae: 0.0028\n",
      "Epoch 920: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.3494e-05 - mae: 0.0028 - val_loss: 5.0950e-05 - val_mae: 0.0057\n",
      "Epoch 921/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490/800 [=================>............] - ETA: 0s - loss: 1.4147e-05 - mae: 0.0029\n",
      "Epoch 921: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.4583e-05 - mae: 0.0030 - val_loss: 5.2190e-05 - val_mae: 0.0059\n",
      "Epoch 922/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6988e-05 - mae: 0.0033\n",
      "Epoch 922: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6557e-05 - mae: 0.0032 - val_loss: 5.0882e-05 - val_mae: 0.0059\n",
      "Epoch 923/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.4045e-05 - mae: 0.0029\n",
      "Epoch 923: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.4361e-05 - mae: 0.0030 - val_loss: 5.6061e-05 - val_mae: 0.0059\n",
      "Epoch 924/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.5147e-05 - mae: 0.0030\n",
      "Epoch 924: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.4545e-05 - mae: 0.0030 - val_loss: 5.0865e-05 - val_mae: 0.0059\n",
      "Epoch 925/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.2728e-05 - mae: 0.0028\n",
      "Epoch 925: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.3164e-05 - mae: 0.0028 - val_loss: 5.3456e-05 - val_mae: 0.0058\n",
      "Epoch 926/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3687e-05 - mae: 0.0029\n",
      "Epoch 926: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.3198e-05 - mae: 0.0028 - val_loss: 4.8954e-05 - val_mae: 0.0056\n",
      "Epoch 927/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.1861e-05 - mae: 0.0027\n",
      "Epoch 927: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.3116e-05 - mae: 0.0028 - val_loss: 4.9926e-05 - val_mae: 0.0056\n",
      "Epoch 928/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4228e-05 - mae: 0.0029\n",
      "Epoch 928: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.3995e-05 - mae: 0.0029 - val_loss: 5.0621e-05 - val_mae: 0.0056\n",
      "Epoch 929/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.2929e-05 - mae: 0.0028\n",
      "Epoch 929: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.3532e-05 - mae: 0.0028 - val_loss: 5.1233e-05 - val_mae: 0.0059\n",
      "Epoch 930/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3713e-05 - mae: 0.0028\n",
      "Epoch 930: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.3150e-05 - mae: 0.0028 - val_loss: 5.2495e-05 - val_mae: 0.0057\n",
      "Epoch 931/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.3710e-05 - mae: 0.0029\n",
      "Epoch 931: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.4817e-05 - mae: 0.0030 - val_loss: 5.2645e-05 - val_mae: 0.0060\n",
      "Epoch 932/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5212e-05 - mae: 0.0030\n",
      "Epoch 932: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.4851e-05 - mae: 0.0030 - val_loss: 4.8861e-05 - val_mae: 0.0057\n",
      "Epoch 933/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.2536e-05 - mae: 0.0027\n",
      "Epoch 933: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.2801e-05 - mae: 0.0028 - val_loss: 4.9365e-05 - val_mae: 0.0057\n",
      "Epoch 934/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6117e-05 - mae: 0.0032\n",
      "Epoch 934: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6875e-05 - mae: 0.0032 - val_loss: 4.9632e-05 - val_mae: 0.0056\n",
      "Epoch 935/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.3779e-05 - mae: 0.0028\n",
      "Epoch 935: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.3873e-05 - mae: 0.0028 - val_loss: 5.0601e-05 - val_mae: 0.0056\n",
      "Epoch 936/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.2588e-05 - mae: 0.0027\n",
      "Epoch 936: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.2908e-05 - mae: 0.0028 - val_loss: 5.1931e-05 - val_mae: 0.0057\n",
      "Epoch 937/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.5433e-05 - mae: 0.0031\n",
      "Epoch 937: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 162us/sample - loss: 1.5812e-05 - mae: 0.0031 - val_loss: 4.9564e-05 - val_mae: 0.0057\n",
      "Epoch 938/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.6873e-05 - mae: 0.0032\n",
      "Epoch 938: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.6873e-05 - mae: 0.0032 - val_loss: 4.9529e-05 - val_mae: 0.0056\n",
      "Epoch 939/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.3970e-05 - mae: 0.0029\n",
      "Epoch 939: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.3753e-05 - mae: 0.0029 - val_loss: 5.0989e-05 - val_mae: 0.0058\n",
      "Epoch 940/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.4449e-05 - mae: 0.0030\n",
      "Epoch 940: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.4356e-05 - mae: 0.0029 - val_loss: 4.9979e-05 - val_mae: 0.0057\n",
      "Epoch 941/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7746e-05 - mae: 0.0034\n",
      "Epoch 941: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.5749e-05 - mae: 0.0031 - val_loss: 5.2073e-05 - val_mae: 0.0057\n",
      "Epoch 942/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4113e-05 - mae: 0.0029\n",
      "Epoch 942: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.5188e-05 - mae: 0.0030 - val_loss: 4.9001e-05 - val_mae: 0.0056\n",
      "Epoch 943/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.3201e-05 - mae: 0.0029\n",
      "Epoch 943: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.2951e-05 - mae: 0.0028 - val_loss: 5.4601e-05 - val_mae: 0.0058\n",
      "Epoch 944/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.4437e-05 - mae: 0.0029\n",
      "Epoch 944: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.4377e-05 - mae: 0.0029 - val_loss: 4.8620e-05 - val_mae: 0.0056\n",
      "Epoch 945/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5515e-05 - mae: 0.0031\n",
      "Epoch 945: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.5609e-05 - mae: 0.0031 - val_loss: 6.8460e-05 - val_mae: 0.0066\n",
      "Epoch 946/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5174e-05 - mae: 0.0030\n",
      "Epoch 946: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.4929e-05 - mae: 0.0030 - val_loss: 4.9077e-05 - val_mae: 0.0057\n",
      "Epoch 947/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.3013e-05 - mae: 0.0028\n",
      "Epoch 947: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.3117e-05 - mae: 0.0028 - val_loss: 4.8509e-05 - val_mae: 0.0056\n",
      "Epoch 948/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.3800e-05 - mae: 0.0029\n",
      "Epoch 948: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.3233e-05 - mae: 0.0028 - val_loss: 4.9908e-05 - val_mae: 0.0056\n",
      "Epoch 949/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.1934e-05 - mae: 0.0027\n",
      "Epoch 949: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.2503e-05 - mae: 0.0027 - val_loss: 4.9081e-05 - val_mae: 0.0057\n",
      "Epoch 950/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/800 [===========================>..] - ETA: 0s - loss: 1.1946e-05 - mae: 0.0027\n",
      "Epoch 950: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 158us/sample - loss: 1.2219e-05 - mae: 0.0027 - val_loss: 4.8839e-05 - val_mae: 0.0056\n",
      "Epoch 951/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.2452e-05 - mae: 0.0027\n",
      "Epoch 951: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.2850e-05 - mae: 0.0028 - val_loss: 4.8990e-05 - val_mae: 0.0056\n",
      "Epoch 952/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.2395e-05 - mae: 0.0027\n",
      "Epoch 952: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.3650e-05 - mae: 0.0028 - val_loss: 4.9961e-05 - val_mae: 0.0058\n",
      "Epoch 953/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.3313e-05 - mae: 0.0028\n",
      "Epoch 953: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.3415e-05 - mae: 0.0028 - val_loss: 4.9199e-05 - val_mae: 0.0057\n",
      "Epoch 954/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.4353e-05 - mae: 0.0029\n",
      "Epoch 954: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.4518e-05 - mae: 0.0030 - val_loss: 5.2250e-05 - val_mae: 0.0060\n",
      "Epoch 955/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.3539e-05 - mae: 0.0029\n",
      "Epoch 955: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.3323e-05 - mae: 0.0028 - val_loss: 4.9412e-05 - val_mae: 0.0056\n",
      "Epoch 956/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.3743e-05 - mae: 0.0029\n",
      "Epoch 956: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.3075e-05 - mae: 0.0028 - val_loss: 5.7199e-05 - val_mae: 0.0060\n",
      "Epoch 957/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.9550e-05 - mae: 0.0035\n",
      "Epoch 957: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8104e-05 - mae: 0.0033 - val_loss: 5.4478e-05 - val_mae: 0.0061\n",
      "Epoch 958/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.4293e-05 - mae: 0.0030\n",
      "Epoch 958: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.3601e-05 - mae: 0.0029 - val_loss: 5.0809e-05 - val_mae: 0.0056\n",
      "Epoch 959/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.1772e-05 - mae: 0.0026\n",
      "Epoch 959: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.2998e-05 - mae: 0.0028 - val_loss: 4.8930e-05 - val_mae: 0.0057\n",
      "Epoch 960/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.4429e-05 - mae: 0.0030\n",
      "Epoch 960: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.2962e-05 - mae: 0.0028 - val_loss: 5.1864e-05 - val_mae: 0.0057\n",
      "Epoch 961/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.2226e-05 - mae: 0.0027\n",
      "Epoch 961: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.4465e-05 - mae: 0.0030 - val_loss: 5.0300e-05 - val_mae: 0.0056\n",
      "Epoch 962/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.2919e-05 - mae: 0.0028\n",
      "Epoch 962: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.4868e-05 - mae: 0.0030 - val_loss: 4.9355e-05 - val_mae: 0.0057\n",
      "Epoch 963/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.1969e-05 - mae: 0.0027\n",
      "Epoch 963: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.2981e-05 - mae: 0.0028 - val_loss: 4.9615e-05 - val_mae: 0.0056\n",
      "Epoch 964/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.3575e-05 - mae: 0.0029\n",
      "Epoch 964: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.3675e-05 - mae: 0.0029 - val_loss: 4.9281e-05 - val_mae: 0.0057\n",
      "Epoch 965/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3493e-05 - mae: 0.0029\n",
      "Epoch 965: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.3294e-05 - mae: 0.0028 - val_loss: 4.9495e-05 - val_mae: 0.0056\n",
      "Epoch 966/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.2208e-05 - mae: 0.0027\n",
      "Epoch 966: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.3170e-05 - mae: 0.0028 - val_loss: 4.9287e-05 - val_mae: 0.0056\n",
      "Epoch 967/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4410e-05 - mae: 0.0030\n",
      "Epoch 967: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.3704e-05 - mae: 0.0029 - val_loss: 4.9450e-05 - val_mae: 0.0056\n",
      "Epoch 968/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.2031e-05 - mae: 0.0027\n",
      "Epoch 968: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.2682e-05 - mae: 0.0027 - val_loss: 4.9350e-05 - val_mae: 0.0056\n",
      "Epoch 969/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.2225e-05 - mae: 0.0027\n",
      "Epoch 969: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.2712e-05 - mae: 0.0028 - val_loss: 4.9181e-05 - val_mae: 0.0056\n",
      "Epoch 970/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.2717e-05 - mae: 0.0028\n",
      "Epoch 970: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.2944e-05 - mae: 0.0028 - val_loss: 5.0223e-05 - val_mae: 0.0058\n",
      "Epoch 971/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.2085e-05 - mae: 0.0026\n",
      "Epoch 971: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.3270e-05 - mae: 0.0028 - val_loss: 4.9846e-05 - val_mae: 0.0056\n",
      "Epoch 972/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4532e-05 - mae: 0.0030\n",
      "Epoch 972: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.4452e-05 - mae: 0.0030 - val_loss: 5.2169e-05 - val_mae: 0.0057\n",
      "Epoch 973/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.2267e-05 - mae: 0.0027\n",
      "Epoch 973: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.3161e-05 - mae: 0.0028 - val_loss: 5.4258e-05 - val_mae: 0.0058\n",
      "Epoch 974/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4453e-05 - mae: 0.0030\n",
      "Epoch 974: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.3537e-05 - mae: 0.0029 - val_loss: 4.9379e-05 - val_mae: 0.0057\n",
      "Epoch 975/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.2465e-05 - mae: 0.0027\n",
      "Epoch 975: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.2962e-05 - mae: 0.0028 - val_loss: 4.9792e-05 - val_mae: 0.0056\n",
      "Epoch 976/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.2743e-05 - mae: 0.0028\n",
      "Epoch 976: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.3229e-05 - mae: 0.0028 - val_loss: 4.8777e-05 - val_mae: 0.0056\n",
      "Epoch 977/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.2370e-05 - mae: 0.0027\n",
      "Epoch 977: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.3443e-05 - mae: 0.0029 - val_loss: 4.9518e-05 - val_mae: 0.0056\n",
      "Epoch 978/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.2227e-05 - mae: 0.0027\n",
      "Epoch 978: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.5772e-05 - mae: 0.0031 - val_loss: 5.2197e-05 - val_mae: 0.0057\n",
      "Epoch 979/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/800 [=================>............] - ETA: 0s - loss: 1.3968e-05 - mae: 0.0030\n",
      "Epoch 979: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.4196e-05 - mae: 0.0030 - val_loss: 5.2819e-05 - val_mae: 0.0057\n",
      "Epoch 980/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4451e-05 - mae: 0.0029\n",
      "Epoch 980: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.3903e-05 - mae: 0.0028 - val_loss: 5.0237e-05 - val_mae: 0.0056\n",
      "Epoch 981/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.3053e-05 - mae: 0.0028\n",
      "Epoch 981: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.5050e-05 - mae: 0.0030 - val_loss: 5.3903e-05 - val_mae: 0.0058\n",
      "Epoch 982/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.1860e-05 - mae: 0.0027\n",
      "Epoch 982: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.2371e-05 - mae: 0.0028 - val_loss: 4.9571e-05 - val_mae: 0.0057\n",
      "Epoch 983/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.1811e-05 - mae: 0.0026\n",
      "Epoch 983: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.2129e-05 - mae: 0.0027 - val_loss: 5.0631e-05 - val_mae: 0.0056\n",
      "Epoch 984/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4614e-05 - mae: 0.0030\n",
      "Epoch 984: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.4694e-05 - mae: 0.0030 - val_loss: 5.5102e-05 - val_mae: 0.0062\n",
      "Epoch 985/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.3948e-05 - mae: 0.0030\n",
      "Epoch 985: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.4752e-05 - mae: 0.0030 - val_loss: 5.9560e-05 - val_mae: 0.0064\n",
      "Epoch 986/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5976e-05 - mae: 0.0032\n",
      "Epoch 986: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.5020e-05 - mae: 0.0030 - val_loss: 5.1523e-05 - val_mae: 0.0059\n",
      "Epoch 987/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.5435e-05 - mae: 0.0031\n",
      "Epoch 987: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.5363e-05 - mae: 0.0031 - val_loss: 5.0645e-05 - val_mae: 0.0057\n",
      "Epoch 988/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.3147e-05 - mae: 0.0028\n",
      "Epoch 988: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.2596e-05 - mae: 0.0028 - val_loss: 4.9858e-05 - val_mae: 0.0057\n",
      "Epoch 989/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.3048e-05 - mae: 0.0028\n",
      "Epoch 989: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.2614e-05 - mae: 0.0027 - val_loss: 5.1960e-05 - val_mae: 0.0059\n",
      "Epoch 990/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.3872e-05 - mae: 0.0029\n",
      "Epoch 990: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.3910e-05 - mae: 0.0029 - val_loss: 5.0260e-05 - val_mae: 0.0058\n",
      "Epoch 991/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6257e-05 - mae: 0.0031\n",
      "Epoch 991: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.4649e-05 - mae: 0.0029 - val_loss: 4.9392e-05 - val_mae: 0.0056\n",
      "Epoch 992/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.2952e-05 - mae: 0.0028\n",
      "Epoch 992: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.2771e-05 - mae: 0.0028 - val_loss: 4.9708e-05 - val_mae: 0.0056\n",
      "Epoch 993/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.2512e-05 - mae: 0.0027\n",
      "Epoch 993: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.2680e-05 - mae: 0.0027 - val_loss: 5.1579e-05 - val_mae: 0.0059\n",
      "Epoch 994/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.2820e-05 - mae: 0.0028\n",
      "Epoch 994: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.3286e-05 - mae: 0.0028 - val_loss: 5.3746e-05 - val_mae: 0.0058\n",
      "Epoch 995/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5282e-05 - mae: 0.0031\n",
      "Epoch 995: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.4781e-05 - mae: 0.0030 - val_loss: 4.9281e-05 - val_mae: 0.0056\n",
      "Epoch 996/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.3332e-05 - mae: 0.0028\n",
      "Epoch 996: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.3276e-05 - mae: 0.0028 - val_loss: 4.9470e-05 - val_mae: 0.0057\n",
      "Epoch 997/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.1999e-05 - mae: 0.0026\n",
      "Epoch 997: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.2184e-05 - mae: 0.0027 - val_loss: 5.1046e-05 - val_mae: 0.0056\n",
      "Epoch 998/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.3820e-05 - mae: 0.0029\n",
      "Epoch 998: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.4539e-05 - mae: 0.0029 - val_loss: 4.9519e-05 - val_mae: 0.0056\n",
      "Epoch 999/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.2396e-05 - mae: 0.0027\n",
      "Epoch 999: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.2488e-05 - mae: 0.0027 - val_loss: 4.9238e-05 - val_mae: 0.0056\n",
      "Epoch 1000/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.2745e-05 - mae: 0.0027\n",
      "Epoch 1000: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.2840e-05 - mae: 0.0028 - val_loss: 5.8324e-05 - val_mae: 0.0064\n"
     ]
    }
   ],
   "source": [
    "Layers = [{'size': nx+1, 'activation': None    , 'use_bias': None},\n",
    "          {'size': 10 , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1  , 'activation': 'linear', 'use_bias': False}]\n",
    "Losses = [{'kind': 'mse', 'weight': 1.0}]\n",
    "\n",
    "K = TrainFullyConnectedNN(M_samples, H_samples, \n",
    "                    Layers, Losses,\n",
    "                    'adam', ['mae'], \n",
    "                    10, 1000, 0.2, \n",
    "                    'model', os.path.abspath(''))\n",
    "\n",
    "best_model = K.quickTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7337de",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': 0.0}\n",
    "\n",
    "X = XAIR(best_model, 'lrp.alpha_1_beta_0', 'classic', M_samples[:2], normalizeDict, **kwargs)\n",
    "a_a1b0, _  = X.quick_analyze()\n",
    "\n",
    "X = XAIR(best_model, 'lrp.z', 'classic', M_samples[:2], normalizeDict, **kwargs)\n",
    "a_z, _  = X.quick_analyze()\n",
    "\n",
    "L = TrainLR(M_samples, H_samples, y_ref = 0.0, fit_intercept = False)\n",
    "regr = L.quickTrain()\n",
    "\n",
    "XL = XLR(regr, M_samples)\n",
    "a_LR, _ = XL.quick_analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cad66ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2bab979584c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.tight_layout()\n",
    "\n",
    "ax.plot(a_a1b0[0], 'b', label = 'lrp.alpha_1_beta_0')\n",
    "ax.plot(a_z[0], 'r--', label = 'lrp.z')\n",
    "ax.plot(a_LR[0], 'g:', label = 'lrp.LR')\n",
    "ax.plot(grad_0, 'k-.', label = 'FD grad')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ccd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': 0.001}\n",
    "X = XAIR(best_model, 'lrp.alpha_1_beta_0', 'letzgus', M_samples[:2], normalizeDict, **kwargs)\n",
    "X.check_sample(M_samples[0]), X.check_sample(M_samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f591db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "a, stats  = X.quick_analyze()\n",
    "plt.plot(a[0])\n",
    "plt.plot(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658003da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ref = 0.001\n",
    "best_model = K.loadBestModel()\n",
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': y_ref}\n",
    "X = XAIR(best_model, 'lrp.z', 'classic', M_samples[:10], normalizeDict, **kwargs)\n",
    "X.check_sample(M_samples[0]), X.check_sample(M_samples[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a05202",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a, stats  = X.quick_analyze()\n",
    "plt.plot(a[0])\n",
    "plt.plot(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = TrainLR(M_samples, H_samples, y_ref = y_ref, fit_intercept = False)\n",
    "regr = L.quickTrain()\n",
    "\n",
    "XL = XLR(regr, M_samples)\n",
    "a_LR, stats_LR = XL.quick_analyze()\n",
    "\n",
    "plt.plot(a_LR[0])\n",
    "plt.plot(a_LR[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb211cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ref = 0.0004\n",
    "best_model = K.loadBestModel()\n",
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': y_ref}\n",
    "X = XAIR(best_model, 'lrp.z', 'classic', M_samples[:10], normalizeDict, **kwargs)\n",
    "X.check_sample(M_samples[0]), X.check_sample(M_samples[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753dc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a, stats  = X.quick_analyze()\n",
    "plt.plot(a[0])\n",
    "plt.plot(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3550ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = TrainLR(M_samples, H_samples, y_ref = y_ref, fit_intercept = False)\n",
    "regr = L.quickTrain()\n",
    "\n",
    "XL = XLR(regr, M_samples)\n",
    "a_LR, stats_LR = XL.quick_analyze()\n",
    "\n",
    "plt.plot(a_LR[0])\n",
    "plt.plot(a_LR[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa0ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try one model with non-zero last layer bias\n",
    "\n",
    "Layers = [{'size': nx+1, 'activation': None    , 'use_bias': None},\n",
    "          {'size': 10 , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1  , 'activation': 'linear', 'use_bias': True}]\n",
    "Losses = [{'kind': 'mse', 'weight': 1.0}]\n",
    "\n",
    "K = TrainFullyConnectedNN(M_samples, H_samples, \n",
    "                    Layers, Losses,\n",
    "                    'adam', ['mae'], \n",
    "                    10, 1000, 0.2, \n",
    "                    'model', os.path.abspath(''))\n",
    "\n",
    "best_model = K.quickTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0602507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ref = 0.0004\n",
    "best_model = K.loadBestModel()\n",
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': y_ref}\n",
    "X = XAIR(best_model, 'lrp.z', 'classic', M_samples[:10], normalizeDict, **kwargs)\n",
    "X.check_sample(M_samples[0]), X.check_sample(M_samples[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, stats  = X.quick_analyze()\n",
    "plt.plot(a[0])\n",
    "plt.plot(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a85bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = TrainLR(M_samples, H_samples, y_ref = y_ref, fit_intercept = False)\n",
    "regr = L.quickTrain()\n",
    "\n",
    "XL = XLR(regr, M_samples)\n",
    "a_LR, stats_LR = XL.quick_analyze()\n",
    "\n",
    "plt.plot(a_LR[0])\n",
    "plt.plot(a_LR[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9349edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ref = 0.0\n",
    "best_model = K.loadBestModel()\n",
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': y_ref}\n",
    "X = XAIR(best_model, 'lrp.alpha_1_beta_0', 'classic', M_samples, normalizeDict, **kwargs)\n",
    "a_a1b0, _  = X.quick_analyze()\n",
    "plt.plot(np.mean(a_a1b0, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ref = 0.0\n",
    "best_model = K.loadBestModel()\n",
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': y_ref}\n",
    "X = XAIR(best_model, 'lrp.z', 'classic', M_samples, normalizeDict, **kwargs)\n",
    "a_z, _  = X.quick_analyze()\n",
    "plt.plot(np.mean(a_z, axis = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_LRP",
   "language": "python",
   "name": "py310_lrp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
