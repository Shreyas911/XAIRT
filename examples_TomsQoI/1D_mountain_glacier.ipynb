{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fd7382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Import the required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Append to sys.path the absolute path to src/XAIRT\n",
    "path_list = os.path.abspath('').split('/')\n",
    "path_src_XAIRT = ''\n",
    "for link in path_list[:-1]:\n",
    "    path_src_XAIRT = path_src_XAIRT+link+'/'\n",
    "sys.path.append(path_src_XAIRT+'/src')\n",
    "\n",
    "# Now import module XAIRT\n",
    "from XAIRT import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82c18bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample #1000\r"
     ]
    }
   ],
   "source": [
    "def basal_topology_func(x):\n",
    "    b = 1.0 - 0.1*x\n",
    "    return b\n",
    "\n",
    "def solution(nx, nt, L, T, M, basal_topology_func):\n",
    "\n",
    "    if len(M) != nx + 1:\n",
    "        raise ValueError('M specified but len(M) != nx + 1')\n",
    "        \n",
    "    dx = L/nx\n",
    "    dt = T/nt\n",
    "    x = np.linspace(0,L,nx+1)\n",
    "    t = np.linspace(0,T,nt+1)\n",
    "\n",
    "    b = basal_topology_func(x)\n",
    "\n",
    "    A = 1e-16\n",
    "    rho = 920.0\n",
    "    g = 9.2 \n",
    "    n = 3\n",
    "\n",
    "    C = 2*A/(n+2) * (rho*g)**n * (1e3)**n\n",
    "\n",
    "    h = np.zeros((nx+1,nt+1))\n",
    "    H = np.zeros((nx+1,nt+1))\n",
    "    h[:,0] = b\n",
    "    h[0,:] = b[0]\n",
    "    h[-1,:] = b[-1]\n",
    "\n",
    "    H[:,0] = h[:,0] - b\n",
    "    H[0,:] = h[0,:] - b[0]\n",
    "    H[-1,:] = h[-1,:] - b[-1]\n",
    "\n",
    "    for i in range(1,len(t)):\n",
    "\n",
    "        D = C *((H[1:,i-1]+H[:nx,i-1])/2.0)**(n+2) * ((h[1:,i-1] - h[:nx,i-1])/dx)**(n-1)\n",
    "\n",
    "        phi = -D*(h[1:,i-1]-h[:nx,i-1])/dx\n",
    "\n",
    "        h[1:nx,i] = h[1:nx,i-1] + M[1:nx]*dt - dt/dx * (phi[1:]-phi[:nx-1])\n",
    "        h[1:nx,i] = (h[1:nx,i] < b[1:nx]) * b[1:nx] + (h[1:nx,i] >= b[1:nx]) * h[1:nx,i]\n",
    "        H[:,i] = np.maximum(h[:,i] - b, 0.)\n",
    "\n",
    "        if not np.any(H[:,i]>=0.0):\n",
    "            raise Exception(\"Something went wrong.\")\n",
    "            \n",
    "    Volume = np.sum(H)*dx\n",
    "    \n",
    "    return H[int(nx/3),-1], h[int(nx/2),-1], Volume\n",
    "\n",
    "L = 30.\n",
    "T = 10.\n",
    "nx = 300\n",
    "nt = 12000\n",
    "samples = 1000\n",
    "\n",
    "M_samples = 0.01*np.random.rand(samples, nx+1)\n",
    "H_samples = np.zeros((samples,1), dtype = np.float64)\n",
    "Volume_samples = np.zeros((samples,1), dtype = np.float64)\n",
    "\n",
    "for sample in range(samples):\n",
    "    if (sample+1) % 100 == 0:\n",
    "        print(f'Sample #{sample+1}', end='\\r')\n",
    "    H_samples[sample], _, Volume_samples[sample] = solution(nx, nt, L, T, M_samples[sample], basal_topology_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f166a7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index #300\r"
     ]
    }
   ],
   "source": [
    "def FD_grad(M, pert = 0.0001, normalize = True):\n",
    "    grad = np.zeros(M.shape)\n",
    "\n",
    "    H, *_ = solution(nx, nt, L, T, M, basal_topology_func)\n",
    "    \n",
    "    for i in range(len(M)):\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Index #{i+1}', end='\\r')\n",
    "            \n",
    "        M_pos = np.copy(M)\n",
    "        M_pos[i] = M_pos[i]*(1+pert)\n",
    "        H_pos, *_ = solution(nx, nt, L, T, M_pos, basal_topology_func)\n",
    "        grad[i] = (H_pos - H) / (2*pert)\n",
    "\n",
    "    grad = grad / np.max(np.abs(grad))\n",
    "    \n",
    "    return grad\n",
    "\n",
    "grad_0 = FD_grad(M_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9844b26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      " 10/800 [..............................] - ETA: 6s - loss: 0.0017 - mae: 0.0331"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 18:46:33.520854: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ohpc/pub/libs/gnu7/openmpi/netcdf/4.5.0/lib:/opt/ohpc/pub/libs/gnu7/openmpi/netcdf-fortran/4.4.4/lib:/opt/ohpc/pub/libs/gnu7/openmpi/hdf5/1.10.1/lib:/opt/ohpc/pub/mpi/openmpi-gnu7/1.10.7/lib:/opt/ohpc/pub/compiler/gcc/7.3.0/lib64:/home/shreyas/lis-2.1.3/installation/lib:/share/jdk-16.0.1/lib::\n",
      "2023-08-08 18:46:33.520898: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-08 18:46:33.520928: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c2-2): /proc/driver/nvidia/version does not exist\n",
      "2023-08-08 18:46:33.521713: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-08 18:46:33.537961: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/800 [==============>...............] - ETA: 0s - loss: 5.9304e-04 - mae: 0.0200\n",
      "Epoch 1: val_loss improved from inf to 0.00046, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 316us/sample - loss: 5.4088e-04 - mae: 0.0193 - val_loss: 4.5708e-04 - val_mae: 0.0177\n",
      "Epoch 2/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 4.7372e-04 - mae: 0.0183\n",
      "Epoch 2: val_loss did not improve from 0.00046\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 4.8340e-04 - mae: 0.0184 - val_loss: 6.0183e-04 - val_mae: 0.0183\n",
      "Epoch 3/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 4.7044e-04 - mae: 0.0180\n",
      "Epoch 3: val_loss improved from 0.00046 to 0.00044, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 4.7109e-04 - mae: 0.0181 - val_loss: 4.3874e-04 - val_mae: 0.0170\n",
      "Epoch 4/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 4.0774e-04 - mae: 0.0168\n",
      "Epoch 4: val_loss did not improve from 0.00044\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 4.2811e-04 - mae: 0.0174 - val_loss: 4.4599e-04 - val_mae: 0.0186\n",
      "Epoch 5/1000\n",
      "580/800 [====================>.........] - ETA: 0s - loss: 4.2860e-04 - mae: 0.0175\n",
      "Epoch 5: val_loss improved from 0.00044 to 0.00040, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 4.0999e-04 - mae: 0.0170 - val_loss: 4.0075e-04 - val_mae: 0.0173\n",
      "Epoch 6/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 3.9086e-04 - mae: 0.0168\n",
      "Epoch 6: val_loss improved from 0.00040 to 0.00040, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 3.8082e-04 - mae: 0.0165 - val_loss: 3.9773e-04 - val_mae: 0.0174\n",
      "Epoch 7/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 3.8755e-04 - mae: 0.0166\n",
      "Epoch 7: val_loss improved from 0.00040 to 0.00040, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 3.6961e-04 - mae: 0.0162 - val_loss: 3.9736e-04 - val_mae: 0.0157\n",
      "Epoch 8/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 3.4082e-04 - mae: 0.0155\n",
      "Epoch 8: val_loss improved from 0.00040 to 0.00036, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 3.3634e-04 - mae: 0.0154 - val_loss: 3.5730e-04 - val_mae: 0.0158\n",
      "Epoch 9/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 3.2030e-04 - mae: 0.0153\n",
      "Epoch 9: val_loss improved from 0.00036 to 0.00035, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 3.1426e-04 - mae: 0.0150 - val_loss: 3.4871e-04 - val_mae: 0.0162\n",
      "Epoch 10/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 2.8862e-04 - mae: 0.0142\n",
      "Epoch 10: val_loss did not improve from 0.00035\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 2.8526e-04 - mae: 0.0141 - val_loss: 3.6128e-04 - val_mae: 0.0167\n",
      "Epoch 11/1000\n",
      "640/800 [=======================>......] - ETA: 0s - loss: 2.6625e-04 - mae: 0.0137\n",
      "Epoch 11: val_loss improved from 0.00035 to 0.00032, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 2.7017e-04 - mae: 0.0138 - val_loss: 3.2129e-04 - val_mae: 0.0145\n",
      "Epoch 12/1000\n",
      "650/800 [=======================>......] - ETA: 0s - loss: 2.3748e-04 - mae: 0.0128\n",
      "Epoch 12: val_loss improved from 0.00032 to 0.00032, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 2.4426e-04 - mae: 0.0129 - val_loss: 3.1887e-04 - val_mae: 0.0156\n",
      "Epoch 13/1000\n",
      "650/800 [=======================>......] - ETA: 0s - loss: 2.2774e-04 - mae: 0.0126\n",
      "Epoch 13: val_loss improved from 0.00032 to 0.00029, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 2.2474e-04 - mae: 0.0125 - val_loss: 2.8802e-04 - val_mae: 0.0140\n",
      "Epoch 14/1000\n",
      "640/800 [=======================>......] - ETA: 0s - loss: 2.1103e-04 - mae: 0.0119\n",
      "Epoch 14: val_loss improved from 0.00029 to 0.00027, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 2.0641e-04 - mae: 0.0118 - val_loss: 2.7459e-04 - val_mae: 0.0138\n",
      "Epoch 15/1000\n",
      "650/800 [=======================>......] - ETA: 0s - loss: 1.8073e-04 - mae: 0.0111\n",
      "Epoch 15: val_loss improved from 0.00027 to 0.00027, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 1.8895e-04 - mae: 0.0113 - val_loss: 2.6765e-04 - val_mae: 0.0129\n",
      "Epoch 16/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 1.7138e-04 - mae: 0.0108\n",
      "Epoch 16: val_loss improved from 0.00027 to 0.00026, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.6747e-04 - mae: 0.0107 - val_loss: 2.5770e-04 - val_mae: 0.0125\n",
      "Epoch 17/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.5910e-04 - mae: 0.0103\n",
      "Epoch 17: val_loss improved from 0.00026 to 0.00026, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.5546e-04 - mae: 0.0102 - val_loss: 2.5753e-04 - val_mae: 0.0138\n",
      "Epoch 18/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.4171e-04 - mae: 0.0097\n",
      "Epoch 18: val_loss improved from 0.00026 to 0.00023, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.4233e-04 - mae: 0.0096 - val_loss: 2.2506e-04 - val_mae: 0.0121\n",
      "Epoch 19/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.3588e-04 - mae: 0.0095\n",
      "Epoch 19: val_loss improved from 0.00023 to 0.00022, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.3259e-04 - mae: 0.0093 - val_loss: 2.1959e-04 - val_mae: 0.0115\n",
      "Epoch 20/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.1551e-04 - mae: 0.0086\n",
      "Epoch 20: val_loss improved from 0.00022 to 0.00021, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.1501e-04 - mae: 0.0087 - val_loss: 2.1003e-04 - val_mae: 0.0121\n",
      "Epoch 21/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.0579e-04 - mae: 0.0084\n",
      "Epoch 21: val_loss improved from 0.00021 to 0.00019, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.0236e-04 - mae: 0.0082 - val_loss: 1.9361e-04 - val_mae: 0.0113\n",
      "Epoch 22/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 9.7245e-05 - mae: 0.0080\n",
      "Epoch 22: val_loss improved from 0.00019 to 0.00018, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 9.7784e-05 - mae: 0.0080 - val_loss: 1.8459e-04 - val_mae: 0.0110\n",
      "Epoch 23/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 8.3723e-05 - mae: 0.0073\n",
      "Epoch 23: val_loss improved from 0.00018 to 0.00017, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 8.4353e-05 - mae: 0.0074 - val_loss: 1.7427e-04 - val_mae: 0.0106\n",
      "Epoch 24/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 8.0449e-05 - mae: 0.0073\n",
      "Epoch 24: val_loss improved from 0.00017 to 0.00017, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 7.9651e-05 - mae: 0.0072 - val_loss: 1.6649e-04 - val_mae: 0.0105\n",
      "Epoch 25/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 7.2890e-05 - mae: 0.0069\n",
      "Epoch 25: val_loss improved from 0.00017 to 0.00016, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 7.6198e-05 - mae: 0.0070 - val_loss: 1.5626e-04 - val_mae: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 6.6095e-05 - mae: 0.0065\n",
      "Epoch 26: val_loss improved from 0.00016 to 0.00015, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 6.5237e-05 - mae: 0.0065 - val_loss: 1.4818e-04 - val_mae: 0.0096\n",
      "Epoch 27/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 6.1933e-05 - mae: 0.0062\n",
      "Epoch 27: val_loss improved from 0.00015 to 0.00014, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 6.4456e-05 - mae: 0.0064 - val_loss: 1.4165e-04 - val_mae: 0.0095\n",
      "Epoch 28/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 5.8148e-05 - mae: 0.0061\n",
      "Epoch 28: val_loss improved from 0.00014 to 0.00013, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 5.7954e-05 - mae: 0.0061 - val_loss: 1.3405e-04 - val_mae: 0.0092\n",
      "Epoch 29/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 5.3640e-05 - mae: 0.0059\n",
      "Epoch 29: val_loss did not improve from 0.00013\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 5.4440e-05 - mae: 0.0059 - val_loss: 1.4605e-04 - val_mae: 0.0100\n",
      "Epoch 30/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 4.6973e-05 - mae: 0.0055\n",
      "Epoch 30: val_loss improved from 0.00013 to 0.00013, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 5.0102e-05 - mae: 0.0056 - val_loss: 1.3233e-04 - val_mae: 0.0088\n",
      "Epoch 31/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 4.7080e-05 - mae: 0.0056\n",
      "Epoch 31: val_loss improved from 0.00013 to 0.00013, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 4.6417e-05 - mae: 0.0055 - val_loss: 1.2897e-04 - val_mae: 0.0093\n",
      "Epoch 32/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 4.5465e-05 - mae: 0.0054\n",
      "Epoch 32: val_loss improved from 0.00013 to 0.00012, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 4.4276e-05 - mae: 0.0053 - val_loss: 1.1981e-04 - val_mae: 0.0089\n",
      "Epoch 33/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 4.4793e-05 - mae: 0.0054\n",
      "Epoch 33: val_loss improved from 0.00012 to 0.00011, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 4.4631e-05 - mae: 0.0053 - val_loss: 1.0770e-04 - val_mae: 0.0083\n",
      "Epoch 34/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 3.9503e-05 - mae: 0.0050\n",
      "Epoch 34: val_loss improved from 0.00011 to 0.00011, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 4.1987e-05 - mae: 0.0052 - val_loss: 1.0602e-04 - val_mae: 0.0080\n",
      "Epoch 35/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 3.8390e-05 - mae: 0.0050\n",
      "Epoch 35: val_loss improved from 0.00011 to 0.00010, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 3.7310e-05 - mae: 0.0049 - val_loss: 9.7084e-05 - val_mae: 0.0077\n",
      "Epoch 36/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 3.8200e-05 - mae: 0.0049\n",
      "Epoch 36: val_loss improved from 0.00010 to 0.00010, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 3.8100e-05 - mae: 0.0049 - val_loss: 9.6370e-05 - val_mae: 0.0076\n",
      "Epoch 37/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 3.4581e-05 - mae: 0.0046\n",
      "Epoch 37: val_loss improved from 0.00010 to 0.00009, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 3.4171e-05 - mae: 0.0046 - val_loss: 8.9119e-05 - val_mae: 0.0074\n",
      "Epoch 38/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 3.2167e-05 - mae: 0.0045\n",
      "Epoch 38: val_loss improved from 0.00009 to 0.00009, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 3.3603e-05 - mae: 0.0046 - val_loss: 8.5741e-05 - val_mae: 0.0074\n",
      "Epoch 39/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.9704e-05 - mae: 0.0043\n",
      "Epoch 39: val_loss did not improve from 0.00009\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 3.1811e-05 - mae: 0.0045 - val_loss: 8.7511e-05 - val_mae: 0.0073\n",
      "Epoch 40/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 2.9100e-05 - mae: 0.0043\n",
      "Epoch 40: val_loss improved from 0.00009 to 0.00008, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 2.9159e-05 - mae: 0.0043 - val_loss: 7.8706e-05 - val_mae: 0.0071\n",
      "Epoch 41/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 3.1316e-05 - mae: 0.0045\n",
      "Epoch 41: val_loss did not improve from 0.00008\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 3.0281e-05 - mae: 0.0044 - val_loss: 7.8986e-05 - val_mae: 0.0070\n",
      "Epoch 42/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 2.7431e-05 - mae: 0.0042\n",
      "Epoch 42: val_loss did not improve from 0.00008\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 2.8842e-05 - mae: 0.0043 - val_loss: 8.1147e-05 - val_mae: 0.0072\n",
      "Epoch 43/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 2.5776e-05 - mae: 0.0040\n",
      "Epoch 43: val_loss improved from 0.00008 to 0.00007, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 2.6664e-05 - mae: 0.0041 - val_loss: 7.0925e-05 - val_mae: 0.0067\n",
      "Epoch 44/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 2.6456e-05 - mae: 0.0042\n",
      "Epoch 44: val_loss did not improve from 0.00007\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 2.5620e-05 - mae: 0.0041 - val_loss: 7.8337e-05 - val_mae: 0.0070\n",
      "Epoch 45/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 2.7357e-05 - mae: 0.0041\n",
      "Epoch 45: val_loss improved from 0.00007 to 0.00007, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 2.7063e-05 - mae: 0.0041 - val_loss: 6.6468e-05 - val_mae: 0.0065\n",
      "Epoch 46/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 2.3306e-05 - mae: 0.0038\n",
      "Epoch 46: val_loss did not improve from 0.00007\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 2.5552e-05 - mae: 0.0040 - val_loss: 6.9325e-05 - val_mae: 0.0067\n",
      "Epoch 47/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 2.8516e-05 - mae: 0.0043\n",
      "Epoch 47: val_loss improved from 0.00007 to 0.00006, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 2.7128e-05 - mae: 0.0042 - val_loss: 6.4038e-05 - val_mae: 0.0064\n",
      "Epoch 48/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 2.3790e-05 - mae: 0.0039\n",
      "Epoch 48: val_loss improved from 0.00006 to 0.00006, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 2.2672e-05 - mae: 0.0038 - val_loss: 6.1633e-05 - val_mae: 0.0063\n",
      "Epoch 49/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 2.1659e-05 - mae: 0.0038\n",
      "Epoch 49: val_loss improved from 0.00006 to 0.00006, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 2.1966e-05 - mae: 0.0038 - val_loss: 6.0565e-05 - val_mae: 0.0062\n",
      "Epoch 50/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 2.4686e-05 - mae: 0.0040\n",
      "Epoch 50: val_loss did not improve from 0.00006\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 2.6763e-05 - mae: 0.0041 - val_loss: 7.2039e-05 - val_mae: 0.0068\n",
      "Epoch 51/1000\n",
      "630/800 [======================>.......] - ETA: 0s - loss: 2.2187e-05 - mae: 0.0038\n",
      "Epoch 51: val_loss improved from 0.00006 to 0.00006, saving model to /home/shreyas/XAIRT/examples/model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 120us/sample - loss: 2.2542e-05 - mae: 0.0038 - val_loss: 6.0144e-05 - val_mae: 0.0063\n",
      "Epoch 52/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 2.4960e-05 - mae: 0.0040\n",
      "Epoch 52: val_loss improved from 0.00006 to 0.00006, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 2.3998e-05 - mae: 0.0039 - val_loss: 5.6561e-05 - val_mae: 0.0061\n",
      "Epoch 53/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 2.0249e-05 - mae: 0.0036\n",
      "Epoch 53: val_loss improved from 0.00006 to 0.00006, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 2.0852e-05 - mae: 0.0036 - val_loss: 5.5355e-05 - val_mae: 0.0060\n",
      "Epoch 54/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 1.9024e-05 - mae: 0.0035\n",
      "Epoch 54: val_loss did not improve from 0.00006\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 2.0493e-05 - mae: 0.0037 - val_loss: 5.5912e-05 - val_mae: 0.0060\n",
      "Epoch 55/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 2.0166e-05 - mae: 0.0036\n",
      "Epoch 55: val_loss did not improve from 0.00006\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 2.0115e-05 - mae: 0.0036 - val_loss: 5.7938e-05 - val_mae: 0.0061\n",
      "Epoch 56/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 2.1242e-05 - mae: 0.0037\n",
      "Epoch 56: val_loss improved from 0.00006 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 2.2623e-05 - mae: 0.0038 - val_loss: 5.2289e-05 - val_mae: 0.0058\n",
      "Epoch 57/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 2.1584e-05 - mae: 0.0037\n",
      "Epoch 57: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 2.2435e-05 - mae: 0.0038 - val_loss: 6.7871e-05 - val_mae: 0.0067\n",
      "Epoch 58/1000\n",
      "580/800 [====================>.........] - ETA: 0s - loss: 2.0742e-05 - mae: 0.0036\n",
      "Epoch 58: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 2.0472e-05 - mae: 0.0036 - val_loss: 5.1209e-05 - val_mae: 0.0058\n",
      "Epoch 59/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 1.7607e-05 - mae: 0.0034\n",
      "Epoch 59: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.8450e-05 - mae: 0.0035 - val_loss: 5.0301e-05 - val_mae: 0.0057\n",
      "Epoch 60/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 1.9720e-05 - mae: 0.0035\n",
      "Epoch 60: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 2.0024e-05 - mae: 0.0036 - val_loss: 5.9584e-05 - val_mae: 0.0062\n",
      "Epoch 61/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 2.2741e-05 - mae: 0.0038\n",
      "Epoch 61: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 2.1836e-05 - mae: 0.0038 - val_loss: 4.8795e-05 - val_mae: 0.0056\n",
      "Epoch 62/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 2.1689e-05 - mae: 0.0038\n",
      "Epoch 62: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 2.1509e-05 - mae: 0.0037 - val_loss: 4.9018e-05 - val_mae: 0.0056\n",
      "Epoch 63/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 1.9755e-05 - mae: 0.0036\n",
      "Epoch 63: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.9482e-05 - mae: 0.0036 - val_loss: 4.8539e-05 - val_mae: 0.0056\n",
      "Epoch 64/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 1.9015e-05 - mae: 0.0035\n",
      "Epoch 64: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.9348e-05 - mae: 0.0035 - val_loss: 4.7888e-05 - val_mae: 0.0056\n",
      "Epoch 65/1000\n",
      "570/800 [====================>.........] - ETA: 0s - loss: 1.7248e-05 - mae: 0.0033\n",
      "Epoch 65: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 1.8522e-05 - mae: 0.0035 - val_loss: 5.0064e-05 - val_mae: 0.0057\n",
      "Epoch 66/1000\n",
      "580/800 [====================>.........] - ETA: 0s - loss: 1.9209e-05 - mae: 0.0035\n",
      "Epoch 66: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8750e-05 - mae: 0.0035 - val_loss: 4.7366e-05 - val_mae: 0.0056\n",
      "Epoch 67/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 1.8809e-05 - mae: 0.0035\n",
      "Epoch 67: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 2.0101e-05 - mae: 0.0036 - val_loss: 4.7518e-05 - val_mae: 0.0056\n",
      "Epoch 68/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 1.8514e-05 - mae: 0.0034\n",
      "Epoch 68: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.9117e-05 - mae: 0.0035 - val_loss: 4.6475e-05 - val_mae: 0.0055\n",
      "Epoch 69/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 2.0504e-05 - mae: 0.0036\n",
      "Epoch 69: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 1.9796e-05 - mae: 0.0036 - val_loss: 4.7291e-05 - val_mae: 0.0056\n",
      "Epoch 70/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.9148e-05 - mae: 0.0035\n",
      "Epoch 70: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.9465e-05 - mae: 0.0035 - val_loss: 5.2578e-05 - val_mae: 0.0058\n",
      "Epoch 71/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8858e-05 - mae: 0.0035\n",
      "Epoch 71: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.9920e-05 - mae: 0.0036 - val_loss: 5.3189e-05 - val_mae: 0.0059\n",
      "Epoch 72/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 2.0900e-05 - mae: 0.0038\n",
      "Epoch 72: val_loss improved from 0.00005 to 0.00005, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.9727e-05 - mae: 0.0036 - val_loss: 4.5556e-05 - val_mae: 0.0055\n",
      "Epoch 73/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7502e-05 - mae: 0.0034\n",
      "Epoch 73: val_loss did not improve from 0.00005\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.7950e-05 - mae: 0.0034 - val_loss: 4.6337e-05 - val_mae: 0.0055\n",
      "Epoch 74/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7688e-05 - mae: 0.0033\n",
      "Epoch 74: val_loss improved from 0.00005 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.7979e-05 - mae: 0.0034 - val_loss: 4.4634e-05 - val_mae: 0.0054\n",
      "Epoch 75/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7853e-05 - mae: 0.0034\n",
      "Epoch 75: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.8789e-05 - mae: 0.0035 - val_loss: 4.7826e-05 - val_mae: 0.0056\n",
      "Epoch 76/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.9178e-05 - mae: 0.0036\n",
      "Epoch 76: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 2.1221e-05 - mae: 0.0037 - val_loss: 4.4751e-05 - val_mae: 0.0054\n",
      "Epoch 77/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.9827e-05 - mae: 0.0036\n",
      "Epoch 77: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 2.0338e-05 - mae: 0.0036 - val_loss: 4.6953e-05 - val_mae: 0.0055\n",
      "Epoch 78/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7831e-05 - mae: 0.0034\n",
      "Epoch 78: val_loss did not improve from 0.00004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 120us/sample - loss: 1.9761e-05 - mae: 0.0036 - val_loss: 4.4750e-05 - val_mae: 0.0054\n",
      "Epoch 79/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.1736e-05 - mae: 0.0037\n",
      "Epoch 79: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 2.1240e-05 - mae: 0.0036 - val_loss: 4.8816e-05 - val_mae: 0.0057\n",
      "Epoch 80/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7687e-05 - mae: 0.0033\n",
      "Epoch 80: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.8818e-05 - mae: 0.0035 - val_loss: 4.5908e-05 - val_mae: 0.0055\n",
      "Epoch 81/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.8730e-05 - mae: 0.0035\n",
      "Epoch 81: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.9793e-05 - mae: 0.0036 - val_loss: 4.3640e-05 - val_mae: 0.0054\n",
      "Epoch 82/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9809e-05 - mae: 0.0035\n",
      "Epoch 82: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.9701e-05 - mae: 0.0035 - val_loss: 4.3176e-05 - val_mae: 0.0053\n",
      "Epoch 83/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7317e-05 - mae: 0.0033\n",
      "Epoch 83: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 2.0846e-05 - mae: 0.0036 - val_loss: 4.3110e-05 - val_mae: 0.0053\n",
      "Epoch 84/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7493e-05 - mae: 0.0034\n",
      "Epoch 84: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.7273e-05 - mae: 0.0034 - val_loss: 4.4175e-05 - val_mae: 0.0054\n",
      "Epoch 85/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9140e-05 - mae: 0.0036\n",
      "Epoch 85: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 2.0280e-05 - mae: 0.0036 - val_loss: 4.6546e-05 - val_mae: 0.0055\n",
      "Epoch 86/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7926e-05 - mae: 0.0034\n",
      "Epoch 86: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.7744e-05 - mae: 0.0034 - val_loss: 4.2794e-05 - val_mae: 0.0053\n",
      "Epoch 87/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.8035e-05 - mae: 0.0034\n",
      "Epoch 87: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.8148e-05 - mae: 0.0034 - val_loss: 4.2790e-05 - val_mae: 0.0053\n",
      "Epoch 88/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 1.7079e-05 - mae: 0.0033\n",
      "Epoch 88: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.8842e-05 - mae: 0.0035 - val_loss: 4.2595e-05 - val_mae: 0.0053\n",
      "Epoch 89/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 2.0056e-05 - mae: 0.0036\n",
      "Epoch 89: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 2.0641e-05 - mae: 0.0036 - val_loss: 4.4252e-05 - val_mae: 0.0054\n",
      "Epoch 90/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 2.2201e-05 - mae: 0.0038\n",
      "Epoch 90: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.9983e-05 - mae: 0.0036 - val_loss: 4.2396e-05 - val_mae: 0.0053\n",
      "Epoch 91/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.6944e-05 - mae: 0.0033\n",
      "Epoch 91: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.8583e-05 - mae: 0.0034 - val_loss: 5.5102e-05 - val_mae: 0.0060\n",
      "Epoch 92/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.9523e-05 - mae: 0.0035\n",
      "Epoch 92: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.9840e-05 - mae: 0.0036 - val_loss: 5.4530e-05 - val_mae: 0.0060\n",
      "Epoch 93/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 2.3850e-05 - mae: 0.0039\n",
      "Epoch 93: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 2.1416e-05 - mae: 0.0037 - val_loss: 4.2584e-05 - val_mae: 0.0052\n",
      "Epoch 94/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6809e-05 - mae: 0.0033\n",
      "Epoch 94: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.7511e-05 - mae: 0.0033 - val_loss: 4.2563e-05 - val_mae: 0.0053\n",
      "Epoch 95/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.8294e-05 - mae: 0.0034\n",
      "Epoch 95: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.8348e-05 - mae: 0.0034 - val_loss: 4.3969e-05 - val_mae: 0.0054\n",
      "Epoch 96/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.8047e-05 - mae: 0.0035\n",
      "Epoch 96: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.8558e-05 - mae: 0.0035 - val_loss: 5.4489e-05 - val_mae: 0.0060\n",
      "Epoch 97/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8524e-05 - mae: 0.0035\n",
      "Epoch 97: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 2.1377e-05 - mae: 0.0037 - val_loss: 4.4696e-05 - val_mae: 0.0054\n",
      "Epoch 98/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.9417e-05 - mae: 0.0035\n",
      "Epoch 98: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.9338e-05 - mae: 0.0035 - val_loss: 4.4931e-05 - val_mae: 0.0054\n",
      "Epoch 99/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6018e-05 - mae: 0.0032\n",
      "Epoch 99: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.7614e-05 - mae: 0.0034 - val_loss: 4.2045e-05 - val_mae: 0.0052\n",
      "Epoch 100/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 2.1666e-05 - mae: 0.0037\n",
      "Epoch 100: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 2.1438e-05 - mae: 0.0037 - val_loss: 4.2337e-05 - val_mae: 0.0053\n",
      "Epoch 101/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5408e-05 - mae: 0.0032\n",
      "Epoch 101: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7462e-05 - mae: 0.0033 - val_loss: 4.5887e-05 - val_mae: 0.0054\n",
      "Epoch 102/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8140e-05 - mae: 0.0034\n",
      "Epoch 102: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.9001e-05 - mae: 0.0035 - val_loss: 4.3312e-05 - val_mae: 0.0053\n",
      "Epoch 103/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 2.0100e-05 - mae: 0.0036\n",
      "Epoch 103: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.9518e-05 - mae: 0.0036 - val_loss: 4.9864e-05 - val_mae: 0.0057\n",
      "Epoch 104/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9699e-05 - mae: 0.0036\n",
      "Epoch 104: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.8515e-05 - mae: 0.0035 - val_loss: 4.1854e-05 - val_mae: 0.0052\n",
      "Epoch 105/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.6631e-05 - mae: 0.0032\n",
      "Epoch 105: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.7725e-05 - mae: 0.0034 - val_loss: 4.2027e-05 - val_mae: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6282e-05 - mae: 0.0033\n",
      "Epoch 106: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 2.0125e-05 - mae: 0.0036 - val_loss: 5.1272e-05 - val_mae: 0.0058\n",
      "Epoch 107/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9106e-05 - mae: 0.0035\n",
      "Epoch 107: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.7840e-05 - mae: 0.0034 - val_loss: 4.1551e-05 - val_mae: 0.0052\n",
      "Epoch 108/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6124e-05 - mae: 0.0032\n",
      "Epoch 108: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7842e-05 - mae: 0.0033 - val_loss: 6.7160e-05 - val_mae: 0.0067\n",
      "Epoch 109/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 2.1810e-05 - mae: 0.0038\n",
      "Epoch 109: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 2.1833e-05 - mae: 0.0038 - val_loss: 5.1692e-05 - val_mae: 0.0058\n",
      "Epoch 110/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7767e-05 - mae: 0.0034\n",
      "Epoch 110: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.8047e-05 - mae: 0.0034 - val_loss: 4.1541e-05 - val_mae: 0.0052\n",
      "Epoch 111/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8345e-05 - mae: 0.0035\n",
      "Epoch 111: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7231e-05 - mae: 0.0033 - val_loss: 4.1685e-05 - val_mae: 0.0052\n",
      "Epoch 112/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9529e-05 - mae: 0.0036\n",
      "Epoch 112: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.9303e-05 - mae: 0.0035 - val_loss: 4.4259e-05 - val_mae: 0.0054\n",
      "Epoch 113/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7642e-05 - mae: 0.0033\n",
      "Epoch 113: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7649e-05 - mae: 0.0034 - val_loss: 4.9756e-05 - val_mae: 0.0057\n",
      "Epoch 114/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.0053e-05 - mae: 0.0036\n",
      "Epoch 114: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 2.0042e-05 - mae: 0.0036 - val_loss: 4.1304e-05 - val_mae: 0.0052\n",
      "Epoch 115/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7236e-05 - mae: 0.0033\n",
      "Epoch 115: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.7140e-05 - mae: 0.0033 - val_loss: 4.1388e-05 - val_mae: 0.0052\n",
      "Epoch 116/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.9736e-05 - mae: 0.0036\n",
      "Epoch 116: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 2.0015e-05 - mae: 0.0036 - val_loss: 4.2186e-05 - val_mae: 0.0053\n",
      "Epoch 117/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.7185e-05 - mae: 0.0033\n",
      "Epoch 117: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.7389e-05 - mae: 0.0033 - val_loss: 4.1442e-05 - val_mae: 0.0052\n",
      "Epoch 118/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7798e-05 - mae: 0.0034\n",
      "Epoch 118: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7473e-05 - mae: 0.0034 - val_loss: 4.2204e-05 - val_mae: 0.0052\n",
      "Epoch 119/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7876e-05 - mae: 0.0034\n",
      "Epoch 119: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.9105e-05 - mae: 0.0035 - val_loss: 4.6150e-05 - val_mae: 0.0055\n",
      "Epoch 120/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 2.2243e-05 - mae: 0.0038\n",
      "Epoch 120: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 2.0887e-05 - mae: 0.0037 - val_loss: 4.3136e-05 - val_mae: 0.0053\n",
      "Epoch 121/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7385e-05 - mae: 0.0034\n",
      "Epoch 121: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7783e-05 - mae: 0.0034 - val_loss: 4.7125e-05 - val_mae: 0.0055\n",
      "Epoch 122/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8081e-05 - mae: 0.0034\n",
      "Epoch 122: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.8354e-05 - mae: 0.0035 - val_loss: 4.2497e-05 - val_mae: 0.0053\n",
      "Epoch 123/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6095e-05 - mae: 0.0032\n",
      "Epoch 123: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.6911e-05 - mae: 0.0033 - val_loss: 4.8612e-05 - val_mae: 0.0056\n",
      "Epoch 124/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.9023e-05 - mae: 0.0035\n",
      "Epoch 124: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.9512e-05 - mae: 0.0035 - val_loss: 4.2135e-05 - val_mae: 0.0053\n",
      "Epoch 125/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.7734e-05 - mae: 0.0034\n",
      "Epoch 125: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.9279e-05 - mae: 0.0035 - val_loss: 5.0642e-05 - val_mae: 0.0058\n",
      "Epoch 126/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.9731e-05 - mae: 0.0035\n",
      "Epoch 126: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.8051e-05 - mae: 0.0034 - val_loss: 4.4205e-05 - val_mae: 0.0054\n",
      "Epoch 127/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7518e-05 - mae: 0.0033\n",
      "Epoch 127: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.8419e-05 - mae: 0.0034 - val_loss: 4.2440e-05 - val_mae: 0.0053\n",
      "Epoch 128/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.9044e-05 - mae: 0.0035\n",
      "Epoch 128: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.9330e-05 - mae: 0.0035 - val_loss: 4.2891e-05 - val_mae: 0.0053\n",
      "Epoch 129/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 2.2483e-05 - mae: 0.0038\n",
      "Epoch 129: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.9975e-05 - mae: 0.0036 - val_loss: 4.2407e-05 - val_mae: 0.0053\n",
      "Epoch 130/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5624e-05 - mae: 0.0031\n",
      "Epoch 130: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7513e-05 - mae: 0.0034 - val_loss: 4.2237e-05 - val_mae: 0.0053\n",
      "Epoch 131/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7207e-05 - mae: 0.0034\n",
      "Epoch 131: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.7618e-05 - mae: 0.0034 - val_loss: 4.1954e-05 - val_mae: 0.0052\n",
      "Epoch 132/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6749e-05 - mae: 0.0033\n",
      "Epoch 132: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 2.0307e-05 - mae: 0.0036 - val_loss: 6.0271e-05 - val_mae: 0.0063\n",
      "Epoch 133/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.9988e-05 - mae: 0.0036\n",
      "Epoch 133: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 2.1005e-05 - mae: 0.0037 - val_loss: 4.4398e-05 - val_mae: 0.0054\n",
      "Epoch 134/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.9885e-05 - mae: 0.0036\n",
      "Epoch 134: val_loss did not improve from 0.00004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 128us/sample - loss: 2.0394e-05 - mae: 0.0036 - val_loss: 4.2512e-05 - val_mae: 0.0053\n",
      "Epoch 135/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7128e-05 - mae: 0.0034\n",
      "Epoch 135: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.9628e-05 - mae: 0.0036 - val_loss: 4.2908e-05 - val_mae: 0.0053\n",
      "Epoch 136/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7617e-05 - mae: 0.0034\n",
      "Epoch 136: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.8044e-05 - mae: 0.0034 - val_loss: 4.3618e-05 - val_mae: 0.0053\n",
      "Epoch 137/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7553e-05 - mae: 0.0034\n",
      "Epoch 137: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.8453e-05 - mae: 0.0035 - val_loss: 4.4635e-05 - val_mae: 0.0054\n",
      "Epoch 138/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.8684e-05 - mae: 0.0034\n",
      "Epoch 138: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.8837e-05 - mae: 0.0034 - val_loss: 4.5320e-05 - val_mae: 0.0054\n",
      "Epoch 139/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 2.1665e-05 - mae: 0.0038\n",
      "Epoch 139: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 2.3012e-05 - mae: 0.0039 - val_loss: 4.2611e-05 - val_mae: 0.0053\n",
      "Epoch 140/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9883e-05 - mae: 0.0036\n",
      "Epoch 140: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.8610e-05 - mae: 0.0035 - val_loss: 4.2995e-05 - val_mae: 0.0053\n",
      "Epoch 141/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8052e-05 - mae: 0.0034\n",
      "Epoch 141: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.8503e-05 - mae: 0.0034 - val_loss: 5.6638e-05 - val_mae: 0.0061\n",
      "Epoch 142/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.3962e-05 - mae: 0.0040\n",
      "Epoch 142: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 2.1406e-05 - mae: 0.0038 - val_loss: 4.2555e-05 - val_mae: 0.0053\n",
      "Epoch 143/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7545e-05 - mae: 0.0033\n",
      "Epoch 143: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.8350e-05 - mae: 0.0035 - val_loss: 4.2266e-05 - val_mae: 0.0053\n",
      "Epoch 144/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5814e-05 - mae: 0.0032\n",
      "Epoch 144: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.8640e-05 - mae: 0.0034 - val_loss: 4.3330e-05 - val_mae: 0.0053\n",
      "Epoch 145/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8123e-05 - mae: 0.0034\n",
      "Epoch 145: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.8276e-05 - mae: 0.0034 - val_loss: 4.2554e-05 - val_mae: 0.0053\n",
      "Epoch 146/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5294e-05 - mae: 0.0031\n",
      "Epoch 146: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.8420e-05 - mae: 0.0034 - val_loss: 4.3192e-05 - val_mae: 0.0053\n",
      "Epoch 147/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7795e-05 - mae: 0.0034\n",
      "Epoch 147: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.8727e-05 - mae: 0.0035 - val_loss: 5.3684e-05 - val_mae: 0.0059\n",
      "Epoch 148/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 2.1117e-05 - mae: 0.0037\n",
      "Epoch 148: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.9282e-05 - mae: 0.0035 - val_loss: 5.0010e-05 - val_mae: 0.0057\n",
      "Epoch 149/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.0814e-05 - mae: 0.0037\n",
      "Epoch 149: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 2.0362e-05 - mae: 0.0037 - val_loss: 4.3666e-05 - val_mae: 0.0054\n",
      "Epoch 150/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7168e-05 - mae: 0.0033\n",
      "Epoch 150: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.6921e-05 - mae: 0.0033 - val_loss: 4.2294e-05 - val_mae: 0.0053\n",
      "Epoch 151/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6639e-05 - mae: 0.0032\n",
      "Epoch 151: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.6933e-05 - mae: 0.0033 - val_loss: 4.3499e-05 - val_mae: 0.0053\n",
      "Epoch 152/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.6809e-05 - mae: 0.0033\n",
      "Epoch 152: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.6929e-05 - mae: 0.0033 - val_loss: 4.5816e-05 - val_mae: 0.0055\n",
      "Epoch 153/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8065e-05 - mae: 0.0035\n",
      "Epoch 153: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.8814e-05 - mae: 0.0035 - val_loss: 4.2177e-05 - val_mae: 0.0053\n",
      "Epoch 154/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7557e-05 - mae: 0.0033\n",
      "Epoch 154: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.9618e-05 - mae: 0.0035 - val_loss: 4.5350e-05 - val_mae: 0.0054\n",
      "Epoch 155/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7781e-05 - mae: 0.0033\n",
      "Epoch 155: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.8986e-05 - mae: 0.0035 - val_loss: 5.0345e-05 - val_mae: 0.0057\n",
      "Epoch 156/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 2.2514e-05 - mae: 0.0038\n",
      "Epoch 156: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 2.1767e-05 - mae: 0.0038 - val_loss: 4.7030e-05 - val_mae: 0.0055\n",
      "Epoch 157/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7947e-05 - mae: 0.0035\n",
      "Epoch 157: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7901e-05 - mae: 0.0034 - val_loss: 4.2101e-05 - val_mae: 0.0052\n",
      "Epoch 158/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6245e-05 - mae: 0.0032\n",
      "Epoch 158: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7073e-05 - mae: 0.0033 - val_loss: 4.4002e-05 - val_mae: 0.0053\n",
      "Epoch 159/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.9361e-05 - mae: 0.0035\n",
      "Epoch 159: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 2.0453e-05 - mae: 0.0036 - val_loss: 7.1994e-05 - val_mae: 0.0069\n",
      "Epoch 160/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 2.2623e-05 - mae: 0.0038\n",
      "Epoch 160: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 2.1333e-05 - mae: 0.0037 - val_loss: 4.1918e-05 - val_mae: 0.0053\n",
      "Epoch 161/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7641e-05 - mae: 0.0034\n",
      "Epoch 161: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8257e-05 - mae: 0.0035 - val_loss: 5.0912e-05 - val_mae: 0.0058\n",
      "Epoch 162/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.9955e-05 - mae: 0.0036\n",
      "Epoch 162: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.9697e-05 - mae: 0.0036 - val_loss: 4.2319e-05 - val_mae: 0.0053\n",
      "Epoch 163/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.7174e-05 - mae: 0.0034\n",
      "Epoch 163: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.7288e-05 - mae: 0.0034 - val_loss: 4.1892e-05 - val_mae: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8162e-05 - mae: 0.0034\n",
      "Epoch 164: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7337e-05 - mae: 0.0033 - val_loss: 4.1854e-05 - val_mae: 0.0052\n",
      "Epoch 165/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7310e-05 - mae: 0.0033\n",
      "Epoch 165: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7770e-05 - mae: 0.0034 - val_loss: 4.2092e-05 - val_mae: 0.0052\n",
      "Epoch 166/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.8310e-05 - mae: 0.0034\n",
      "Epoch 166: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.9252e-05 - mae: 0.0035 - val_loss: 4.2212e-05 - val_mae: 0.0053\n",
      "Epoch 167/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8602e-05 - mae: 0.0034\n",
      "Epoch 167: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.8349e-05 - mae: 0.0034 - val_loss: 4.2370e-05 - val_mae: 0.0053\n",
      "Epoch 168/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8550e-05 - mae: 0.0034\n",
      "Epoch 168: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7865e-05 - mae: 0.0034 - val_loss: 4.8070e-05 - val_mae: 0.0056\n",
      "Epoch 169/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7419e-05 - mae: 0.0033\n",
      "Epoch 169: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.8182e-05 - mae: 0.0034 - val_loss: 4.1590e-05 - val_mae: 0.0052\n",
      "Epoch 170/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7143e-05 - mae: 0.0033\n",
      "Epoch 170: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.7330e-05 - mae: 0.0033 - val_loss: 4.3324e-05 - val_mae: 0.0053\n",
      "Epoch 171/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7130e-05 - mae: 0.0033\n",
      "Epoch 171: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8800e-05 - mae: 0.0035 - val_loss: 4.6530e-05 - val_mae: 0.0055\n",
      "Epoch 172/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 2.1636e-05 - mae: 0.0038\n",
      "Epoch 172: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 2.1367e-05 - mae: 0.0037 - val_loss: 4.7813e-05 - val_mae: 0.0056\n",
      "Epoch 173/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6828e-05 - mae: 0.0032\n",
      "Epoch 173: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.7168e-05 - mae: 0.0033 - val_loss: 4.2993e-05 - val_mae: 0.0053\n",
      "Epoch 174/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7013e-05 - mae: 0.0034\n",
      "Epoch 174: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.8452e-05 - mae: 0.0035 - val_loss: 4.2797e-05 - val_mae: 0.0053\n",
      "Epoch 175/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 2.2733e-05 - mae: 0.0038\n",
      "Epoch 175: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 2.0483e-05 - mae: 0.0036 - val_loss: 4.1682e-05 - val_mae: 0.0052\n",
      "Epoch 176/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 2.1392e-05 - mae: 0.0037\n",
      "Epoch 176: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 2.2594e-05 - mae: 0.0038 - val_loss: 4.9596e-05 - val_mae: 0.0057\n",
      "Epoch 177/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7461e-05 - mae: 0.0034\n",
      "Epoch 177: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7436e-05 - mae: 0.0034 - val_loss: 4.6211e-05 - val_mae: 0.0055\n",
      "Epoch 178/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7296e-05 - mae: 0.0034\n",
      "Epoch 178: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.7978e-05 - mae: 0.0034 - val_loss: 5.4397e-05 - val_mae: 0.0060\n",
      "Epoch 179/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8948e-05 - mae: 0.0036\n",
      "Epoch 179: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 2.0637e-05 - mae: 0.0037 - val_loss: 4.2668e-05 - val_mae: 0.0053\n",
      "Epoch 180/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.1234e-05 - mae: 0.0037\n",
      "Epoch 180: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 2.2029e-05 - mae: 0.0038 - val_loss: 4.1979e-05 - val_mae: 0.0053\n",
      "Epoch 181/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.8934e-05 - mae: 0.0035\n",
      "Epoch 181: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.8318e-05 - mae: 0.0034 - val_loss: 4.4918e-05 - val_mae: 0.0054\n",
      "Epoch 182/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9364e-05 - mae: 0.0035\n",
      "Epoch 182: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 2.0628e-05 - mae: 0.0037 - val_loss: 5.2247e-05 - val_mae: 0.0059\n",
      "Epoch 183/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.9250e-05 - mae: 0.0035\n",
      "Epoch 183: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.9093e-05 - mae: 0.0035 - val_loss: 4.7605e-05 - val_mae: 0.0056\n",
      "Epoch 184/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6345e-05 - mae: 0.0032\n",
      "Epoch 184: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.6407e-05 - mae: 0.0033 - val_loss: 4.1910e-05 - val_mae: 0.0052\n",
      "Epoch 185/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8581e-05 - mae: 0.0035\n",
      "Epoch 185: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7947e-05 - mae: 0.0034 - val_loss: 4.2172e-05 - val_mae: 0.0053\n",
      "Epoch 186/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6707e-05 - mae: 0.0033\n",
      "Epoch 186: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7308e-05 - mae: 0.0034 - val_loss: 4.1865e-05 - val_mae: 0.0052\n",
      "Epoch 187/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.9365e-05 - mae: 0.0036\n",
      "Epoch 187: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 2.0734e-05 - mae: 0.0037 - val_loss: 4.3175e-05 - val_mae: 0.0053\n",
      "Epoch 188/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6329e-05 - mae: 0.0032\n",
      "Epoch 188: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.8663e-05 - mae: 0.0034 - val_loss: 4.6041e-05 - val_mae: 0.0055\n",
      "Epoch 189/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8287e-05 - mae: 0.0035\n",
      "Epoch 189: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7836e-05 - mae: 0.0034 - val_loss: 4.2953e-05 - val_mae: 0.0053\n",
      "Epoch 190/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8800e-05 - mae: 0.0035\n",
      "Epoch 190: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 2.0004e-05 - mae: 0.0035 - val_loss: 4.2192e-05 - val_mae: 0.0052\n",
      "Epoch 191/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.9199e-05 - mae: 0.0036\n",
      "Epoch 191: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.9027e-05 - mae: 0.0035 - val_loss: 4.6560e-05 - val_mae: 0.0055\n",
      "Epoch 192/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8654e-05 - mae: 0.0035\n",
      "Epoch 192: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.9336e-05 - mae: 0.0035 - val_loss: 4.1604e-05 - val_mae: 0.0052\n",
      "Epoch 193/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6634e-05 - mae: 0.0033\n",
      "Epoch 193: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7862e-05 - mae: 0.0034 - val_loss: 4.4278e-05 - val_mae: 0.0054\n",
      "Epoch 194/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.6684e-05 - mae: 0.0033\n",
      "Epoch 194: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 1.8479e-05 - mae: 0.0035 - val_loss: 4.2636e-05 - val_mae: 0.0053\n",
      "Epoch 195/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 1.8312e-05 - mae: 0.0034\n",
      "Epoch 195: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 1.8959e-05 - mae: 0.0035 - val_loss: 4.2293e-05 - val_mae: 0.0052\n",
      "Epoch 196/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 2.4266e-05 - mae: 0.0039\n",
      "Epoch 196: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 2.3129e-05 - mae: 0.0038 - val_loss: 5.2930e-05 - val_mae: 0.0059\n",
      "Epoch 197/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 2.0028e-05 - mae: 0.0036\n",
      "Epoch 197: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 1.9487e-05 - mae: 0.0035 - val_loss: 4.4370e-05 - val_mae: 0.0054\n",
      "Epoch 198/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.8286e-05 - mae: 0.0035\n",
      "Epoch 198: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 1.8672e-05 - mae: 0.0035 - val_loss: 4.9125e-05 - val_mae: 0.0057\n",
      "Epoch 199/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7748e-05 - mae: 0.0034\n",
      "Epoch 199: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.9306e-05 - mae: 0.0035 - val_loss: 4.2600e-05 - val_mae: 0.0052\n",
      "Epoch 200/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6504e-05 - mae: 0.0032\n",
      "Epoch 200: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6465e-05 - mae: 0.0032 - val_loss: 4.4062e-05 - val_mae: 0.0053\n",
      "Epoch 201/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7122e-05 - mae: 0.0033\n",
      "Epoch 201: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.8264e-05 - mae: 0.0035 - val_loss: 4.2290e-05 - val_mae: 0.0052\n",
      "Epoch 202/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7132e-05 - mae: 0.0034\n",
      "Epoch 202: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.7170e-05 - mae: 0.0034 - val_loss: 5.4108e-05 - val_mae: 0.0059\n",
      "Epoch 203/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6021e-05 - mae: 0.0032\n",
      "Epoch 203: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7344e-05 - mae: 0.0034 - val_loss: 4.3106e-05 - val_mae: 0.0053\n",
      "Epoch 204/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.0585e-05 - mae: 0.0037\n",
      "Epoch 204: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 2.0921e-05 - mae: 0.0037 - val_loss: 4.2381e-05 - val_mae: 0.0053\n",
      "Epoch 205/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6304e-05 - mae: 0.0033\n",
      "Epoch 205: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.7282e-05 - mae: 0.0033 - val_loss: 4.2815e-05 - val_mae: 0.0053\n",
      "Epoch 206/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 2.0799e-05 - mae: 0.0037\n",
      "Epoch 206: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 2.0139e-05 - mae: 0.0036 - val_loss: 4.2395e-05 - val_mae: 0.0053\n",
      "Epoch 207/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7256e-05 - mae: 0.0034\n",
      "Epoch 207: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7874e-05 - mae: 0.0034 - val_loss: 4.2384e-05 - val_mae: 0.0053\n",
      "Epoch 208/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 2.1154e-05 - mae: 0.0037\n",
      "Epoch 208: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.9239e-05 - mae: 0.0035 - val_loss: 4.2488e-05 - val_mae: 0.0053\n",
      "Epoch 209/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7363e-05 - mae: 0.0034\n",
      "Epoch 209: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7448e-05 - mae: 0.0034 - val_loss: 4.8495e-05 - val_mae: 0.0056\n",
      "Epoch 210/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5995e-05 - mae: 0.0032\n",
      "Epoch 210: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6829e-05 - mae: 0.0033 - val_loss: 5.1140e-05 - val_mae: 0.0058\n",
      "Epoch 211/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7667e-05 - mae: 0.0033\n",
      "Epoch 211: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.7970e-05 - mae: 0.0034 - val_loss: 4.2457e-05 - val_mae: 0.0053\n",
      "Epoch 212/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.8411e-05 - mae: 0.0035\n",
      "Epoch 212: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.8287e-05 - mae: 0.0034 - val_loss: 4.3640e-05 - val_mae: 0.0054\n",
      "Epoch 213/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5607e-05 - mae: 0.0031\n",
      "Epoch 213: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.6781e-05 - mae: 0.0033 - val_loss: 4.2561e-05 - val_mae: 0.0053\n",
      "Epoch 214/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.9732e-05 - mae: 0.0035\n",
      "Epoch 214: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.9283e-05 - mae: 0.0035 - val_loss: 5.1251e-05 - val_mae: 0.0058\n",
      "Epoch 215/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8690e-05 - mae: 0.0035\n",
      "Epoch 215: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.9260e-05 - mae: 0.0035 - val_loss: 4.2795e-05 - val_mae: 0.0053\n",
      "Epoch 216/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6858e-05 - mae: 0.0033\n",
      "Epoch 216: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8332e-05 - mae: 0.0034 - val_loss: 4.1786e-05 - val_mae: 0.0052\n",
      "Epoch 217/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.9792e-05 - mae: 0.0036\n",
      "Epoch 217: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7964e-05 - mae: 0.0034 - val_loss: 4.6736e-05 - val_mae: 0.0055\n",
      "Epoch 218/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.8125e-05 - mae: 0.0033\n",
      "Epoch 218: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.7501e-05 - mae: 0.0033 - val_loss: 4.1857e-05 - val_mae: 0.0052\n",
      "Epoch 219/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6795e-05 - mae: 0.0033\n",
      "Epoch 219: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7476e-05 - mae: 0.0034 - val_loss: 4.3436e-05 - val_mae: 0.0053\n",
      "Epoch 220/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7490e-05 - mae: 0.0033\n",
      "Epoch 220: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7545e-05 - mae: 0.0033 - val_loss: 4.2742e-05 - val_mae: 0.0053\n",
      "Epoch 221/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.5907e-05 - mae: 0.0032\n",
      "Epoch 221: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7565e-05 - mae: 0.0033 - val_loss: 4.3687e-05 - val_mae: 0.0053\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/800 [==================>...........] - ETA: 0s - loss: 2.0759e-05 - mae: 0.0037\n",
      "Epoch 222: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.9537e-05 - mae: 0.0035 - val_loss: 4.2890e-05 - val_mae: 0.0053\n",
      "Epoch 223/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7788e-05 - mae: 0.0034\n",
      "Epoch 223: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7622e-05 - mae: 0.0034 - val_loss: 4.2734e-05 - val_mae: 0.0053\n",
      "Epoch 224/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6774e-05 - mae: 0.0033\n",
      "Epoch 224: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7057e-05 - mae: 0.0033 - val_loss: 4.2769e-05 - val_mae: 0.0053\n",
      "Epoch 225/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7215e-05 - mae: 0.0033\n",
      "Epoch 225: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.8435e-05 - mae: 0.0035 - val_loss: 4.2538e-05 - val_mae: 0.0053\n",
      "Epoch 226/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.8442e-05 - mae: 0.0035\n",
      "Epoch 226: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.9333e-05 - mae: 0.0035 - val_loss: 4.2671e-05 - val_mae: 0.0053\n",
      "Epoch 227/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 2.0449e-05 - mae: 0.0036\n",
      "Epoch 227: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 2.0439e-05 - mae: 0.0036 - val_loss: 4.2473e-05 - val_mae: 0.0053\n",
      "Epoch 228/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7754e-05 - mae: 0.0034\n",
      "Epoch 228: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7801e-05 - mae: 0.0034 - val_loss: 4.3380e-05 - val_mae: 0.0053\n",
      "Epoch 229/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7374e-05 - mae: 0.0033\n",
      "Epoch 229: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.8143e-05 - mae: 0.0034 - val_loss: 4.5835e-05 - val_mae: 0.0054\n",
      "Epoch 230/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7851e-05 - mae: 0.0034\n",
      "Epoch 230: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.8054e-05 - mae: 0.0034 - val_loss: 4.2186e-05 - val_mae: 0.0053\n",
      "Epoch 231/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9271e-05 - mae: 0.0036\n",
      "Epoch 231: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 2.1007e-05 - mae: 0.0037 - val_loss: 4.9111e-05 - val_mae: 0.0057\n",
      "Epoch 232/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6689e-05 - mae: 0.0033\n",
      "Epoch 232: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.7000e-05 - mae: 0.0033 - val_loss: 4.2089e-05 - val_mae: 0.0053\n",
      "Epoch 233/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7916e-05 - mae: 0.0034\n",
      "Epoch 233: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8895e-05 - mae: 0.0035 - val_loss: 6.2147e-05 - val_mae: 0.0064\n",
      "Epoch 234/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.0715e-05 - mae: 0.0036\n",
      "Epoch 234: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 2.0542e-05 - mae: 0.0036 - val_loss: 5.4316e-05 - val_mae: 0.0059\n",
      "Epoch 235/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 2.0631e-05 - mae: 0.0036\n",
      "Epoch 235: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 2.3360e-05 - mae: 0.0038 - val_loss: 4.2440e-05 - val_mae: 0.0053\n",
      "Epoch 236/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7461e-05 - mae: 0.0033\n",
      "Epoch 236: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7627e-05 - mae: 0.0033 - val_loss: 4.2717e-05 - val_mae: 0.0053\n",
      "Epoch 237/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.9073e-05 - mae: 0.0035\n",
      "Epoch 237: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.8688e-05 - mae: 0.0034 - val_loss: 4.2090e-05 - val_mae: 0.0053\n",
      "Epoch 238/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6394e-05 - mae: 0.0033\n",
      "Epoch 238: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.8628e-05 - mae: 0.0035 - val_loss: 4.1596e-05 - val_mae: 0.0052\n",
      "Epoch 239/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8351e-05 - mae: 0.0035\n",
      "Epoch 239: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7764e-05 - mae: 0.0034 - val_loss: 4.2015e-05 - val_mae: 0.0052\n",
      "Epoch 240/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9021e-05 - mae: 0.0035\n",
      "Epoch 240: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7737e-05 - mae: 0.0034 - val_loss: 4.2772e-05 - val_mae: 0.0053\n",
      "Epoch 241/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.5735e-05 - mae: 0.0032\n",
      "Epoch 241: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.8500e-05 - mae: 0.0035 - val_loss: 4.2334e-05 - val_mae: 0.0053\n",
      "Epoch 242/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6272e-05 - mae: 0.0032\n",
      "Epoch 242: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.8167e-05 - mae: 0.0034 - val_loss: 5.2186e-05 - val_mae: 0.0058\n",
      "Epoch 243/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 2.0641e-05 - mae: 0.0036\n",
      "Epoch 243: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 2.0106e-05 - mae: 0.0036 - val_loss: 4.4285e-05 - val_mae: 0.0054\n",
      "Epoch 244/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.7543e-05 - mae: 0.0034\n",
      "Epoch 244: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.7319e-05 - mae: 0.0033 - val_loss: 4.1809e-05 - val_mae: 0.0052\n",
      "Epoch 245/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.7837e-05 - mae: 0.0034\n",
      "Epoch 245: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.7462e-05 - mae: 0.0034 - val_loss: 4.2608e-05 - val_mae: 0.0052\n",
      "Epoch 246/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8602e-05 - mae: 0.0034\n",
      "Epoch 246: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.9085e-05 - mae: 0.0035 - val_loss: 4.1983e-05 - val_mae: 0.0052\n",
      "Epoch 247/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7020e-05 - mae: 0.0033\n",
      "Epoch 247: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.7620e-05 - mae: 0.0034 - val_loss: 5.5073e-05 - val_mae: 0.0060\n",
      "Epoch 248/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.7241e-05 - mae: 0.0034\n",
      "Epoch 248: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.6587e-05 - mae: 0.0033 - val_loss: 4.1724e-05 - val_mae: 0.0052\n",
      "Epoch 249/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6013e-05 - mae: 0.0032\n",
      "Epoch 249: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.7045e-05 - mae: 0.0033 - val_loss: 4.1925e-05 - val_mae: 0.0052\n",
      "Epoch 250/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4952e-05 - mae: 0.0032\n",
      "Epoch 250: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6209e-05 - mae: 0.0032 - val_loss: 4.2034e-05 - val_mae: 0.0052\n",
      "Epoch 251/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/800 [=================>............] - ETA: 0s - loss: 1.7586e-05 - mae: 0.0034\n",
      "Epoch 251: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.8943e-05 - mae: 0.0035 - val_loss: 4.8785e-05 - val_mae: 0.0056\n",
      "Epoch 252/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.9741e-05 - mae: 0.0036\n",
      "Epoch 252: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.9663e-05 - mae: 0.0035 - val_loss: 5.2661e-05 - val_mae: 0.0059\n",
      "Epoch 253/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.9264e-05 - mae: 0.0035\n",
      "Epoch 253: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.8344e-05 - mae: 0.0034 - val_loss: 4.2249e-05 - val_mae: 0.0052\n",
      "Epoch 254/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5827e-05 - mae: 0.0032\n",
      "Epoch 254: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6534e-05 - mae: 0.0033 - val_loss: 4.2703e-05 - val_mae: 0.0053\n",
      "Epoch 255/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.9474e-05 - mae: 0.0036\n",
      "Epoch 255: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.9050e-05 - mae: 0.0035 - val_loss: 4.2360e-05 - val_mae: 0.0052\n",
      "Epoch 256/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.8550e-05 - mae: 0.0034\n",
      "Epoch 256: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 2.0455e-05 - mae: 0.0036 - val_loss: 4.8634e-05 - val_mae: 0.0056\n",
      "Epoch 257/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.8980e-05 - mae: 0.0035\n",
      "Epoch 257: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.8457e-05 - mae: 0.0034 - val_loss: 4.1875e-05 - val_mae: 0.0052\n",
      "Epoch 258/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8685e-05 - mae: 0.0035\n",
      "Epoch 258: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.8606e-05 - mae: 0.0035 - val_loss: 4.1893e-05 - val_mae: 0.0052\n",
      "Epoch 259/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.8792e-05 - mae: 0.0034\n",
      "Epoch 259: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.8199e-05 - mae: 0.0034 - val_loss: 4.6129e-05 - val_mae: 0.0055\n",
      "Epoch 260/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7560e-05 - mae: 0.0034\n",
      "Epoch 260: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.6761e-05 - mae: 0.0033 - val_loss: 4.1489e-05 - val_mae: 0.0052\n",
      "Epoch 261/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 2.0944e-05 - mae: 0.0037\n",
      "Epoch 261: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.8599e-05 - mae: 0.0035 - val_loss: 5.2702e-05 - val_mae: 0.0059\n",
      "Epoch 262/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 2.1163e-05 - mae: 0.0038\n",
      "Epoch 262: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 2.0336e-05 - mae: 0.0037 - val_loss: 4.4710e-05 - val_mae: 0.0054\n",
      "Epoch 263/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 2.1397e-05 - mae: 0.0037\n",
      "Epoch 263: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 2.0632e-05 - mae: 0.0037 - val_loss: 4.2810e-05 - val_mae: 0.0053\n",
      "Epoch 264/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6352e-05 - mae: 0.0032\n",
      "Epoch 264: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.7656e-05 - mae: 0.0034 - val_loss: 4.4388e-05 - val_mae: 0.0054\n",
      "Epoch 265/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6449e-05 - mae: 0.0033\n",
      "Epoch 265: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8203e-05 - mae: 0.0035 - val_loss: 4.2006e-05 - val_mae: 0.0052\n",
      "Epoch 266/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6613e-05 - mae: 0.0033\n",
      "Epoch 266: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.6855e-05 - mae: 0.0033 - val_loss: 4.3614e-05 - val_mae: 0.0053\n",
      "Epoch 267/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.1243e-05 - mae: 0.0037\n",
      "Epoch 267: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.9963e-05 - mae: 0.0036 - val_loss: 4.7338e-05 - val_mae: 0.0055\n",
      "Epoch 268/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.8682e-05 - mae: 0.0035\n",
      "Epoch 268: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 1.8470e-05 - mae: 0.0035 - val_loss: 4.5279e-05 - val_mae: 0.0054\n",
      "Epoch 269/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.5971e-05 - mae: 0.0032\n",
      "Epoch 269: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.7347e-05 - mae: 0.0033 - val_loss: 4.2512e-05 - val_mae: 0.0052\n",
      "Epoch 270/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 2.0067e-05 - mae: 0.0036\n",
      "Epoch 270: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 2.0294e-05 - mae: 0.0036 - val_loss: 4.2365e-05 - val_mae: 0.0052\n",
      "Epoch 271/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 1.7171e-05 - mae: 0.0033\n",
      "Epoch 271: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 1.7898e-05 - mae: 0.0034 - val_loss: 4.1585e-05 - val_mae: 0.0052\n",
      "Epoch 272/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 1.7561e-05 - mae: 0.0034\n",
      "Epoch 272: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 1.7883e-05 - mae: 0.0034 - val_loss: 4.1809e-05 - val_mae: 0.0052\n",
      "Epoch 273/1000\n",
      "580/800 [====================>.........] - ETA: 0s - loss: 2.4463e-05 - mae: 0.0039\n",
      "Epoch 273: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 2.4525e-05 - mae: 0.0040 - val_loss: 4.2518e-05 - val_mae: 0.0053\n",
      "Epoch 274/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 1.7358e-05 - mae: 0.0033\n",
      "Epoch 274: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 1.8379e-05 - mae: 0.0034 - val_loss: 4.2850e-05 - val_mae: 0.0053\n",
      "Epoch 275/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 1.8393e-05 - mae: 0.0034\n",
      "Epoch 275: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 1.8059e-05 - mae: 0.0034 - val_loss: 4.2339e-05 - val_mae: 0.0052\n",
      "Epoch 276/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 1.7178e-05 - mae: 0.0034\n",
      "Epoch 276: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.6967e-05 - mae: 0.0033 - val_loss: 4.3467e-05 - val_mae: 0.0053\n",
      "Epoch 277/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 2.2377e-05 - mae: 0.0038\n",
      "Epoch 277: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 2.0933e-05 - mae: 0.0037 - val_loss: 4.2869e-05 - val_mae: 0.0053\n",
      "Epoch 278/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 1.7138e-05 - mae: 0.0033\n",
      "Epoch 278: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 1.7744e-05 - mae: 0.0034 - val_loss: 4.2026e-05 - val_mae: 0.0052\n",
      "Epoch 279/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 1.8629e-05 - mae: 0.0034\n",
      "Epoch 279: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 1.9202e-05 - mae: 0.0035 - val_loss: 4.3037e-05 - val_mae: 0.0053\n",
      "Epoch 280/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/800 [======================>.......] - ETA: 0s - loss: 1.6563e-05 - mae: 0.0033\n",
      "Epoch 280: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 1.6588e-05 - mae: 0.0032 - val_loss: 4.2312e-05 - val_mae: 0.0052\n",
      "Epoch 281/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 1.6792e-05 - mae: 0.0033\n",
      "Epoch 281: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.6649e-05 - mae: 0.0033 - val_loss: 4.4432e-05 - val_mae: 0.0054\n",
      "Epoch 282/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 1.6820e-05 - mae: 0.0033\n",
      "Epoch 282: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 1.7158e-05 - mae: 0.0033 - val_loss: 4.2512e-05 - val_mae: 0.0053\n",
      "Epoch 283/1000\n",
      "580/800 [====================>.........] - ETA: 0s - loss: 1.8575e-05 - mae: 0.0035\n",
      "Epoch 283: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 1.7696e-05 - mae: 0.0034 - val_loss: 4.1892e-05 - val_mae: 0.0052\n",
      "Epoch 284/1000\n",
      "580/800 [====================>.........] - ETA: 0s - loss: 2.0072e-05 - mae: 0.0035\n",
      "Epoch 284: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 2.1358e-05 - mae: 0.0037 - val_loss: 4.3396e-05 - val_mae: 0.0053\n",
      "Epoch 285/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.6464e-05 - mae: 0.0032\n",
      "Epoch 285: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.6032e-05 - mae: 0.0032 - val_loss: 4.1831e-05 - val_mae: 0.0052\n",
      "Epoch 286/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.7492e-05 - mae: 0.0033\n",
      "Epoch 286: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.8449e-05 - mae: 0.0035 - val_loss: 4.3211e-05 - val_mae: 0.0053\n",
      "Epoch 287/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.7441e-05 - mae: 0.0034\n",
      "Epoch 287: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 1.6655e-05 - mae: 0.0033 - val_loss: 4.2201e-05 - val_mae: 0.0053\n",
      "Epoch 288/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.6882e-05 - mae: 0.0033\n",
      "Epoch 288: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 1.7191e-05 - mae: 0.0033 - val_loss: 4.2984e-05 - val_mae: 0.0053\n",
      "Epoch 289/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 2.0936e-05 - mae: 0.0036\n",
      "Epoch 289: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.9844e-05 - mae: 0.0035 - val_loss: 4.3043e-05 - val_mae: 0.0053\n",
      "Epoch 290/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7107e-05 - mae: 0.0033\n",
      "Epoch 290: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7543e-05 - mae: 0.0034 - val_loss: 4.6289e-05 - val_mae: 0.0055\n",
      "Epoch 291/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8335e-05 - mae: 0.0035\n",
      "Epoch 291: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.8547e-05 - mae: 0.0034 - val_loss: 4.3321e-05 - val_mae: 0.0053\n",
      "Epoch 292/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5016e-05 - mae: 0.0032\n",
      "Epoch 292: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.6547e-05 - mae: 0.0033 - val_loss: 4.1506e-05 - val_mae: 0.0052\n",
      "Epoch 293/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 2.1335e-05 - mae: 0.0037\n",
      "Epoch 293: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.9404e-05 - mae: 0.0035 - val_loss: 4.4945e-05 - val_mae: 0.0054\n",
      "Epoch 294/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6985e-05 - mae: 0.0033\n",
      "Epoch 294: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7947e-05 - mae: 0.0034 - val_loss: 4.1448e-05 - val_mae: 0.0052\n",
      "Epoch 295/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7863e-05 - mae: 0.0034\n",
      "Epoch 295: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.8197e-05 - mae: 0.0034 - val_loss: 4.7193e-05 - val_mae: 0.0055\n",
      "Epoch 296/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7544e-05 - mae: 0.0034\n",
      "Epoch 296: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7387e-05 - mae: 0.0034 - val_loss: 4.1952e-05 - val_mae: 0.0052\n",
      "Epoch 297/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6096e-05 - mae: 0.0032\n",
      "Epoch 297: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7744e-05 - mae: 0.0033 - val_loss: 6.1071e-05 - val_mae: 0.0063\n",
      "Epoch 298/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 2.2428e-05 - mae: 0.0039\n",
      "Epoch 298: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 2.1472e-05 - mae: 0.0037 - val_loss: 4.3414e-05 - val_mae: 0.0053\n",
      "Epoch 299/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.8339e-05 - mae: 0.0034\n",
      "Epoch 299: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7296e-05 - mae: 0.0033 - val_loss: 4.8600e-05 - val_mae: 0.0056\n",
      "Epoch 300/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8926e-05 - mae: 0.0035\n",
      "Epoch 300: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.8577e-05 - mae: 0.0035 - val_loss: 4.1980e-05 - val_mae: 0.0052\n",
      "Epoch 301/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7393e-05 - mae: 0.0033\n",
      "Epoch 301: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7433e-05 - mae: 0.0034 - val_loss: 4.1879e-05 - val_mae: 0.0052\n",
      "Epoch 302/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6917e-05 - mae: 0.0033\n",
      "Epoch 302: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.7847e-05 - mae: 0.0034 - val_loss: 4.2077e-05 - val_mae: 0.0052\n",
      "Epoch 303/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6997e-05 - mae: 0.0033\n",
      "Epoch 303: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.7737e-05 - mae: 0.0034 - val_loss: 4.2459e-05 - val_mae: 0.0053\n",
      "Epoch 304/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6908e-05 - mae: 0.0033\n",
      "Epoch 304: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.6866e-05 - mae: 0.0033 - val_loss: 4.2209e-05 - val_mae: 0.0053\n",
      "Epoch 305/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6428e-05 - mae: 0.0032\n",
      "Epoch 305: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7408e-05 - mae: 0.0034 - val_loss: 4.3188e-05 - val_mae: 0.0053\n",
      "Epoch 306/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7846e-05 - mae: 0.0034\n",
      "Epoch 306: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7576e-05 - mae: 0.0033 - val_loss: 4.1945e-05 - val_mae: 0.0052\n",
      "Epoch 307/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6372e-05 - mae: 0.0033\n",
      "Epoch 307: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.6812e-05 - mae: 0.0033 - val_loss: 4.4375e-05 - val_mae: 0.0054\n",
      "Epoch 308/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9420e-05 - mae: 0.0035\n",
      "Epoch 308: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.9491e-05 - mae: 0.0035 - val_loss: 4.2231e-05 - val_mae: 0.0052\n",
      "Epoch 309/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490/800 [=================>............] - ETA: 0s - loss: 1.9221e-05 - mae: 0.0035\n",
      "Epoch 309: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.8123e-05 - mae: 0.0034 - val_loss: 4.2361e-05 - val_mae: 0.0053\n",
      "Epoch 310/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.8068e-05 - mae: 0.0034\n",
      "Epoch 310: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 1.8508e-05 - mae: 0.0034 - val_loss: 4.2409e-05 - val_mae: 0.0053\n",
      "Epoch 311/1000\n",
      "570/800 [====================>.........] - ETA: 0s - loss: 1.6619e-05 - mae: 0.0033\n",
      "Epoch 311: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 1.7297e-05 - mae: 0.0033 - val_loss: 5.1428e-05 - val_mae: 0.0058\n",
      "Epoch 312/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 2.0213e-05 - mae: 0.0036\n",
      "Epoch 312: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 2.0166e-05 - mae: 0.0036 - val_loss: 5.2172e-05 - val_mae: 0.0058\n",
      "Epoch 313/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 1.8403e-05 - mae: 0.0034\n",
      "Epoch 313: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 1.8698e-05 - mae: 0.0035 - val_loss: 4.4567e-05 - val_mae: 0.0054\n",
      "Epoch 314/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 1.5827e-05 - mae: 0.0032\n",
      "Epoch 314: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 1.7389e-05 - mae: 0.0034 - val_loss: 4.5052e-05 - val_mae: 0.0054\n",
      "Epoch 315/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.6999e-05 - mae: 0.0033\n",
      "Epoch 315: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 1.7621e-05 - mae: 0.0033 - val_loss: 5.3319e-05 - val_mae: 0.0059\n",
      "Epoch 316/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7789e-05 - mae: 0.0033\n",
      "Epoch 316: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.8047e-05 - mae: 0.0034 - val_loss: 4.3257e-05 - val_mae: 0.0053\n",
      "Epoch 317/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7137e-05 - mae: 0.0033\n",
      "Epoch 317: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.8218e-05 - mae: 0.0034 - val_loss: 4.3803e-05 - val_mae: 0.0054\n",
      "Epoch 318/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6996e-05 - mae: 0.0033\n",
      "Epoch 318: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.7021e-05 - mae: 0.0033 - val_loss: 4.2503e-05 - val_mae: 0.0053\n",
      "Epoch 319/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6712e-05 - mae: 0.0033\n",
      "Epoch 319: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7315e-05 - mae: 0.0033 - val_loss: 4.2466e-05 - val_mae: 0.0053\n",
      "Epoch 320/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.9467e-05 - mae: 0.0036\n",
      "Epoch 320: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.8658e-05 - mae: 0.0035 - val_loss: 4.6038e-05 - val_mae: 0.0055\n",
      "Epoch 321/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7860e-05 - mae: 0.0034\n",
      "Epoch 321: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7432e-05 - mae: 0.0034 - val_loss: 4.7136e-05 - val_mae: 0.0055\n",
      "Epoch 322/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7967e-05 - mae: 0.0033\n",
      "Epoch 322: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7530e-05 - mae: 0.0033 - val_loss: 4.2244e-05 - val_mae: 0.0052\n",
      "Epoch 323/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7278e-05 - mae: 0.0033\n",
      "Epoch 323: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8540e-05 - mae: 0.0034 - val_loss: 4.2832e-05 - val_mae: 0.0053\n",
      "Epoch 324/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.5903e-05 - mae: 0.0032\n",
      "Epoch 324: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.6559e-05 - mae: 0.0033 - val_loss: 4.5321e-05 - val_mae: 0.0054\n",
      "Epoch 325/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 2.0113e-05 - mae: 0.0036\n",
      "Epoch 325: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 2.0091e-05 - mae: 0.0036 - val_loss: 4.4082e-05 - val_mae: 0.0054\n",
      "Epoch 326/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 1.8170e-05 - mae: 0.0034\n",
      "Epoch 326: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.8612e-05 - mae: 0.0035 - val_loss: 5.1830e-05 - val_mae: 0.0058\n",
      "Epoch 327/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 2.0672e-05 - mae: 0.0037\n",
      "Epoch 327: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 2.0691e-05 - mae: 0.0037 - val_loss: 4.6945e-05 - val_mae: 0.0055\n",
      "Epoch 328/1000\n",
      "630/800 [======================>.......] - ETA: 0s - loss: 1.7594e-05 - mae: 0.0033\n",
      "Epoch 328: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 1.7849e-05 - mae: 0.0034 - val_loss: 4.1948e-05 - val_mae: 0.0052\n",
      "Epoch 329/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 1.7475e-05 - mae: 0.0034\n",
      "Epoch 329: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.8326e-05 - mae: 0.0035 - val_loss: 4.6132e-05 - val_mae: 0.0055\n",
      "Epoch 330/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 1.8313e-05 - mae: 0.0034\n",
      "Epoch 330: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.9305e-05 - mae: 0.0035 - val_loss: 4.5263e-05 - val_mae: 0.0054\n",
      "Epoch 331/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 2.1525e-05 - mae: 0.0038\n",
      "Epoch 331: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 2.0929e-05 - mae: 0.0037 - val_loss: 4.1775e-05 - val_mae: 0.0052\n",
      "Epoch 332/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 1.7633e-05 - mae: 0.0034\n",
      "Epoch 332: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 1.9076e-05 - mae: 0.0035 - val_loss: 5.3524e-05 - val_mae: 0.0059\n",
      "Epoch 333/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.8540e-05 - mae: 0.0035\n",
      "Epoch 333: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 1.7489e-05 - mae: 0.0034 - val_loss: 4.3270e-05 - val_mae: 0.0053\n",
      "Epoch 334/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7290e-05 - mae: 0.0033\n",
      "Epoch 334: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.7786e-05 - mae: 0.0034 - val_loss: 4.1966e-05 - val_mae: 0.0052\n",
      "Epoch 335/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6626e-05 - mae: 0.0033\n",
      "Epoch 335: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7027e-05 - mae: 0.0033 - val_loss: 4.1799e-05 - val_mae: 0.0052\n",
      "Epoch 336/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.9576e-05 - mae: 0.0035\n",
      "Epoch 336: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.9522e-05 - mae: 0.0035 - val_loss: 4.2642e-05 - val_mae: 0.0053\n",
      "Epoch 337/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 2.2266e-05 - mae: 0.0038\n",
      "Epoch 337: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 2.0645e-05 - mae: 0.0036 - val_loss: 4.2749e-05 - val_mae: 0.0053\n",
      "Epoch 338/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/800 [================>.............] - ETA: 0s - loss: 1.6001e-05 - mae: 0.0032\n",
      "Epoch 338: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.6575e-05 - mae: 0.0033 - val_loss: 4.1834e-05 - val_mae: 0.0052\n",
      "Epoch 339/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6050e-05 - mae: 0.0032\n",
      "Epoch 339: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7255e-05 - mae: 0.0033 - val_loss: 4.2274e-05 - val_mae: 0.0053\n",
      "Epoch 340/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7435e-05 - mae: 0.0033\n",
      "Epoch 340: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.8030e-05 - mae: 0.0033 - val_loss: 4.2275e-05 - val_mae: 0.0053\n",
      "Epoch 341/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9228e-05 - mae: 0.0036\n",
      "Epoch 341: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 2.0604e-05 - mae: 0.0037 - val_loss: 5.0832e-05 - val_mae: 0.0058\n",
      "Epoch 342/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8578e-05 - mae: 0.0034\n",
      "Epoch 342: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.9250e-05 - mae: 0.0035 - val_loss: 5.0965e-05 - val_mae: 0.0058\n",
      "Epoch 343/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8930e-05 - mae: 0.0035\n",
      "Epoch 343: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.8795e-05 - mae: 0.0035 - val_loss: 4.1519e-05 - val_mae: 0.0052\n",
      "Epoch 344/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.5929e-05 - mae: 0.0032\n",
      "Epoch 344: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.6615e-05 - mae: 0.0033 - val_loss: 4.2080e-05 - val_mae: 0.0052\n",
      "Epoch 345/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.0153e-05 - mae: 0.0036\n",
      "Epoch 345: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.9391e-05 - mae: 0.0035 - val_loss: 4.3540e-05 - val_mae: 0.0053\n",
      "Epoch 346/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 2.0371e-05 - mae: 0.0036\n",
      "Epoch 346: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.9127e-05 - mae: 0.0035 - val_loss: 4.2019e-05 - val_mae: 0.0052\n",
      "Epoch 347/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7816e-05 - mae: 0.0034\n",
      "Epoch 347: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.8673e-05 - mae: 0.0034 - val_loss: 4.2363e-05 - val_mae: 0.0052\n",
      "Epoch 348/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7636e-05 - mae: 0.0034\n",
      "Epoch 348: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.8275e-05 - mae: 0.0035 - val_loss: 4.1526e-05 - val_mae: 0.0052\n",
      "Epoch 349/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.6977e-05 - mae: 0.0033\n",
      "Epoch 349: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 1.7099e-05 - mae: 0.0033 - val_loss: 4.1971e-05 - val_mae: 0.0052\n",
      "Epoch 350/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7288e-05 - mae: 0.0033\n",
      "Epoch 350: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.8081e-05 - mae: 0.0034 - val_loss: 4.2736e-05 - val_mae: 0.0053\n",
      "Epoch 351/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 2.0975e-05 - mae: 0.0036\n",
      "Epoch 351: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 2.0768e-05 - mae: 0.0037 - val_loss: 4.2097e-05 - val_mae: 0.0053\n",
      "Epoch 352/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6943e-05 - mae: 0.0033\n",
      "Epoch 352: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7542e-05 - mae: 0.0034 - val_loss: 4.2013e-05 - val_mae: 0.0053\n",
      "Epoch 353/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6409e-05 - mae: 0.0033\n",
      "Epoch 353: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7712e-05 - mae: 0.0034 - val_loss: 4.6328e-05 - val_mae: 0.0055\n",
      "Epoch 354/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7239e-05 - mae: 0.0033\n",
      "Epoch 354: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.7668e-05 - mae: 0.0033 - val_loss: 4.1570e-05 - val_mae: 0.0052\n",
      "Epoch 355/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7608e-05 - mae: 0.0034\n",
      "Epoch 355: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7232e-05 - mae: 0.0034 - val_loss: 4.5378e-05 - val_mae: 0.0054\n",
      "Epoch 356/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.8046e-05 - mae: 0.0034\n",
      "Epoch 356: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.9184e-05 - mae: 0.0035 - val_loss: 4.1851e-05 - val_mae: 0.0052\n",
      "Epoch 357/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6210e-05 - mae: 0.0032\n",
      "Epoch 357: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8582e-05 - mae: 0.0035 - val_loss: 4.8790e-05 - val_mae: 0.0057\n",
      "Epoch 358/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6711e-05 - mae: 0.0032\n",
      "Epoch 358: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.8143e-05 - mae: 0.0034 - val_loss: 4.2236e-05 - val_mae: 0.0053\n",
      "Epoch 359/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8633e-05 - mae: 0.0034\n",
      "Epoch 359: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.8111e-05 - mae: 0.0034 - val_loss: 4.2005e-05 - val_mae: 0.0052\n",
      "Epoch 360/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.5228e-05 - mae: 0.0032\n",
      "Epoch 360: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7749e-05 - mae: 0.0034 - val_loss: 4.6104e-05 - val_mae: 0.0055\n",
      "Epoch 361/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7071e-05 - mae: 0.0033\n",
      "Epoch 361: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.8441e-05 - mae: 0.0034 - val_loss: 4.1588e-05 - val_mae: 0.0052\n",
      "Epoch 362/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.8142e-05 - mae: 0.0034\n",
      "Epoch 362: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 1.7088e-05 - mae: 0.0033 - val_loss: 4.6548e-05 - val_mae: 0.0055\n",
      "Epoch 363/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.8995e-05 - mae: 0.0035\n",
      "Epoch 363: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 2.0033e-05 - mae: 0.0036 - val_loss: 4.2178e-05 - val_mae: 0.0053\n",
      "Epoch 364/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 1.8258e-05 - mae: 0.0034\n",
      "Epoch 364: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 1.7777e-05 - mae: 0.0034 - val_loss: 4.2029e-05 - val_mae: 0.0052\n",
      "Epoch 365/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 1.8988e-05 - mae: 0.0035\n",
      "Epoch 365: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 1.9117e-05 - mae: 0.0035 - val_loss: 4.1818e-05 - val_mae: 0.0052\n",
      "Epoch 366/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.7266e-05 - mae: 0.0034\n",
      "Epoch 366: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 1.8605e-05 - mae: 0.0035 - val_loss: 4.2047e-05 - val_mae: 0.0052\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530/800 [==================>...........] - ETA: 0s - loss: 1.7001e-05 - mae: 0.0033\n",
      "Epoch 367: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.8474e-05 - mae: 0.0034 - val_loss: 4.7310e-05 - val_mae: 0.0056\n",
      "Epoch 368/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6612e-05 - mae: 0.0033\n",
      "Epoch 368: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7496e-05 - mae: 0.0034 - val_loss: 4.2310e-05 - val_mae: 0.0053\n",
      "Epoch 369/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6604e-05 - mae: 0.0033\n",
      "Epoch 369: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7385e-05 - mae: 0.0034 - val_loss: 4.2238e-05 - val_mae: 0.0053\n",
      "Epoch 370/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6748e-05 - mae: 0.0033\n",
      "Epoch 370: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8527e-05 - mae: 0.0035 - val_loss: 4.2743e-05 - val_mae: 0.0053\n",
      "Epoch 371/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6145e-05 - mae: 0.0033\n",
      "Epoch 371: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7989e-05 - mae: 0.0034 - val_loss: 4.1936e-05 - val_mae: 0.0052\n",
      "Epoch 372/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7156e-05 - mae: 0.0033\n",
      "Epoch 372: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.8083e-05 - mae: 0.0034 - val_loss: 4.6662e-05 - val_mae: 0.0055\n",
      "Epoch 373/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8745e-05 - mae: 0.0035\n",
      "Epoch 373: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.8795e-05 - mae: 0.0035 - val_loss: 4.1740e-05 - val_mae: 0.0052\n",
      "Epoch 374/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7022e-05 - mae: 0.0033\n",
      "Epoch 374: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.7760e-05 - mae: 0.0034 - val_loss: 4.3489e-05 - val_mae: 0.0053\n",
      "Epoch 375/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7676e-05 - mae: 0.0034\n",
      "Epoch 375: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.8459e-05 - mae: 0.0035 - val_loss: 4.1715e-05 - val_mae: 0.0052\n",
      "Epoch 376/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7615e-05 - mae: 0.0034\n",
      "Epoch 376: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.8771e-05 - mae: 0.0035 - val_loss: 6.2620e-05 - val_mae: 0.0064\n",
      "Epoch 377/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 2.2323e-05 - mae: 0.0038\n",
      "Epoch 377: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 2.0320e-05 - mae: 0.0037 - val_loss: 4.2198e-05 - val_mae: 0.0052\n",
      "Epoch 378/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6619e-05 - mae: 0.0032\n",
      "Epoch 378: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.6725e-05 - mae: 0.0033 - val_loss: 4.1775e-05 - val_mae: 0.0052\n",
      "Epoch 379/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7179e-05 - mae: 0.0034\n",
      "Epoch 379: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.8620e-05 - mae: 0.0034 - val_loss: 5.0466e-05 - val_mae: 0.0057\n",
      "Epoch 380/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8034e-05 - mae: 0.0034\n",
      "Epoch 380: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.8606e-05 - mae: 0.0035 - val_loss: 4.1563e-05 - val_mae: 0.0052\n",
      "Epoch 381/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.6278e-05 - mae: 0.0032\n",
      "Epoch 381: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.6536e-05 - mae: 0.0032 - val_loss: 4.2998e-05 - val_mae: 0.0053\n",
      "Epoch 382/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5476e-05 - mae: 0.0032\n",
      "Epoch 382: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6495e-05 - mae: 0.0033 - val_loss: 4.3310e-05 - val_mae: 0.0053\n",
      "Epoch 383/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.9417e-05 - mae: 0.0035\n",
      "Epoch 383: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.9692e-05 - mae: 0.0035 - val_loss: 4.8973e-05 - val_mae: 0.0057\n",
      "Epoch 384/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7326e-05 - mae: 0.0033\n",
      "Epoch 384: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.8431e-05 - mae: 0.0034 - val_loss: 4.2551e-05 - val_mae: 0.0053\n",
      "Epoch 385/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7263e-05 - mae: 0.0034\n",
      "Epoch 385: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.6422e-05 - mae: 0.0033 - val_loss: 4.2230e-05 - val_mae: 0.0053\n",
      "Epoch 386/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.5319e-05 - mae: 0.0031\n",
      "Epoch 386: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.6608e-05 - mae: 0.0032 - val_loss: 4.5985e-05 - val_mae: 0.0055\n",
      "Epoch 387/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6949e-05 - mae: 0.0033\n",
      "Epoch 387: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.8005e-05 - mae: 0.0034 - val_loss: 4.1739e-05 - val_mae: 0.0052\n",
      "Epoch 388/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7236e-05 - mae: 0.0033\n",
      "Epoch 388: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.6508e-05 - mae: 0.0032 - val_loss: 4.1822e-05 - val_mae: 0.0052\n",
      "Epoch 389/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.5749e-05 - mae: 0.0032\n",
      "Epoch 389: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.6335e-05 - mae: 0.0032 - val_loss: 5.4862e-05 - val_mae: 0.0060\n",
      "Epoch 390/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 2.0397e-05 - mae: 0.0036\n",
      "Epoch 390: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 2.0058e-05 - mae: 0.0036 - val_loss: 4.6343e-05 - val_mae: 0.0055\n",
      "Epoch 391/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.9254e-05 - mae: 0.0035\n",
      "Epoch 391: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 2.0191e-05 - mae: 0.0036 - val_loss: 4.3775e-05 - val_mae: 0.0053\n",
      "Epoch 392/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7744e-05 - mae: 0.0033\n",
      "Epoch 392: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 2.0890e-05 - mae: 0.0036 - val_loss: 4.8519e-05 - val_mae: 0.0056\n",
      "Epoch 393/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6845e-05 - mae: 0.0033\n",
      "Epoch 393: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.6993e-05 - mae: 0.0033 - val_loss: 4.7282e-05 - val_mae: 0.0055\n",
      "Epoch 394/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6452e-05 - mae: 0.0033\n",
      "Epoch 394: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 1.7709e-05 - mae: 0.0034 - val_loss: 4.4076e-05 - val_mae: 0.0053\n",
      "Epoch 395/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6771e-05 - mae: 0.0033\n",
      "Epoch 395: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.6352e-05 - mae: 0.0032 - val_loss: 4.2005e-05 - val_mae: 0.0053\n",
      "Epoch 396/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7394e-05 - mae: 0.0033\n",
      "Epoch 396: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.6976e-05 - mae: 0.0033 - val_loss: 4.3582e-05 - val_mae: 0.0053\n",
      "Epoch 397/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.6548e-05 - mae: 0.0033\n",
      "Epoch 397: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.7206e-05 - mae: 0.0033 - val_loss: 4.7461e-05 - val_mae: 0.0056\n",
      "Epoch 398/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7423e-05 - mae: 0.0034\n",
      "Epoch 398: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7853e-05 - mae: 0.0034 - val_loss: 4.2107e-05 - val_mae: 0.0052\n",
      "Epoch 399/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6921e-05 - mae: 0.0033\n",
      "Epoch 399: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.8619e-05 - mae: 0.0034 - val_loss: 4.9474e-05 - val_mae: 0.0057\n",
      "Epoch 400/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6562e-05 - mae: 0.0033\n",
      "Epoch 400: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.6862e-05 - mae: 0.0033 - val_loss: 4.7154e-05 - val_mae: 0.0055\n",
      "Epoch 401/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7262e-05 - mae: 0.0034\n",
      "Epoch 401: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.8155e-05 - mae: 0.0035 - val_loss: 4.1925e-05 - val_mae: 0.0052\n",
      "Epoch 402/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 1.6817e-05 - mae: 0.0033\n",
      "Epoch 402: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 1.7421e-05 - mae: 0.0034 - val_loss: 4.2016e-05 - val_mae: 0.0052\n",
      "Epoch 403/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 1.8622e-05 - mae: 0.0034\n",
      "Epoch 403: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 1.8333e-05 - mae: 0.0034 - val_loss: 4.2000e-05 - val_mae: 0.0052\n",
      "Epoch 404/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 1.7898e-05 - mae: 0.0034\n",
      "Epoch 404: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 1.8039e-05 - mae: 0.0034 - val_loss: 4.2508e-05 - val_mae: 0.0053\n",
      "Epoch 405/1000\n",
      "620/800 [======================>.......] - ETA: 0s - loss: 1.7891e-05 - mae: 0.0035\n",
      "Epoch 405: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.8848e-05 - mae: 0.0035 - val_loss: 4.1752e-05 - val_mae: 0.0052\n",
      "Epoch 406/1000\n",
      "630/800 [======================>.......] - ETA: 0s - loss: 1.7791e-05 - mae: 0.0034\n",
      "Epoch 406: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 1.8183e-05 - mae: 0.0034 - val_loss: 4.5549e-05 - val_mae: 0.0054\n",
      "Epoch 407/1000\n",
      "630/800 [======================>.......] - ETA: 0s - loss: 1.8562e-05 - mae: 0.0034\n",
      "Epoch 407: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 1.8154e-05 - mae: 0.0034 - val_loss: 5.8079e-05 - val_mae: 0.0062\n",
      "Epoch 408/1000\n",
      "610/800 [=====================>........] - ETA: 0s - loss: 1.7235e-05 - mae: 0.0034\n",
      "Epoch 408: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 1.7952e-05 - mae: 0.0034 - val_loss: 4.1599e-05 - val_mae: 0.0052\n",
      "Epoch 409/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 1.8900e-05 - mae: 0.0035\n",
      "Epoch 409: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 2.1553e-05 - mae: 0.0037 - val_loss: 5.4655e-05 - val_mae: 0.0060\n",
      "Epoch 410/1000\n",
      "630/800 [======================>.......] - ETA: 0s - loss: 1.9823e-05 - mae: 0.0036\n",
      "Epoch 410: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.9091e-05 - mae: 0.0035 - val_loss: 4.2770e-05 - val_mae: 0.0053\n",
      "Epoch 411/1000\n",
      "570/800 [====================>.........] - ETA: 0s - loss: 1.5840e-05 - mae: 0.0032\n",
      "Epoch 411: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.6981e-05 - mae: 0.0033 - val_loss: 4.6252e-05 - val_mae: 0.0055\n",
      "Epoch 412/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9149e-05 - mae: 0.0035\n",
      "Epoch 412: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.9931e-05 - mae: 0.0036 - val_loss: 4.4980e-05 - val_mae: 0.0054\n",
      "Epoch 413/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6894e-05 - mae: 0.0033\n",
      "Epoch 413: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.6939e-05 - mae: 0.0033 - val_loss: 4.1253e-05 - val_mae: 0.0052\n",
      "Epoch 414/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7045e-05 - mae: 0.0033\n",
      "Epoch 414: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.8181e-05 - mae: 0.0034 - val_loss: 4.7971e-05 - val_mae: 0.0056\n",
      "Epoch 415/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8584e-05 - mae: 0.0034\n",
      "Epoch 415: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.8292e-05 - mae: 0.0034 - val_loss: 4.1442e-05 - val_mae: 0.0052\n",
      "Epoch 416/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.8437e-05 - mae: 0.0035\n",
      "Epoch 416: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.7839e-05 - mae: 0.0034 - val_loss: 5.0438e-05 - val_mae: 0.0057\n",
      "Epoch 417/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5853e-05 - mae: 0.0032\n",
      "Epoch 417: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6729e-05 - mae: 0.0033 - val_loss: 4.1429e-05 - val_mae: 0.0052\n",
      "Epoch 418/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 2.2320e-05 - mae: 0.0038\n",
      "Epoch 418: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 2.1172e-05 - mae: 0.0037 - val_loss: 6.8693e-05 - val_mae: 0.0068\n",
      "Epoch 419/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 2.0382e-05 - mae: 0.0036\n",
      "Epoch 419: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.9415e-05 - mae: 0.0036 - val_loss: 4.2838e-05 - val_mae: 0.0053\n",
      "Epoch 420/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5140e-05 - mae: 0.0031\n",
      "Epoch 420: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7064e-05 - mae: 0.0033 - val_loss: 4.2461e-05 - val_mae: 0.0053\n",
      "Epoch 421/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7345e-05 - mae: 0.0033\n",
      "Epoch 421: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7264e-05 - mae: 0.0033 - val_loss: 4.6515e-05 - val_mae: 0.0055\n",
      "Epoch 422/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7413e-05 - mae: 0.0034\n",
      "Epoch 422: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.7843e-05 - mae: 0.0034 - val_loss: 4.3410e-05 - val_mae: 0.0053\n",
      "Epoch 423/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6451e-05 - mae: 0.0032\n",
      "Epoch 423: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7132e-05 - mae: 0.0033 - val_loss: 4.5771e-05 - val_mae: 0.0055\n",
      "Epoch 424/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6855e-05 - mae: 0.0033\n",
      "Epoch 424: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8999e-05 - mae: 0.0035 - val_loss: 4.2993e-05 - val_mae: 0.0053\n",
      "Epoch 425/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6222e-05 - mae: 0.0032\n",
      "Epoch 425: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.6202e-05 - mae: 0.0032 - val_loss: 4.2806e-05 - val_mae: 0.0053\n",
      "Epoch 426/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7981e-05 - mae: 0.0034\n",
      "Epoch 426: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.8617e-05 - mae: 0.0035 - val_loss: 4.7320e-05 - val_mae: 0.0055\n",
      "Epoch 427/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.9503e-05 - mae: 0.0035\n",
      "Epoch 427: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.8681e-05 - mae: 0.0034 - val_loss: 4.1868e-05 - val_mae: 0.0052\n",
      "Epoch 428/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.7894e-05 - mae: 0.0034\n",
      "Epoch 428: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.8754e-05 - mae: 0.0035 - val_loss: 4.6940e-05 - val_mae: 0.0055\n",
      "Epoch 429/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 2.1022e-05 - mae: 0.0037\n",
      "Epoch 429: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.9097e-05 - mae: 0.0035 - val_loss: 4.2603e-05 - val_mae: 0.0053\n",
      "Epoch 430/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6911e-05 - mae: 0.0033\n",
      "Epoch 430: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.6954e-05 - mae: 0.0033 - val_loss: 4.9608e-05 - val_mae: 0.0056\n",
      "Epoch 431/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6600e-05 - mae: 0.0032\n",
      "Epoch 431: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7361e-05 - mae: 0.0033 - val_loss: 4.1502e-05 - val_mae: 0.0052\n",
      "Epoch 432/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7382e-05 - mae: 0.0034\n",
      "Epoch 432: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.9865e-05 - mae: 0.0036 - val_loss: 4.2579e-05 - val_mae: 0.0052\n",
      "Epoch 433/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6987e-05 - mae: 0.0033\n",
      "Epoch 433: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7712e-05 - mae: 0.0034 - val_loss: 4.3419e-05 - val_mae: 0.0053\n",
      "Epoch 434/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.8181e-05 - mae: 0.0034\n",
      "Epoch 434: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.7814e-05 - mae: 0.0034 - val_loss: 4.1837e-05 - val_mae: 0.0052\n",
      "Epoch 435/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6778e-05 - mae: 0.0033\n",
      "Epoch 435: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.6912e-05 - mae: 0.0033 - val_loss: 4.1625e-05 - val_mae: 0.0052\n",
      "Epoch 436/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5193e-05 - mae: 0.0031\n",
      "Epoch 436: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7214e-05 - mae: 0.0033 - val_loss: 4.2774e-05 - val_mae: 0.0053\n",
      "Epoch 437/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7883e-05 - mae: 0.0034\n",
      "Epoch 437: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7399e-05 - mae: 0.0034 - val_loss: 4.1910e-05 - val_mae: 0.0052\n",
      "Epoch 438/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.4381e-05 - mae: 0.0030\n",
      "Epoch 438: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7201e-05 - mae: 0.0033 - val_loss: 4.1574e-05 - val_mae: 0.0052\n",
      "Epoch 439/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8254e-05 - mae: 0.0034\n",
      "Epoch 439: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.8283e-05 - mae: 0.0034 - val_loss: 4.3500e-05 - val_mae: 0.0053\n",
      "Epoch 440/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8356e-05 - mae: 0.0035\n",
      "Epoch 440: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.8252e-05 - mae: 0.0035 - val_loss: 4.1271e-05 - val_mae: 0.0052\n",
      "Epoch 441/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.7198e-05 - mae: 0.0033\n",
      "Epoch 441: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 1.7149e-05 - mae: 0.0033 - val_loss: 4.1393e-05 - val_mae: 0.0052\n",
      "Epoch 442/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 2.2430e-05 - mae: 0.0038\n",
      "Epoch 442: val_loss improved from 0.00004 to 0.00004, saving model to /home/shreyas/XAIRT/examples/model.h5\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 2.0768e-05 - mae: 0.0037 - val_loss: 4.1201e-05 - val_mae: 0.0052\n",
      "Epoch 443/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7829e-05 - mae: 0.0034\n",
      "Epoch 443: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7650e-05 - mae: 0.0034 - val_loss: 4.3369e-05 - val_mae: 0.0053\n",
      "Epoch 444/1000\n",
      "570/800 [====================>.........] - ETA: 0s - loss: 1.7073e-05 - mae: 0.0033\n",
      "Epoch 444: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 1.7606e-05 - mae: 0.0034 - val_loss: 4.2459e-05 - val_mae: 0.0052\n",
      "Epoch 445/1000\n",
      "570/800 [====================>.........] - ETA: 0s - loss: 1.6720e-05 - mae: 0.0033\n",
      "Epoch 445: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 1.8303e-05 - mae: 0.0034 - val_loss: 4.5887e-05 - val_mae: 0.0055\n",
      "Epoch 446/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8486e-05 - mae: 0.0035\n",
      "Epoch 446: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.8914e-05 - mae: 0.0035 - val_loss: 4.1856e-05 - val_mae: 0.0052\n",
      "Epoch 447/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8686e-05 - mae: 0.0035\n",
      "Epoch 447: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.9421e-05 - mae: 0.0035 - val_loss: 4.4217e-05 - val_mae: 0.0054\n",
      "Epoch 448/1000\n",
      "630/800 [======================>.......] - ETA: 0s - loss: 1.8194e-05 - mae: 0.0034\n",
      "Epoch 448: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 189us/sample - loss: 1.8264e-05 - mae: 0.0034 - val_loss: 4.2546e-05 - val_mae: 0.0052\n",
      "Epoch 449/1000\n",
      "720/800 [==========================>...] - ETA: 0s - loss: 1.6124e-05 - mae: 0.0032\n",
      "Epoch 449: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 166us/sample - loss: 1.6313e-05 - mae: 0.0032 - val_loss: 4.1935e-05 - val_mae: 0.0052\n",
      "Epoch 450/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6583e-05 - mae: 0.0033\n",
      "Epoch 450: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6918e-05 - mae: 0.0033 - val_loss: 4.5071e-05 - val_mae: 0.0054\n",
      "Epoch 451/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7863e-05 - mae: 0.0035\n",
      "Epoch 451: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.6974e-05 - mae: 0.0033 - val_loss: 4.2765e-05 - val_mae: 0.0053\n",
      "Epoch 452/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9949e-05 - mae: 0.0037\n",
      "Epoch 452: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.9255e-05 - mae: 0.0036 - val_loss: 4.3323e-05 - val_mae: 0.0053\n",
      "Epoch 453/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 2.1274e-05 - mae: 0.0037\n",
      "Epoch 453: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.9503e-05 - mae: 0.0035 - val_loss: 4.4252e-05 - val_mae: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.7423e-05 - mae: 0.0034\n",
      "Epoch 454: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.7382e-05 - mae: 0.0034 - val_loss: 4.8034e-05 - val_mae: 0.0056\n",
      "Epoch 455/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.9793e-05 - mae: 0.0036\n",
      "Epoch 455: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.8378e-05 - mae: 0.0034 - val_loss: 4.2651e-05 - val_mae: 0.0053\n",
      "Epoch 456/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.6692e-05 - mae: 0.0033\n",
      "Epoch 456: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.6648e-05 - mae: 0.0033 - val_loss: 4.3175e-05 - val_mae: 0.0053\n",
      "Epoch 457/1000\n",
      "650/800 [=======================>......] - ETA: 0s - loss: 1.6631e-05 - mae: 0.0033\n",
      "Epoch 457: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 179us/sample - loss: 1.7214e-05 - mae: 0.0033 - val_loss: 4.6743e-05 - val_mae: 0.0055\n",
      "Epoch 458/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6854e-05 - mae: 0.0033\n",
      "Epoch 458: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6964e-05 - mae: 0.0033 - val_loss: 4.2978e-05 - val_mae: 0.0053\n",
      "Epoch 459/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.9532e-05 - mae: 0.0036\n",
      "Epoch 459: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7919e-05 - mae: 0.0034 - val_loss: 4.1515e-05 - val_mae: 0.0052\n",
      "Epoch 460/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.9805e-05 - mae: 0.0036\n",
      "Epoch 460: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.9251e-05 - mae: 0.0035 - val_loss: 4.2212e-05 - val_mae: 0.0053\n",
      "Epoch 461/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6640e-05 - mae: 0.0033\n",
      "Epoch 461: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.7951e-05 - mae: 0.0034 - val_loss: 4.3240e-05 - val_mae: 0.0053\n",
      "Epoch 462/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8457e-05 - mae: 0.0035\n",
      "Epoch 462: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7532e-05 - mae: 0.0034 - val_loss: 4.2270e-05 - val_mae: 0.0053\n",
      "Epoch 463/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5756e-05 - mae: 0.0033\n",
      "Epoch 463: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.6387e-05 - mae: 0.0033 - val_loss: 4.4297e-05 - val_mae: 0.0054\n",
      "Epoch 464/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 2.0078e-05 - mae: 0.0036\n",
      "Epoch 464: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.9191e-05 - mae: 0.0035 - val_loss: 4.1636e-05 - val_mae: 0.0052\n",
      "Epoch 465/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9441e-05 - mae: 0.0036\n",
      "Epoch 465: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.9505e-05 - mae: 0.0036 - val_loss: 4.4131e-05 - val_mae: 0.0053\n",
      "Epoch 466/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7322e-05 - mae: 0.0033\n",
      "Epoch 466: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7256e-05 - mae: 0.0033 - val_loss: 4.2099e-05 - val_mae: 0.0053\n",
      "Epoch 467/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.2254e-05 - mae: 0.0038\n",
      "Epoch 467: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 2.0018e-05 - mae: 0.0036 - val_loss: 4.3210e-05 - val_mae: 0.0053\n",
      "Epoch 468/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6267e-05 - mae: 0.0032\n",
      "Epoch 468: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.6865e-05 - mae: 0.0033 - val_loss: 4.6675e-05 - val_mae: 0.0055\n",
      "Epoch 469/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7397e-05 - mae: 0.0034\n",
      "Epoch 469: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.9178e-05 - mae: 0.0035 - val_loss: 4.2030e-05 - val_mae: 0.0053\n",
      "Epoch 470/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7237e-05 - mae: 0.0034\n",
      "Epoch 470: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7290e-05 - mae: 0.0033 - val_loss: 4.2399e-05 - val_mae: 0.0053\n",
      "Epoch 471/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7763e-05 - mae: 0.0034\n",
      "Epoch 471: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.6520e-05 - mae: 0.0033 - val_loss: 4.2533e-05 - val_mae: 0.0053\n",
      "Epoch 472/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6980e-05 - mae: 0.0033\n",
      "Epoch 472: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.8416e-05 - mae: 0.0034 - val_loss: 5.0784e-05 - val_mae: 0.0057\n",
      "Epoch 473/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6294e-05 - mae: 0.0032\n",
      "Epoch 473: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7169e-05 - mae: 0.0033 - val_loss: 4.8209e-05 - val_mae: 0.0056\n",
      "Epoch 474/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7891e-05 - mae: 0.0034\n",
      "Epoch 474: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.8134e-05 - mae: 0.0034 - val_loss: 4.4058e-05 - val_mae: 0.0054\n",
      "Epoch 475/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7355e-05 - mae: 0.0034\n",
      "Epoch 475: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7719e-05 - mae: 0.0034 - val_loss: 4.9083e-05 - val_mae: 0.0056\n",
      "Epoch 476/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.8385e-05 - mae: 0.0034\n",
      "Epoch 476: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.8534e-05 - mae: 0.0034 - val_loss: 4.3668e-05 - val_mae: 0.0053\n",
      "Epoch 477/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6733e-05 - mae: 0.0033\n",
      "Epoch 477: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.6512e-05 - mae: 0.0033 - val_loss: 4.2888e-05 - val_mae: 0.0053\n",
      "Epoch 478/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7139e-05 - mae: 0.0033\n",
      "Epoch 478: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.7139e-05 - mae: 0.0033 - val_loss: 5.3682e-05 - val_mae: 0.0059\n",
      "Epoch 479/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.8307e-05 - mae: 0.0034\n",
      "Epoch 479: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7260e-05 - mae: 0.0033 - val_loss: 4.3331e-05 - val_mae: 0.0053\n",
      "Epoch 480/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7020e-05 - mae: 0.0033\n",
      "Epoch 480: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.7215e-05 - mae: 0.0033 - val_loss: 4.3157e-05 - val_mae: 0.0053\n",
      "Epoch 481/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4845e-05 - mae: 0.0031\n",
      "Epoch 481: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6463e-05 - mae: 0.0033 - val_loss: 4.3184e-05 - val_mae: 0.0053\n",
      "Epoch 482/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7889e-05 - mae: 0.0034\n",
      "Epoch 482: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.9491e-05 - mae: 0.0035 - val_loss: 4.2812e-05 - val_mae: 0.0053\n",
      "Epoch 483/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/800 [=================>............] - ETA: 0s - loss: 1.6593e-05 - mae: 0.0033\n",
      "Epoch 483: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.8171e-05 - mae: 0.0034 - val_loss: 4.5235e-05 - val_mae: 0.0055\n",
      "Epoch 484/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.9366e-05 - mae: 0.0035\n",
      "Epoch 484: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.9023e-05 - mae: 0.0035 - val_loss: 4.2198e-05 - val_mae: 0.0052\n",
      "Epoch 485/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5675e-05 - mae: 0.0032\n",
      "Epoch 485: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.9034e-05 - mae: 0.0035 - val_loss: 4.9184e-05 - val_mae: 0.0056\n",
      "Epoch 486/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6884e-05 - mae: 0.0033\n",
      "Epoch 486: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7462e-05 - mae: 0.0033 - val_loss: 4.3279e-05 - val_mae: 0.0053\n",
      "Epoch 487/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7008e-05 - mae: 0.0033\n",
      "Epoch 487: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7686e-05 - mae: 0.0034 - val_loss: 4.4607e-05 - val_mae: 0.0054\n",
      "Epoch 488/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7076e-05 - mae: 0.0033\n",
      "Epoch 488: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.7780e-05 - mae: 0.0034 - val_loss: 4.2126e-05 - val_mae: 0.0052\n",
      "Epoch 489/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.8196e-05 - mae: 0.0034\n",
      "Epoch 489: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.7784e-05 - mae: 0.0034 - val_loss: 4.1889e-05 - val_mae: 0.0052\n",
      "Epoch 490/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6585e-05 - mae: 0.0033\n",
      "Epoch 490: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.6549e-05 - mae: 0.0032 - val_loss: 4.1710e-05 - val_mae: 0.0052\n",
      "Epoch 491/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6648e-05 - mae: 0.0033\n",
      "Epoch 491: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.7513e-05 - mae: 0.0033 - val_loss: 4.5338e-05 - val_mae: 0.0054\n",
      "Epoch 492/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5448e-05 - mae: 0.0032\n",
      "Epoch 492: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.7328e-05 - mae: 0.0033 - val_loss: 4.2109e-05 - val_mae: 0.0052\n",
      "Epoch 493/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.7877e-05 - mae: 0.0034\n",
      "Epoch 493: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.8761e-05 - mae: 0.0035 - val_loss: 4.2554e-05 - val_mae: 0.0053\n",
      "Epoch 494/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5232e-05 - mae: 0.0032\n",
      "Epoch 494: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7733e-05 - mae: 0.0034 - val_loss: 4.2869e-05 - val_mae: 0.0053\n",
      "Epoch 495/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6559e-05 - mae: 0.0033\n",
      "Epoch 495: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6904e-05 - mae: 0.0033 - val_loss: 4.2340e-05 - val_mae: 0.0052\n",
      "Epoch 496/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.6331e-05 - mae: 0.0032\n",
      "Epoch 496: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 1.7544e-05 - mae: 0.0033 - val_loss: 4.2279e-05 - val_mae: 0.0053\n",
      "Epoch 497/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.7675e-05 - mae: 0.0034\n",
      "Epoch 497: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.7840e-05 - mae: 0.0034 - val_loss: 4.4975e-05 - val_mae: 0.0054\n",
      "Epoch 498/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6809e-05 - mae: 0.0032\n",
      "Epoch 498: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7823e-05 - mae: 0.0034 - val_loss: 4.2151e-05 - val_mae: 0.0052\n",
      "Epoch 499/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.5944e-05 - mae: 0.0032\n",
      "Epoch 499: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.7110e-05 - mae: 0.0033 - val_loss: 4.2632e-05 - val_mae: 0.0053\n",
      "Epoch 500/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5641e-05 - mae: 0.0032\n",
      "Epoch 500: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.6577e-05 - mae: 0.0033 - val_loss: 4.3529e-05 - val_mae: 0.0053\n",
      "Epoch 501/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7341e-05 - mae: 0.0033\n",
      "Epoch 501: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8250e-05 - mae: 0.0034 - val_loss: 5.1717e-05 - val_mae: 0.0058\n",
      "Epoch 502/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.8190e-05 - mae: 0.0034\n",
      "Epoch 502: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.9292e-05 - mae: 0.0035 - val_loss: 5.1073e-05 - val_mae: 0.0058\n",
      "Epoch 503/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.9559e-05 - mae: 0.0035\n",
      "Epoch 503: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 1.8198e-05 - mae: 0.0034 - val_loss: 4.1797e-05 - val_mae: 0.0052\n",
      "Epoch 504/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.8279e-05 - mae: 0.0034\n",
      "Epoch 504: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 1.7967e-05 - mae: 0.0034 - val_loss: 4.3520e-05 - val_mae: 0.0053\n",
      "Epoch 505/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.6335e-05 - mae: 0.0032\n",
      "Epoch 505: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.6689e-05 - mae: 0.0033 - val_loss: 4.2289e-05 - val_mae: 0.0053\n",
      "Epoch 506/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6345e-05 - mae: 0.0032\n",
      "Epoch 506: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7049e-05 - mae: 0.0033 - val_loss: 4.4657e-05 - val_mae: 0.0054\n",
      "Epoch 507/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.6929e-05 - mae: 0.0034\n",
      "Epoch 507: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 2.0311e-05 - mae: 0.0036 - val_loss: 4.2255e-05 - val_mae: 0.0052\n",
      "Epoch 508/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7567e-05 - mae: 0.0034\n",
      "Epoch 508: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6687e-05 - mae: 0.0033 - val_loss: 4.2357e-05 - val_mae: 0.0052\n",
      "Epoch 509/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4716e-05 - mae: 0.0030\n",
      "Epoch 509: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6529e-05 - mae: 0.0032 - val_loss: 4.2048e-05 - val_mae: 0.0052\n",
      "Epoch 510/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6030e-05 - mae: 0.0032\n",
      "Epoch 510: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7787e-05 - mae: 0.0034 - val_loss: 4.2608e-05 - val_mae: 0.0053\n",
      "Epoch 511/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.8474e-05 - mae: 0.0034\n",
      "Epoch 511: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.8474e-05 - mae: 0.0034 - val_loss: 4.1917e-05 - val_mae: 0.0052\n",
      "Epoch 512/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7276e-05 - mae: 0.0034\n",
      "Epoch 512: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7685e-05 - mae: 0.0034 - val_loss: 5.1990e-05 - val_mae: 0.0058\n",
      "Epoch 513/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6968e-05 - mae: 0.0033\n",
      "Epoch 513: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.6875e-05 - mae: 0.0033 - val_loss: 4.3151e-05 - val_mae: 0.0053\n",
      "Epoch 514/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7177e-05 - mae: 0.0033\n",
      "Epoch 514: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8312e-05 - mae: 0.0034 - val_loss: 5.3331e-05 - val_mae: 0.0059\n",
      "Epoch 515/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5124e-05 - mae: 0.0031\n",
      "Epoch 515: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7368e-05 - mae: 0.0033 - val_loss: 4.5284e-05 - val_mae: 0.0054\n",
      "Epoch 516/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8068e-05 - mae: 0.0034\n",
      "Epoch 516: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7876e-05 - mae: 0.0034 - val_loss: 4.6645e-05 - val_mae: 0.0055\n",
      "Epoch 517/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7501e-05 - mae: 0.0034\n",
      "Epoch 517: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7134e-05 - mae: 0.0033 - val_loss: 4.4268e-05 - val_mae: 0.0054\n",
      "Epoch 518/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7933e-05 - mae: 0.0034\n",
      "Epoch 518: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.8392e-05 - mae: 0.0035 - val_loss: 4.1407e-05 - val_mae: 0.0052\n",
      "Epoch 519/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.5761e-05 - mae: 0.0032\n",
      "Epoch 519: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.6553e-05 - mae: 0.0033 - val_loss: 4.1994e-05 - val_mae: 0.0053\n",
      "Epoch 520/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7309e-05 - mae: 0.0033\n",
      "Epoch 520: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.8381e-05 - mae: 0.0034 - val_loss: 4.2109e-05 - val_mae: 0.0052\n",
      "Epoch 521/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 2.1972e-05 - mae: 0.0038\n",
      "Epoch 521: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 2.0813e-05 - mae: 0.0037 - val_loss: 4.4111e-05 - val_mae: 0.0053\n",
      "Epoch 522/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.9652e-05 - mae: 0.0035\n",
      "Epoch 522: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.9196e-05 - mae: 0.0035 - val_loss: 4.2764e-05 - val_mae: 0.0052\n",
      "Epoch 523/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5725e-05 - mae: 0.0032\n",
      "Epoch 523: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.7480e-05 - mae: 0.0034 - val_loss: 4.2449e-05 - val_mae: 0.0052\n",
      "Epoch 524/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.8515e-05 - mae: 0.0034\n",
      "Epoch 524: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 2.0946e-05 - mae: 0.0036 - val_loss: 4.1972e-05 - val_mae: 0.0052\n",
      "Epoch 525/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8555e-05 - mae: 0.0034\n",
      "Epoch 525: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.8718e-05 - mae: 0.0034 - val_loss: 4.4835e-05 - val_mae: 0.0054\n",
      "Epoch 526/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.6192e-05 - mae: 0.0032\n",
      "Epoch 526: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.6957e-05 - mae: 0.0033 - val_loss: 4.3018e-05 - val_mae: 0.0053\n",
      "Epoch 527/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7210e-05 - mae: 0.0033\n",
      "Epoch 527: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.7558e-05 - mae: 0.0034 - val_loss: 4.2245e-05 - val_mae: 0.0052\n",
      "Epoch 528/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.9794e-05 - mae: 0.0036\n",
      "Epoch 528: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.9945e-05 - mae: 0.0036 - val_loss: 4.9781e-05 - val_mae: 0.0057\n",
      "Epoch 529/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6886e-05 - mae: 0.0033\n",
      "Epoch 529: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7716e-05 - mae: 0.0034 - val_loss: 4.5455e-05 - val_mae: 0.0054\n",
      "Epoch 530/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6687e-05 - mae: 0.0033\n",
      "Epoch 530: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7022e-05 - mae: 0.0033 - val_loss: 4.2110e-05 - val_mae: 0.0052\n",
      "Epoch 531/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9122e-05 - mae: 0.0035\n",
      "Epoch 531: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.9548e-05 - mae: 0.0035 - val_loss: 4.3850e-05 - val_mae: 0.0053\n",
      "Epoch 532/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.5820e-05 - mae: 0.0031\n",
      "Epoch 532: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.6801e-05 - mae: 0.0032 - val_loss: 4.1742e-05 - val_mae: 0.0052\n",
      "Epoch 533/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6893e-05 - mae: 0.0033\n",
      "Epoch 533: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7605e-05 - mae: 0.0034 - val_loss: 4.1994e-05 - val_mae: 0.0052\n",
      "Epoch 534/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.6493e-05 - mae: 0.0033\n",
      "Epoch 534: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.7256e-05 - mae: 0.0034 - val_loss: 4.1807e-05 - val_mae: 0.0052\n",
      "Epoch 535/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7946e-05 - mae: 0.0033\n",
      "Epoch 535: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8064e-05 - mae: 0.0034 - val_loss: 4.4826e-05 - val_mae: 0.0054\n",
      "Epoch 536/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8186e-05 - mae: 0.0035\n",
      "Epoch 536: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.7527e-05 - mae: 0.0034 - val_loss: 4.5392e-05 - val_mae: 0.0055\n",
      "Epoch 537/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8345e-05 - mae: 0.0034\n",
      "Epoch 537: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7679e-05 - mae: 0.0034 - val_loss: 4.7628e-05 - val_mae: 0.0055\n",
      "Epoch 538/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.6801e-05 - mae: 0.0033\n",
      "Epoch 538: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.6840e-05 - mae: 0.0033 - val_loss: 4.3549e-05 - val_mae: 0.0053\n",
      "Epoch 539/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7029e-05 - mae: 0.0033\n",
      "Epoch 539: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.9071e-05 - mae: 0.0035 - val_loss: 4.1918e-05 - val_mae: 0.0052\n",
      "Epoch 540/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9565e-05 - mae: 0.0036\n",
      "Epoch 540: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.8585e-05 - mae: 0.0035 - val_loss: 4.5621e-05 - val_mae: 0.0055\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7577e-05 - mae: 0.0034\n",
      "Epoch 541: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.6885e-05 - mae: 0.0033 - val_loss: 4.2966e-05 - val_mae: 0.0053\n",
      "Epoch 542/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8079e-05 - mae: 0.0034\n",
      "Epoch 542: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7812e-05 - mae: 0.0034 - val_loss: 4.1970e-05 - val_mae: 0.0052\n",
      "Epoch 543/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6493e-05 - mae: 0.0033\n",
      "Epoch 543: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7095e-05 - mae: 0.0033 - val_loss: 4.2468e-05 - val_mae: 0.0053\n",
      "Epoch 544/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7270e-05 - mae: 0.0034\n",
      "Epoch 544: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.6881e-05 - mae: 0.0033 - val_loss: 4.1988e-05 - val_mae: 0.0052\n",
      "Epoch 545/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 2.0962e-05 - mae: 0.0037\n",
      "Epoch 545: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.9890e-05 - mae: 0.0036 - val_loss: 4.5140e-05 - val_mae: 0.0054\n",
      "Epoch 546/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7271e-05 - mae: 0.0034\n",
      "Epoch 546: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 2.2714e-05 - mae: 0.0039 - val_loss: 4.6155e-05 - val_mae: 0.0055\n",
      "Epoch 547/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7138e-05 - mae: 0.0033\n",
      "Epoch 547: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.7644e-05 - mae: 0.0034 - val_loss: 5.9157e-05 - val_mae: 0.0062\n",
      "Epoch 548/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7823e-05 - mae: 0.0034\n",
      "Epoch 548: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.8834e-05 - mae: 0.0035 - val_loss: 4.7764e-05 - val_mae: 0.0056\n",
      "Epoch 549/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.7186e-05 - mae: 0.0033\n",
      "Epoch 549: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6652e-05 - mae: 0.0033 - val_loss: 4.7238e-05 - val_mae: 0.0055\n",
      "Epoch 550/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.7826e-05 - mae: 0.0034\n",
      "Epoch 550: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.8657e-05 - mae: 0.0035 - val_loss: 4.1471e-05 - val_mae: 0.0052\n",
      "Epoch 551/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6394e-05 - mae: 0.0032\n",
      "Epoch 551: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7109e-05 - mae: 0.0033 - val_loss: 4.3531e-05 - val_mae: 0.0053\n",
      "Epoch 552/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.7194e-05 - mae: 0.0033\n",
      "Epoch 552: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.7240e-05 - mae: 0.0033 - val_loss: 4.1691e-05 - val_mae: 0.0052\n",
      "Epoch 553/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.8724e-05 - mae: 0.0035\n",
      "Epoch 553: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.8724e-05 - mae: 0.0035 - val_loss: 4.3118e-05 - val_mae: 0.0053\n",
      "Epoch 554/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6275e-05 - mae: 0.0032\n",
      "Epoch 554: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7251e-05 - mae: 0.0033 - val_loss: 4.4796e-05 - val_mae: 0.0054\n",
      "Epoch 555/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5754e-05 - mae: 0.0032\n",
      "Epoch 555: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7534e-05 - mae: 0.0034 - val_loss: 4.1353e-05 - val_mae: 0.0052\n",
      "Epoch 556/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7283e-05 - mae: 0.0034\n",
      "Epoch 556: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.8897e-05 - mae: 0.0035 - val_loss: 4.1587e-05 - val_mae: 0.0052\n",
      "Epoch 557/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6790e-05 - mae: 0.0033\n",
      "Epoch 557: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.6564e-05 - mae: 0.0033 - val_loss: 4.1550e-05 - val_mae: 0.0052\n",
      "Epoch 558/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.7458e-05 - mae: 0.0033\n",
      "Epoch 558: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.7399e-05 - mae: 0.0033 - val_loss: 4.7960e-05 - val_mae: 0.0055\n",
      "Epoch 559/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9542e-05 - mae: 0.0036\n",
      "Epoch 559: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8791e-05 - mae: 0.0035 - val_loss: 4.1693e-05 - val_mae: 0.0052\n",
      "Epoch 560/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 2.0681e-05 - mae: 0.0037\n",
      "Epoch 560: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.9696e-05 - mae: 0.0036 - val_loss: 4.1314e-05 - val_mae: 0.0052\n",
      "Epoch 561/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6162e-05 - mae: 0.0032\n",
      "Epoch 561: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.7759e-05 - mae: 0.0034 - val_loss: 4.8040e-05 - val_mae: 0.0056\n",
      "Epoch 562/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7083e-05 - mae: 0.0033\n",
      "Epoch 562: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.7449e-05 - mae: 0.0034 - val_loss: 4.6032e-05 - val_mae: 0.0055\n",
      "Epoch 563/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7352e-05 - mae: 0.0033\n",
      "Epoch 563: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.7352e-05 - mae: 0.0033 - val_loss: 4.5414e-05 - val_mae: 0.0054\n",
      "Epoch 564/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9023e-05 - mae: 0.0034\n",
      "Epoch 564: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.8050e-05 - mae: 0.0034 - val_loss: 4.1926e-05 - val_mae: 0.0052\n",
      "Epoch 565/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9744e-05 - mae: 0.0035\n",
      "Epoch 565: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 2.0163e-05 - mae: 0.0036 - val_loss: 4.4576e-05 - val_mae: 0.0054\n",
      "Epoch 566/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7345e-05 - mae: 0.0033\n",
      "Epoch 566: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.7345e-05 - mae: 0.0033 - val_loss: 4.1954e-05 - val_mae: 0.0052\n",
      "Epoch 567/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.8618e-05 - mae: 0.0036\n",
      "Epoch 567: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.9903e-05 - mae: 0.0036 - val_loss: 4.7693e-05 - val_mae: 0.0056\n",
      "Epoch 568/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.8020e-05 - mae: 0.0033\n",
      "Epoch 568: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7737e-05 - mae: 0.0033 - val_loss: 4.1926e-05 - val_mae: 0.0052\n",
      "Epoch 569/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7324e-05 - mae: 0.0033\n",
      "Epoch 569: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.8956e-05 - mae: 0.0035 - val_loss: 4.6015e-05 - val_mae: 0.0055\n",
      "Epoch 570/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/800 [================>.............] - ETA: 0s - loss: 1.7038e-05 - mae: 0.0034\n",
      "Epoch 570: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6285e-05 - mae: 0.0032 - val_loss: 4.3149e-05 - val_mae: 0.0053\n",
      "Epoch 571/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6316e-05 - mae: 0.0032\n",
      "Epoch 571: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.6588e-05 - mae: 0.0033 - val_loss: 4.1990e-05 - val_mae: 0.0052\n",
      "Epoch 572/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5614e-05 - mae: 0.0031\n",
      "Epoch 572: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6795e-05 - mae: 0.0033 - val_loss: 4.2288e-05 - val_mae: 0.0052\n",
      "Epoch 573/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5500e-05 - mae: 0.0032\n",
      "Epoch 573: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7884e-05 - mae: 0.0034 - val_loss: 4.3545e-05 - val_mae: 0.0053\n",
      "Epoch 574/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6149e-05 - mae: 0.0032\n",
      "Epoch 574: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7021e-05 - mae: 0.0033 - val_loss: 4.6511e-05 - val_mae: 0.0055\n",
      "Epoch 575/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.8455e-05 - mae: 0.0034\n",
      "Epoch 575: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7964e-05 - mae: 0.0034 - val_loss: 4.1927e-05 - val_mae: 0.0052\n",
      "Epoch 576/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5907e-05 - mae: 0.0032\n",
      "Epoch 576: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.6797e-05 - mae: 0.0033 - val_loss: 4.3668e-05 - val_mae: 0.0053\n",
      "Epoch 577/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6431e-05 - mae: 0.0032\n",
      "Epoch 577: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.6761e-05 - mae: 0.0033 - val_loss: 4.4118e-05 - val_mae: 0.0054\n",
      "Epoch 578/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7779e-05 - mae: 0.0034\n",
      "Epoch 578: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8535e-05 - mae: 0.0035 - val_loss: 5.2192e-05 - val_mae: 0.0058\n",
      "Epoch 579/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.9414e-05 - mae: 0.0035\n",
      "Epoch 579: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.8726e-05 - mae: 0.0034 - val_loss: 4.5731e-05 - val_mae: 0.0054\n",
      "Epoch 580/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6780e-05 - mae: 0.0033\n",
      "Epoch 580: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.7670e-05 - mae: 0.0034 - val_loss: 4.2880e-05 - val_mae: 0.0053\n",
      "Epoch 581/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5784e-05 - mae: 0.0032\n",
      "Epoch 581: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7126e-05 - mae: 0.0033 - val_loss: 4.2732e-05 - val_mae: 0.0053\n",
      "Epoch 582/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5181e-05 - mae: 0.0031\n",
      "Epoch 582: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7361e-05 - mae: 0.0033 - val_loss: 4.3848e-05 - val_mae: 0.0054\n",
      "Epoch 583/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6028e-05 - mae: 0.0032\n",
      "Epoch 583: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7148e-05 - mae: 0.0033 - val_loss: 4.3799e-05 - val_mae: 0.0053\n",
      "Epoch 584/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6688e-05 - mae: 0.0033\n",
      "Epoch 584: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.6640e-05 - mae: 0.0033 - val_loss: 4.4020e-05 - val_mae: 0.0053\n",
      "Epoch 585/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6770e-05 - mae: 0.0033\n",
      "Epoch 585: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7089e-05 - mae: 0.0033 - val_loss: 4.1987e-05 - val_mae: 0.0052\n",
      "Epoch 586/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5642e-05 - mae: 0.0031\n",
      "Epoch 586: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6323e-05 - mae: 0.0032 - val_loss: 4.2399e-05 - val_mae: 0.0052\n",
      "Epoch 587/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6229e-05 - mae: 0.0033\n",
      "Epoch 587: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7835e-05 - mae: 0.0034 - val_loss: 4.6941e-05 - val_mae: 0.0055\n",
      "Epoch 588/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8339e-05 - mae: 0.0034\n",
      "Epoch 588: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.8478e-05 - mae: 0.0034 - val_loss: 4.6958e-05 - val_mae: 0.0055\n",
      "Epoch 589/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5785e-05 - mae: 0.0032\n",
      "Epoch 589: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.7237e-05 - mae: 0.0033 - val_loss: 4.3839e-05 - val_mae: 0.0053\n",
      "Epoch 590/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5645e-05 - mae: 0.0032\n",
      "Epoch 590: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6304e-05 - mae: 0.0032 - val_loss: 4.2593e-05 - val_mae: 0.0053\n",
      "Epoch 591/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7164e-05 - mae: 0.0034\n",
      "Epoch 591: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.7227e-05 - mae: 0.0033 - val_loss: 4.4901e-05 - val_mae: 0.0054\n",
      "Epoch 592/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5329e-05 - mae: 0.0031\n",
      "Epoch 592: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.6940e-05 - mae: 0.0033 - val_loss: 4.2118e-05 - val_mae: 0.0053\n",
      "Epoch 593/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 2.0607e-05 - mae: 0.0036\n",
      "Epoch 593: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 2.0137e-05 - mae: 0.0036 - val_loss: 4.4290e-05 - val_mae: 0.0054\n",
      "Epoch 594/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7553e-05 - mae: 0.0034\n",
      "Epoch 594: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.7273e-05 - mae: 0.0034 - val_loss: 4.5286e-05 - val_mae: 0.0054\n",
      "Epoch 595/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5799e-05 - mae: 0.0032\n",
      "Epoch 595: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.6732e-05 - mae: 0.0032 - val_loss: 4.5859e-05 - val_mae: 0.0054\n",
      "Epoch 596/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7742e-05 - mae: 0.0034\n",
      "Epoch 596: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.7742e-05 - mae: 0.0034 - val_loss: 4.2067e-05 - val_mae: 0.0052\n",
      "Epoch 597/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.7444e-05 - mae: 0.0034\n",
      "Epoch 597: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.7850e-05 - mae: 0.0034 - val_loss: 4.5332e-05 - val_mae: 0.0054\n",
      "Epoch 598/1000\n",
      "740/800 [==========================>...] - ETA: 0s - loss: 1.8216e-05 - mae: 0.0035\n",
      "Epoch 598: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 159us/sample - loss: 1.8490e-05 - mae: 0.0035 - val_loss: 4.3483e-05 - val_mae: 0.0053\n",
      "Epoch 599/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/800 [===============>..............] - ETA: 0s - loss: 1.8350e-05 - mae: 0.0035\n",
      "Epoch 599: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.8080e-05 - mae: 0.0034 - val_loss: 4.3690e-05 - val_mae: 0.0053\n",
      "Epoch 600/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.7149e-05 - mae: 0.0034\n",
      "Epoch 600: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.7127e-05 - mae: 0.0034 - val_loss: 4.2412e-05 - val_mae: 0.0052\n",
      "Epoch 601/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.8132e-05 - mae: 0.0035\n",
      "Epoch 601: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.7577e-05 - mae: 0.0034 - val_loss: 4.8030e-05 - val_mae: 0.0056\n",
      "Epoch 602/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7239e-05 - mae: 0.0033\n",
      "Epoch 602: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.7325e-05 - mae: 0.0033 - val_loss: 4.2921e-05 - val_mae: 0.0053\n",
      "Epoch 603/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6225e-05 - mae: 0.0032\n",
      "Epoch 603: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.6693e-05 - mae: 0.0033 - val_loss: 4.4726e-05 - val_mae: 0.0054\n",
      "Epoch 604/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7587e-05 - mae: 0.0033\n",
      "Epoch 604: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.7330e-05 - mae: 0.0033 - val_loss: 4.3217e-05 - val_mae: 0.0053\n",
      "Epoch 605/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7238e-05 - mae: 0.0034\n",
      "Epoch 605: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7084e-05 - mae: 0.0033 - val_loss: 4.7452e-05 - val_mae: 0.0055\n",
      "Epoch 606/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6559e-05 - mae: 0.0033\n",
      "Epoch 606: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8021e-05 - mae: 0.0034 - val_loss: 4.1939e-05 - val_mae: 0.0052\n",
      "Epoch 607/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 2.0182e-05 - mae: 0.0036\n",
      "Epoch 607: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.9402e-05 - mae: 0.0035 - val_loss: 4.2258e-05 - val_mae: 0.0053\n",
      "Epoch 608/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7981e-05 - mae: 0.0034\n",
      "Epoch 608: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.8612e-05 - mae: 0.0035 - val_loss: 4.6145e-05 - val_mae: 0.0055\n",
      "Epoch 609/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.9352e-05 - mae: 0.0035\n",
      "Epoch 609: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.8171e-05 - mae: 0.0034 - val_loss: 4.2471e-05 - val_mae: 0.0052\n",
      "Epoch 610/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6348e-05 - mae: 0.0033\n",
      "Epoch 610: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.6994e-05 - mae: 0.0034 - val_loss: 5.9497e-05 - val_mae: 0.0063\n",
      "Epoch 611/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 2.2672e-05 - mae: 0.0039\n",
      "Epoch 611: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.9966e-05 - mae: 0.0036 - val_loss: 4.4948e-05 - val_mae: 0.0054\n",
      "Epoch 612/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5424e-05 - mae: 0.0031\n",
      "Epoch 612: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6843e-05 - mae: 0.0033 - val_loss: 4.3041e-05 - val_mae: 0.0053\n",
      "Epoch 613/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7054e-05 - mae: 0.0033\n",
      "Epoch 613: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6941e-05 - mae: 0.0033 - val_loss: 4.2355e-05 - val_mae: 0.0052\n",
      "Epoch 614/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 2.0829e-05 - mae: 0.0037\n",
      "Epoch 614: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 2.0794e-05 - mae: 0.0037 - val_loss: 4.2712e-05 - val_mae: 0.0052\n",
      "Epoch 615/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8883e-05 - mae: 0.0034\n",
      "Epoch 615: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.7607e-05 - mae: 0.0033 - val_loss: 4.2924e-05 - val_mae: 0.0053\n",
      "Epoch 616/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7685e-05 - mae: 0.0034\n",
      "Epoch 616: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7368e-05 - mae: 0.0034 - val_loss: 4.3831e-05 - val_mae: 0.0053\n",
      "Epoch 617/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6848e-05 - mae: 0.0033\n",
      "Epoch 617: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7144e-05 - mae: 0.0033 - val_loss: 4.3312e-05 - val_mae: 0.0053\n",
      "Epoch 618/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7587e-05 - mae: 0.0033\n",
      "Epoch 618: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.6909e-05 - mae: 0.0033 - val_loss: 4.1856e-05 - val_mae: 0.0052\n",
      "Epoch 619/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5249e-05 - mae: 0.0032\n",
      "Epoch 619: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7422e-05 - mae: 0.0033 - val_loss: 4.4344e-05 - val_mae: 0.0053\n",
      "Epoch 620/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5103e-05 - mae: 0.0031\n",
      "Epoch 620: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.6381e-05 - mae: 0.0032 - val_loss: 4.2854e-05 - val_mae: 0.0053\n",
      "Epoch 621/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.9010e-05 - mae: 0.0035\n",
      "Epoch 621: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.9010e-05 - mae: 0.0035 - val_loss: 5.0177e-05 - val_mae: 0.0057\n",
      "Epoch 622/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5988e-05 - mae: 0.0032\n",
      "Epoch 622: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.7504e-05 - mae: 0.0034 - val_loss: 4.3416e-05 - val_mae: 0.0053\n",
      "Epoch 623/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7101e-05 - mae: 0.0033\n",
      "Epoch 623: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.7103e-05 - mae: 0.0033 - val_loss: 5.1677e-05 - val_mae: 0.0058\n",
      "Epoch 624/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8636e-05 - mae: 0.0035\n",
      "Epoch 624: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.9536e-05 - mae: 0.0036 - val_loss: 4.9069e-05 - val_mae: 0.0056\n",
      "Epoch 625/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7324e-05 - mae: 0.0034\n",
      "Epoch 625: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.8445e-05 - mae: 0.0035 - val_loss: 4.3180e-05 - val_mae: 0.0053\n",
      "Epoch 626/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7558e-05 - mae: 0.0033\n",
      "Epoch 626: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7426e-05 - mae: 0.0033 - val_loss: 4.1820e-05 - val_mae: 0.0052\n",
      "Epoch 627/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7660e-05 - mae: 0.0034\n",
      "Epoch 627: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.7847e-05 - mae: 0.0034 - val_loss: 4.5015e-05 - val_mae: 0.0054\n",
      "Epoch 628/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/800 [=============>................] - ETA: 0s - loss: 1.6399e-05 - mae: 0.0032\n",
      "Epoch 628: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.6265e-05 - mae: 0.0033 - val_loss: 4.2901e-05 - val_mae: 0.0053\n",
      "Epoch 629/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6380e-05 - mae: 0.0032\n",
      "Epoch 629: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.6085e-05 - mae: 0.0032 - val_loss: 4.3522e-05 - val_mae: 0.0053\n",
      "Epoch 630/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7020e-05 - mae: 0.0033\n",
      "Epoch 630: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.6754e-05 - mae: 0.0033 - val_loss: 4.2336e-05 - val_mae: 0.0053\n",
      "Epoch 631/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.9826e-05 - mae: 0.0035\n",
      "Epoch 631: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.8173e-05 - mae: 0.0034 - val_loss: 4.3017e-05 - val_mae: 0.0053\n",
      "Epoch 632/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5840e-05 - mae: 0.0032\n",
      "Epoch 632: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.6804e-05 - mae: 0.0033 - val_loss: 4.4546e-05 - val_mae: 0.0054\n",
      "Epoch 633/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7607e-05 - mae: 0.0034\n",
      "Epoch 633: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7518e-05 - mae: 0.0034 - val_loss: 4.1918e-05 - val_mae: 0.0052\n",
      "Epoch 634/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6090e-05 - mae: 0.0032\n",
      "Epoch 634: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.6699e-05 - mae: 0.0033 - val_loss: 5.3484e-05 - val_mae: 0.0059\n",
      "Epoch 635/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8812e-05 - mae: 0.0034\n",
      "Epoch 635: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.8229e-05 - mae: 0.0034 - val_loss: 4.8656e-05 - val_mae: 0.0056\n",
      "Epoch 636/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8707e-05 - mae: 0.0035\n",
      "Epoch 636: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.8270e-05 - mae: 0.0034 - val_loss: 4.3990e-05 - val_mae: 0.0054\n",
      "Epoch 637/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6830e-05 - mae: 0.0033\n",
      "Epoch 637: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.6348e-05 - mae: 0.0033 - val_loss: 4.2330e-05 - val_mae: 0.0053\n",
      "Epoch 638/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8023e-05 - mae: 0.0034\n",
      "Epoch 638: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7245e-05 - mae: 0.0033 - val_loss: 4.2390e-05 - val_mae: 0.0052\n",
      "Epoch 639/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9105e-05 - mae: 0.0035\n",
      "Epoch 639: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.8300e-05 - mae: 0.0034 - val_loss: 4.3955e-05 - val_mae: 0.0054\n",
      "Epoch 640/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5389e-05 - mae: 0.0031\n",
      "Epoch 640: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.6312e-05 - mae: 0.0033 - val_loss: 4.4422e-05 - val_mae: 0.0053\n",
      "Epoch 641/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6326e-05 - mae: 0.0033\n",
      "Epoch 641: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.8080e-05 - mae: 0.0034 - val_loss: 4.2604e-05 - val_mae: 0.0053\n",
      "Epoch 642/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.7458e-05 - mae: 0.0034\n",
      "Epoch 642: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.7980e-05 - mae: 0.0034 - val_loss: 4.1709e-05 - val_mae: 0.0052\n",
      "Epoch 643/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7193e-05 - mae: 0.0033\n",
      "Epoch 643: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7909e-05 - mae: 0.0034 - val_loss: 4.7706e-05 - val_mae: 0.0055\n",
      "Epoch 644/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7765e-05 - mae: 0.0034\n",
      "Epoch 644: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.6538e-05 - mae: 0.0033 - val_loss: 4.2879e-05 - val_mae: 0.0053\n",
      "Epoch 645/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7747e-05 - mae: 0.0034\n",
      "Epoch 645: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7384e-05 - mae: 0.0034 - val_loss: 4.2047e-05 - val_mae: 0.0052\n",
      "Epoch 646/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7669e-05 - mae: 0.0034\n",
      "Epoch 646: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.8286e-05 - mae: 0.0034 - val_loss: 4.2019e-05 - val_mae: 0.0052\n",
      "Epoch 647/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.5229e-05 - mae: 0.0031\n",
      "Epoch 647: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.6417e-05 - mae: 0.0033 - val_loss: 4.2418e-05 - val_mae: 0.0053\n",
      "Epoch 648/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7275e-05 - mae: 0.0034\n",
      "Epoch 648: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7486e-05 - mae: 0.0034 - val_loss: 4.3040e-05 - val_mae: 0.0053\n",
      "Epoch 649/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7424e-05 - mae: 0.0034\n",
      "Epoch 649: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.6981e-05 - mae: 0.0033 - val_loss: 4.2558e-05 - val_mae: 0.0053\n",
      "Epoch 650/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5528e-05 - mae: 0.0032\n",
      "Epoch 650: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.6587e-05 - mae: 0.0033 - val_loss: 4.3530e-05 - val_mae: 0.0053\n",
      "Epoch 651/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9293e-05 - mae: 0.0035\n",
      "Epoch 651: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7753e-05 - mae: 0.0034 - val_loss: 4.2323e-05 - val_mae: 0.0052\n",
      "Epoch 652/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 1.6437e-05 - mae: 0.0033\n",
      "Epoch 652: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 1.7902e-05 - mae: 0.0034 - val_loss: 4.8654e-05 - val_mae: 0.0056\n",
      "Epoch 653/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.8229e-05 - mae: 0.0034\n",
      "Epoch 653: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.8776e-05 - mae: 0.0035 - val_loss: 4.5380e-05 - val_mae: 0.0054\n",
      "Epoch 654/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7162e-05 - mae: 0.0033\n",
      "Epoch 654: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.6686e-05 - mae: 0.0033 - val_loss: 4.5431e-05 - val_mae: 0.0054\n",
      "Epoch 655/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6389e-05 - mae: 0.0032\n",
      "Epoch 655: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6841e-05 - mae: 0.0033 - val_loss: 4.2034e-05 - val_mae: 0.0053\n",
      "Epoch 656/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6519e-05 - mae: 0.0033\n",
      "Epoch 656: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.6514e-05 - mae: 0.0033 - val_loss: 4.2148e-05 - val_mae: 0.0053\n",
      "Epoch 657/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410/800 [==============>...............] - ETA: 0s - loss: 1.5420e-05 - mae: 0.0032\n",
      "Epoch 657: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.5900e-05 - mae: 0.0032 - val_loss: 4.2093e-05 - val_mae: 0.0052\n",
      "Epoch 658/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4519e-05 - mae: 0.0031\n",
      "Epoch 658: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7370e-05 - mae: 0.0034 - val_loss: 6.0460e-05 - val_mae: 0.0063\n",
      "Epoch 659/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.9590e-05 - mae: 0.0036\n",
      "Epoch 659: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.9527e-05 - mae: 0.0036 - val_loss: 4.9004e-05 - val_mae: 0.0056\n",
      "Epoch 660/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.8719e-05 - mae: 0.0035\n",
      "Epoch 660: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 2.1073e-05 - mae: 0.0037 - val_loss: 5.6364e-05 - val_mae: 0.0061\n",
      "Epoch 661/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9760e-05 - mae: 0.0035\n",
      "Epoch 661: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.9077e-05 - mae: 0.0035 - val_loss: 4.2157e-05 - val_mae: 0.0053\n",
      "Epoch 662/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7858e-05 - mae: 0.0034\n",
      "Epoch 662: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8523e-05 - mae: 0.0035 - val_loss: 4.5868e-05 - val_mae: 0.0054\n",
      "Epoch 663/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8648e-05 - mae: 0.0035\n",
      "Epoch 663: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.7599e-05 - mae: 0.0034 - val_loss: 4.1868e-05 - val_mae: 0.0053\n",
      "Epoch 664/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6402e-05 - mae: 0.0033\n",
      "Epoch 664: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.6164e-05 - mae: 0.0032 - val_loss: 4.2077e-05 - val_mae: 0.0053\n",
      "Epoch 665/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5995e-05 - mae: 0.0032\n",
      "Epoch 665: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.6748e-05 - mae: 0.0033 - val_loss: 4.2107e-05 - val_mae: 0.0053\n",
      "Epoch 666/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6174e-05 - mae: 0.0032\n",
      "Epoch 666: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7190e-05 - mae: 0.0033 - val_loss: 5.1641e-05 - val_mae: 0.0058\n",
      "Epoch 667/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9714e-05 - mae: 0.0037\n",
      "Epoch 667: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.7910e-05 - mae: 0.0034 - val_loss: 4.3649e-05 - val_mae: 0.0053\n",
      "Epoch 668/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.6614e-05 - mae: 0.0033\n",
      "Epoch 668: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.6758e-05 - mae: 0.0033 - val_loss: 4.6613e-05 - val_mae: 0.0055\n",
      "Epoch 669/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7620e-05 - mae: 0.0033\n",
      "Epoch 669: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.7449e-05 - mae: 0.0033 - val_loss: 4.2462e-05 - val_mae: 0.0053\n",
      "Epoch 670/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.4895e-05 - mae: 0.0031\n",
      "Epoch 670: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.6271e-05 - mae: 0.0032 - val_loss: 4.2158e-05 - val_mae: 0.0052\n",
      "Epoch 671/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4166e-05 - mae: 0.0030\n",
      "Epoch 671: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6598e-05 - mae: 0.0033 - val_loss: 4.2931e-05 - val_mae: 0.0053\n",
      "Epoch 672/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6482e-05 - mae: 0.0033\n",
      "Epoch 672: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.8854e-05 - mae: 0.0035 - val_loss: 4.2690e-05 - val_mae: 0.0053\n",
      "Epoch 673/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6422e-05 - mae: 0.0033\n",
      "Epoch 673: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.7963e-05 - mae: 0.0035 - val_loss: 4.3464e-05 - val_mae: 0.0053\n",
      "Epoch 674/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7834e-05 - mae: 0.0034\n",
      "Epoch 674: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.8548e-05 - mae: 0.0035 - val_loss: 5.1616e-05 - val_mae: 0.0058\n",
      "Epoch 675/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.9999e-05 - mae: 0.0035\n",
      "Epoch 675: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.8827e-05 - mae: 0.0035 - val_loss: 4.1949e-05 - val_mae: 0.0053\n",
      "Epoch 676/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.7053e-05 - mae: 0.0033\n",
      "Epoch 676: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 160us/sample - loss: 1.7435e-05 - mae: 0.0034 - val_loss: 4.2390e-05 - val_mae: 0.0053\n",
      "Epoch 677/1000\n",
      "780/800 [============================>.] - ETA: 0s - loss: 1.7039e-05 - mae: 0.0033\n",
      "Epoch 677: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 154us/sample - loss: 1.7018e-05 - mae: 0.0033 - val_loss: 4.1907e-05 - val_mae: 0.0052\n",
      "Epoch 678/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5073e-05 - mae: 0.0031\n",
      "Epoch 678: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6157e-05 - mae: 0.0032 - val_loss: 4.8272e-05 - val_mae: 0.0056\n",
      "Epoch 679/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7913e-05 - mae: 0.0034\n",
      "Epoch 679: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7241e-05 - mae: 0.0033 - val_loss: 4.2636e-05 - val_mae: 0.0053\n",
      "Epoch 680/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.5969e-05 - mae: 0.0032\n",
      "Epoch 680: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.6544e-05 - mae: 0.0032 - val_loss: 4.1428e-05 - val_mae: 0.0052\n",
      "Epoch 681/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5851e-05 - mae: 0.0032\n",
      "Epoch 681: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.7585e-05 - mae: 0.0034 - val_loss: 4.2632e-05 - val_mae: 0.0052\n",
      "Epoch 682/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5930e-05 - mae: 0.0032\n",
      "Epoch 682: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.6564e-05 - mae: 0.0033 - val_loss: 4.4527e-05 - val_mae: 0.0054\n",
      "Epoch 683/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.6444e-05 - mae: 0.0033\n",
      "Epoch 683: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.6132e-05 - mae: 0.0032 - val_loss: 4.6938e-05 - val_mae: 0.0055\n",
      "Epoch 684/1000\n",
      "690/800 [========================>.....] - ETA: 0s - loss: 1.6056e-05 - mae: 0.0032\n",
      "Epoch 684: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 1.6206e-05 - mae: 0.0032 - val_loss: 4.2056e-05 - val_mae: 0.0053\n",
      "Epoch 685/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.6665e-05 - mae: 0.0033\n",
      "Epoch 685: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.6665e-05 - mae: 0.0033 - val_loss: 4.2245e-05 - val_mae: 0.0053\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5177e-05 - mae: 0.0031\n",
      "Epoch 686: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.6707e-05 - mae: 0.0033 - val_loss: 4.2935e-05 - val_mae: 0.0053\n",
      "Epoch 687/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5619e-05 - mae: 0.0032\n",
      "Epoch 687: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6678e-05 - mae: 0.0033 - val_loss: 4.5194e-05 - val_mae: 0.0054\n",
      "Epoch 688/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6455e-05 - mae: 0.0033\n",
      "Epoch 688: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.8248e-05 - mae: 0.0034 - val_loss: 4.2443e-05 - val_mae: 0.0052\n",
      "Epoch 689/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5718e-05 - mae: 0.0032\n",
      "Epoch 689: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.6844e-05 - mae: 0.0033 - val_loss: 4.3929e-05 - val_mae: 0.0053\n",
      "Epoch 690/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9957e-05 - mae: 0.0036\n",
      "Epoch 690: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.9009e-05 - mae: 0.0035 - val_loss: 4.2742e-05 - val_mae: 0.0053\n",
      "Epoch 691/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7254e-05 - mae: 0.0033\n",
      "Epoch 691: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.7642e-05 - mae: 0.0034 - val_loss: 4.5714e-05 - val_mae: 0.0054\n",
      "Epoch 692/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7820e-05 - mae: 0.0034\n",
      "Epoch 692: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.7372e-05 - mae: 0.0033 - val_loss: 4.1991e-05 - val_mae: 0.0052\n",
      "Epoch 693/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6664e-05 - mae: 0.0034\n",
      "Epoch 693: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.7475e-05 - mae: 0.0034 - val_loss: 4.5707e-05 - val_mae: 0.0054\n",
      "Epoch 694/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.7545e-05 - mae: 0.0034\n",
      "Epoch 694: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7165e-05 - mae: 0.0033 - val_loss: 4.3847e-05 - val_mae: 0.0053\n",
      "Epoch 695/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5926e-05 - mae: 0.0032\n",
      "Epoch 695: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.6635e-05 - mae: 0.0033 - val_loss: 4.5879e-05 - val_mae: 0.0054\n",
      "Epoch 696/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7899e-05 - mae: 0.0034\n",
      "Epoch 696: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7780e-05 - mae: 0.0034 - val_loss: 4.3435e-05 - val_mae: 0.0053\n",
      "Epoch 697/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.7485e-05 - mae: 0.0034\n",
      "Epoch 697: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.8192e-05 - mae: 0.0035 - val_loss: 4.3448e-05 - val_mae: 0.0053\n",
      "Epoch 698/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7374e-05 - mae: 0.0033\n",
      "Epoch 698: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.8530e-05 - mae: 0.0034 - val_loss: 4.2278e-05 - val_mae: 0.0053\n",
      "Epoch 699/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6254e-05 - mae: 0.0032\n",
      "Epoch 699: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.7344e-05 - mae: 0.0034 - val_loss: 4.2121e-05 - val_mae: 0.0053\n",
      "Epoch 700/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.6935e-05 - mae: 0.0033\n",
      "Epoch 700: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.8361e-05 - mae: 0.0034 - val_loss: 4.2362e-05 - val_mae: 0.0053\n",
      "Epoch 701/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.7715e-05 - mae: 0.0033\n",
      "Epoch 701: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.7640e-05 - mae: 0.0034 - val_loss: 4.2481e-05 - val_mae: 0.0053\n",
      "Epoch 702/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6798e-05 - mae: 0.0033\n",
      "Epoch 702: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7512e-05 - mae: 0.0034 - val_loss: 4.9677e-05 - val_mae: 0.0057\n",
      "Epoch 703/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 2.2431e-05 - mae: 0.0037\n",
      "Epoch 703: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 2.0333e-05 - mae: 0.0036 - val_loss: 5.1522e-05 - val_mae: 0.0058\n",
      "Epoch 704/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7084e-05 - mae: 0.0033\n",
      "Epoch 704: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.8740e-05 - mae: 0.0035 - val_loss: 4.1949e-05 - val_mae: 0.0053\n",
      "Epoch 705/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6611e-05 - mae: 0.0032\n",
      "Epoch 705: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.6611e-05 - mae: 0.0032 - val_loss: 4.3189e-05 - val_mae: 0.0053\n",
      "Epoch 706/1000\n",
      "760/800 [===========================>..] - ETA: 0s - loss: 1.6731e-05 - mae: 0.0033\n",
      "Epoch 706: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 155us/sample - loss: 1.6672e-05 - mae: 0.0033 - val_loss: 4.1688e-05 - val_mae: 0.0052\n",
      "Epoch 707/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6728e-05 - mae: 0.0033\n",
      "Epoch 707: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.7585e-05 - mae: 0.0034 - val_loss: 4.3916e-05 - val_mae: 0.0054\n",
      "Epoch 708/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6575e-05 - mae: 0.0032\n",
      "Epoch 708: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.6494e-05 - mae: 0.0032 - val_loss: 4.3787e-05 - val_mae: 0.0053\n",
      "Epoch 709/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8308e-05 - mae: 0.0034\n",
      "Epoch 709: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7263e-05 - mae: 0.0033 - val_loss: 4.2018e-05 - val_mae: 0.0053\n",
      "Epoch 710/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7029e-05 - mae: 0.0033\n",
      "Epoch 710: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.6402e-05 - mae: 0.0033 - val_loss: 4.1664e-05 - val_mae: 0.0052\n",
      "Epoch 711/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.9601e-05 - mae: 0.0036\n",
      "Epoch 711: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.8766e-05 - mae: 0.0035 - val_loss: 4.7082e-05 - val_mae: 0.0055\n",
      "Epoch 712/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5849e-05 - mae: 0.0032\n",
      "Epoch 712: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6493e-05 - mae: 0.0033 - val_loss: 4.4577e-05 - val_mae: 0.0054\n",
      "Epoch 713/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6974e-05 - mae: 0.0033\n",
      "Epoch 713: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.6686e-05 - mae: 0.0033 - val_loss: 4.1749e-05 - val_mae: 0.0052\n",
      "Epoch 714/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5034e-05 - mae: 0.0031\n",
      "Epoch 714: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8367e-05 - mae: 0.0035 - val_loss: 4.7888e-05 - val_mae: 0.0056\n",
      "Epoch 715/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410/800 [==============>...............] - ETA: 0s - loss: 2.0620e-05 - mae: 0.0036\n",
      "Epoch 715: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.9425e-05 - mae: 0.0035 - val_loss: 4.1599e-05 - val_mae: 0.0052\n",
      "Epoch 716/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7072e-05 - mae: 0.0034\n",
      "Epoch 716: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7390e-05 - mae: 0.0034 - val_loss: 4.3083e-05 - val_mae: 0.0053\n",
      "Epoch 717/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.4779e-05 - mae: 0.0031\n",
      "Epoch 717: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.6311e-05 - mae: 0.0032 - val_loss: 4.1985e-05 - val_mae: 0.0052\n",
      "Epoch 718/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6350e-05 - mae: 0.0033\n",
      "Epoch 718: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.6928e-05 - mae: 0.0033 - val_loss: 4.1551e-05 - val_mae: 0.0052\n",
      "Epoch 719/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7756e-05 - mae: 0.0034\n",
      "Epoch 719: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.8149e-05 - mae: 0.0034 - val_loss: 4.2103e-05 - val_mae: 0.0052\n",
      "Epoch 720/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.5551e-05 - mae: 0.0031\n",
      "Epoch 720: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.6080e-05 - mae: 0.0032 - val_loss: 4.1806e-05 - val_mae: 0.0052\n",
      "Epoch 721/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7005e-05 - mae: 0.0033\n",
      "Epoch 721: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.6705e-05 - mae: 0.0033 - val_loss: 4.6078e-05 - val_mae: 0.0054\n",
      "Epoch 722/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7925e-05 - mae: 0.0034\n",
      "Epoch 722: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.8228e-05 - mae: 0.0034 - val_loss: 4.1567e-05 - val_mae: 0.0052\n",
      "Epoch 723/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6985e-05 - mae: 0.0033\n",
      "Epoch 723: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7085e-05 - mae: 0.0033 - val_loss: 4.1491e-05 - val_mae: 0.0052\n",
      "Epoch 724/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6440e-05 - mae: 0.0033\n",
      "Epoch 724: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6911e-05 - mae: 0.0033 - val_loss: 4.1924e-05 - val_mae: 0.0053\n",
      "Epoch 725/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6185e-05 - mae: 0.0032\n",
      "Epoch 725: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7764e-05 - mae: 0.0034 - val_loss: 4.4920e-05 - val_mae: 0.0054\n",
      "Epoch 726/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9159e-05 - mae: 0.0035\n",
      "Epoch 726: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.9801e-05 - mae: 0.0036 - val_loss: 4.6851e-05 - val_mae: 0.0055\n",
      "Epoch 727/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.8584e-05 - mae: 0.0034\n",
      "Epoch 727: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 1.7573e-05 - mae: 0.0033 - val_loss: 4.1877e-05 - val_mae: 0.0052\n",
      "Epoch 728/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.5152e-05 - mae: 0.0031\n",
      "Epoch 728: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.6235e-05 - mae: 0.0032 - val_loss: 4.3671e-05 - val_mae: 0.0053\n",
      "Epoch 729/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6830e-05 - mae: 0.0033\n",
      "Epoch 729: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.6739e-05 - mae: 0.0033 - val_loss: 4.2181e-05 - val_mae: 0.0053\n",
      "Epoch 730/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9202e-05 - mae: 0.0035\n",
      "Epoch 730: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.8975e-05 - mae: 0.0035 - val_loss: 4.5938e-05 - val_mae: 0.0055\n",
      "Epoch 731/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7719e-05 - mae: 0.0034\n",
      "Epoch 731: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7391e-05 - mae: 0.0033 - val_loss: 4.3744e-05 - val_mae: 0.0053\n",
      "Epoch 732/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.6600e-05 - mae: 0.0032\n",
      "Epoch 732: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.6160e-05 - mae: 0.0032 - val_loss: 4.1934e-05 - val_mae: 0.0052\n",
      "Epoch 733/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.5889e-05 - mae: 0.0032\n",
      "Epoch 733: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.7280e-05 - mae: 0.0033 - val_loss: 4.6473e-05 - val_mae: 0.0055\n",
      "Epoch 734/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.8065e-05 - mae: 0.0035\n",
      "Epoch 734: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7907e-05 - mae: 0.0034 - val_loss: 4.2239e-05 - val_mae: 0.0052\n",
      "Epoch 735/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6250e-05 - mae: 0.0032\n",
      "Epoch 735: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7944e-05 - mae: 0.0034 - val_loss: 4.5221e-05 - val_mae: 0.0054\n",
      "Epoch 736/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6564e-05 - mae: 0.0033\n",
      "Epoch 736: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.6821e-05 - mae: 0.0033 - val_loss: 5.0475e-05 - val_mae: 0.0058\n",
      "Epoch 737/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.6255e-05 - mae: 0.0033\n",
      "Epoch 737: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.7908e-05 - mae: 0.0034 - val_loss: 4.9328e-05 - val_mae: 0.0057\n",
      "Epoch 738/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6976e-05 - mae: 0.0033\n",
      "Epoch 738: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.6541e-05 - mae: 0.0033 - val_loss: 4.2008e-05 - val_mae: 0.0052\n",
      "Epoch 739/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.8355e-05 - mae: 0.0034\n",
      "Epoch 739: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.7685e-05 - mae: 0.0034 - val_loss: 4.2956e-05 - val_mae: 0.0053\n",
      "Epoch 740/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5340e-05 - mae: 0.0031\n",
      "Epoch 740: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.5832e-05 - mae: 0.0032 - val_loss: 4.2659e-05 - val_mae: 0.0053\n",
      "Epoch 741/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6324e-05 - mae: 0.0033\n",
      "Epoch 741: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.6644e-05 - mae: 0.0033 - val_loss: 4.2291e-05 - val_mae: 0.0053\n",
      "Epoch 742/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8356e-05 - mae: 0.0034\n",
      "Epoch 742: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7864e-05 - mae: 0.0034 - val_loss: 4.6017e-05 - val_mae: 0.0055\n",
      "Epoch 743/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7445e-05 - mae: 0.0034\n",
      "Epoch 743: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.8944e-05 - mae: 0.0035 - val_loss: 5.3976e-05 - val_mae: 0.0059\n",
      "Epoch 744/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520/800 [==================>...........] - ETA: 0s - loss: 1.6797e-05 - mae: 0.0033\n",
      "Epoch 744: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 1.7231e-05 - mae: 0.0034 - val_loss: 4.1669e-05 - val_mae: 0.0052\n",
      "Epoch 745/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7155e-05 - mae: 0.0033\n",
      "Epoch 745: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.6847e-05 - mae: 0.0033 - val_loss: 4.4572e-05 - val_mae: 0.0054\n",
      "Epoch 746/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6687e-05 - mae: 0.0032\n",
      "Epoch 746: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7146e-05 - mae: 0.0033 - val_loss: 4.2348e-05 - val_mae: 0.0052\n",
      "Epoch 747/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5668e-05 - mae: 0.0032\n",
      "Epoch 747: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.6560e-05 - mae: 0.0033 - val_loss: 5.5754e-05 - val_mae: 0.0060\n",
      "Epoch 748/1000\n",
      "380/800 [=============>................] - ETA: 0s - loss: 1.8964e-05 - mae: 0.0035\n",
      "Epoch 748: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.8679e-05 - mae: 0.0035 - val_loss: 4.5073e-05 - val_mae: 0.0054\n",
      "Epoch 749/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 2.0487e-05 - mae: 0.0036\n",
      "Epoch 749: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 2.0023e-05 - mae: 0.0036 - val_loss: 4.4205e-05 - val_mae: 0.0054\n",
      "Epoch 750/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6576e-05 - mae: 0.0033\n",
      "Epoch 750: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.7546e-05 - mae: 0.0034 - val_loss: 4.4234e-05 - val_mae: 0.0054\n",
      "Epoch 751/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 1.7449e-05 - mae: 0.0033\n",
      "Epoch 751: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 1.6858e-05 - mae: 0.0033 - val_loss: 4.2571e-05 - val_mae: 0.0053\n",
      "Epoch 752/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6176e-05 - mae: 0.0033\n",
      "Epoch 752: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.6463e-05 - mae: 0.0033 - val_loss: 4.2481e-05 - val_mae: 0.0053\n",
      "Epoch 753/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6578e-05 - mae: 0.0033\n",
      "Epoch 753: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7863e-05 - mae: 0.0034 - val_loss: 4.5792e-05 - val_mae: 0.0055\n",
      "Epoch 754/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6546e-05 - mae: 0.0033\n",
      "Epoch 754: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.7057e-05 - mae: 0.0033 - val_loss: 4.1709e-05 - val_mae: 0.0052\n",
      "Epoch 755/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.5504e-05 - mae: 0.0032\n",
      "Epoch 755: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 1.6206e-05 - mae: 0.0033 - val_loss: 4.3110e-05 - val_mae: 0.0053\n",
      "Epoch 756/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.8802e-05 - mae: 0.0035\n",
      "Epoch 756: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 1.8111e-05 - mae: 0.0034 - val_loss: 4.2397e-05 - val_mae: 0.0052\n",
      "Epoch 757/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.6835e-05 - mae: 0.0033\n",
      "Epoch 757: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.6934e-05 - mae: 0.0033 - val_loss: 4.2278e-05 - val_mae: 0.0053\n",
      "Epoch 758/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7208e-05 - mae: 0.0034\n",
      "Epoch 758: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 1.8257e-05 - mae: 0.0035 - val_loss: 4.3806e-05 - val_mae: 0.0053\n",
      "Epoch 759/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 2.2455e-05 - mae: 0.0038\n",
      "Epoch 759: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 2.1965e-05 - mae: 0.0037 - val_loss: 4.3910e-05 - val_mae: 0.0053\n",
      "Epoch 760/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.8004e-05 - mae: 0.0035\n",
      "Epoch 760: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.6736e-05 - mae: 0.0033 - val_loss: 4.3231e-05 - val_mae: 0.0053\n",
      "Epoch 761/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.5884e-05 - mae: 0.0032\n",
      "Epoch 761: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 121us/sample - loss: 1.6341e-05 - mae: 0.0032 - val_loss: 4.2479e-05 - val_mae: 0.0053\n",
      "Epoch 762/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7348e-05 - mae: 0.0034\n",
      "Epoch 762: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.7893e-05 - mae: 0.0034 - val_loss: 4.5714e-05 - val_mae: 0.0055\n",
      "Epoch 763/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.9931e-05 - mae: 0.0036\n",
      "Epoch 763: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.8680e-05 - mae: 0.0035 - val_loss: 4.2758e-05 - val_mae: 0.0053\n",
      "Epoch 764/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.4784e-05 - mae: 0.0031\n",
      "Epoch 764: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.9521e-05 - mae: 0.0035 - val_loss: 4.2510e-05 - val_mae: 0.0053\n",
      "Epoch 765/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7629e-05 - mae: 0.0034\n",
      "Epoch 765: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7686e-05 - mae: 0.0034 - val_loss: 5.1299e-05 - val_mae: 0.0058\n",
      "Epoch 766/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6403e-05 - mae: 0.0033\n",
      "Epoch 766: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.7695e-05 - mae: 0.0034 - val_loss: 4.4545e-05 - val_mae: 0.0054\n",
      "Epoch 767/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9159e-05 - mae: 0.0035\n",
      "Epoch 767: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.8672e-05 - mae: 0.0035 - val_loss: 4.3755e-05 - val_mae: 0.0053\n",
      "Epoch 768/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7565e-05 - mae: 0.0034\n",
      "Epoch 768: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6406e-05 - mae: 0.0032 - val_loss: 4.2058e-05 - val_mae: 0.0053\n",
      "Epoch 769/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6910e-05 - mae: 0.0033\n",
      "Epoch 769: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.6740e-05 - mae: 0.0033 - val_loss: 4.2322e-05 - val_mae: 0.0052\n",
      "Epoch 770/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.6798e-05 - mae: 0.0033\n",
      "Epoch 770: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.8367e-05 - mae: 0.0034 - val_loss: 4.3067e-05 - val_mae: 0.0053\n",
      "Epoch 771/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5234e-05 - mae: 0.0032\n",
      "Epoch 771: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.6238e-05 - mae: 0.0032 - val_loss: 4.2375e-05 - val_mae: 0.0053\n",
      "Epoch 772/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5001e-05 - mae: 0.0031\n",
      "Epoch 772: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6579e-05 - mae: 0.0033 - val_loss: 4.5676e-05 - val_mae: 0.0054\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/800 [================>.............] - ETA: 0s - loss: 2.1929e-05 - mae: 0.0038\n",
      "Epoch 773: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 2.1543e-05 - mae: 0.0037 - val_loss: 4.4978e-05 - val_mae: 0.0054\n",
      "Epoch 774/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5509e-05 - mae: 0.0032\n",
      "Epoch 774: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.6584e-05 - mae: 0.0032 - val_loss: 4.5621e-05 - val_mae: 0.0054\n",
      "Epoch 775/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.9264e-05 - mae: 0.0035\n",
      "Epoch 775: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.9264e-05 - mae: 0.0035 - val_loss: 4.4016e-05 - val_mae: 0.0053\n",
      "Epoch 776/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7468e-05 - mae: 0.0033\n",
      "Epoch 776: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6670e-05 - mae: 0.0032 - val_loss: 4.2537e-05 - val_mae: 0.0053\n",
      "Epoch 777/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5351e-05 - mae: 0.0031\n",
      "Epoch 777: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6248e-05 - mae: 0.0032 - val_loss: 4.2583e-05 - val_mae: 0.0053\n",
      "Epoch 778/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5924e-05 - mae: 0.0032\n",
      "Epoch 778: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.6622e-05 - mae: 0.0033 - val_loss: 4.3558e-05 - val_mae: 0.0053\n",
      "Epoch 779/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7429e-05 - mae: 0.0033\n",
      "Epoch 779: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.7461e-05 - mae: 0.0034 - val_loss: 4.2872e-05 - val_mae: 0.0053\n",
      "Epoch 780/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5465e-05 - mae: 0.0032\n",
      "Epoch 780: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.6388e-05 - mae: 0.0032 - val_loss: 4.2638e-05 - val_mae: 0.0053\n",
      "Epoch 781/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7236e-05 - mae: 0.0033\n",
      "Epoch 781: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 152us/sample - loss: 1.7236e-05 - mae: 0.0033 - val_loss: 5.0254e-05 - val_mae: 0.0057\n",
      "Epoch 782/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5408e-05 - mae: 0.0032\n",
      "Epoch 782: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.5844e-05 - mae: 0.0032 - val_loss: 4.1982e-05 - val_mae: 0.0052\n",
      "Epoch 783/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.6809e-05 - mae: 0.0033\n",
      "Epoch 783: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.6504e-05 - mae: 0.0033 - val_loss: 5.3842e-05 - val_mae: 0.0059\n",
      "Epoch 784/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 2.0172e-05 - mae: 0.0036\n",
      "Epoch 784: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.8620e-05 - mae: 0.0035 - val_loss: 4.2264e-05 - val_mae: 0.0052\n",
      "Epoch 785/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.7363e-05 - mae: 0.0033\n",
      "Epoch 785: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.9402e-05 - mae: 0.0035 - val_loss: 4.9654e-05 - val_mae: 0.0057\n",
      "Epoch 786/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.8838e-05 - mae: 0.0035\n",
      "Epoch 786: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.9750e-05 - mae: 0.0035 - val_loss: 4.2398e-05 - val_mae: 0.0052\n",
      "Epoch 787/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.8842e-05 - mae: 0.0035\n",
      "Epoch 787: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8942e-05 - mae: 0.0035 - val_loss: 4.2375e-05 - val_mae: 0.0053\n",
      "Epoch 788/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8618e-05 - mae: 0.0035\n",
      "Epoch 788: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.8111e-05 - mae: 0.0034 - val_loss: 4.2919e-05 - val_mae: 0.0053\n",
      "Epoch 789/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7239e-05 - mae: 0.0033\n",
      "Epoch 789: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.8576e-05 - mae: 0.0035 - val_loss: 5.2826e-05 - val_mae: 0.0059\n",
      "Epoch 790/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.8112e-05 - mae: 0.0034\n",
      "Epoch 790: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7100e-05 - mae: 0.0033 - val_loss: 4.2193e-05 - val_mae: 0.0052\n",
      "Epoch 791/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.5006e-05 - mae: 0.0031\n",
      "Epoch 791: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.6125e-05 - mae: 0.0032 - val_loss: 4.2458e-05 - val_mae: 0.0053\n",
      "Epoch 792/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6246e-05 - mae: 0.0033\n",
      "Epoch 792: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.6790e-05 - mae: 0.0033 - val_loss: 4.2092e-05 - val_mae: 0.0053\n",
      "Epoch 793/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6510e-05 - mae: 0.0033\n",
      "Epoch 793: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.9065e-05 - mae: 0.0035 - val_loss: 5.2288e-05 - val_mae: 0.0058\n",
      "Epoch 794/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.8190e-05 - mae: 0.0034\n",
      "Epoch 794: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.8582e-05 - mae: 0.0035 - val_loss: 4.6352e-05 - val_mae: 0.0055\n",
      "Epoch 795/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.8097e-05 - mae: 0.0034\n",
      "Epoch 795: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7756e-05 - mae: 0.0034 - val_loss: 4.6687e-05 - val_mae: 0.0055\n",
      "Epoch 796/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7082e-05 - mae: 0.0033\n",
      "Epoch 796: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.7082e-05 - mae: 0.0033 - val_loss: 4.5351e-05 - val_mae: 0.0054\n",
      "Epoch 797/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7715e-05 - mae: 0.0034\n",
      "Epoch 797: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7335e-05 - mae: 0.0034 - val_loss: 4.3424e-05 - val_mae: 0.0053\n",
      "Epoch 798/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6418e-05 - mae: 0.0032\n",
      "Epoch 798: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7045e-05 - mae: 0.0033 - val_loss: 4.2277e-05 - val_mae: 0.0052\n",
      "Epoch 799/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4525e-05 - mae: 0.0031\n",
      "Epoch 799: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.6853e-05 - mae: 0.0033 - val_loss: 4.2729e-05 - val_mae: 0.0052\n",
      "Epoch 800/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7614e-05 - mae: 0.0033\n",
      "Epoch 800: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6181e-05 - mae: 0.0032 - val_loss: 4.3916e-05 - val_mae: 0.0054\n",
      "Epoch 801/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7928e-05 - mae: 0.0034\n",
      "Epoch 801: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.9773e-05 - mae: 0.0036 - val_loss: 4.7382e-05 - val_mae: 0.0056\n",
      "Epoch 802/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/800 [================>.............] - ETA: 0s - loss: 1.7002e-05 - mae: 0.0033\n",
      "Epoch 802: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.7781e-05 - mae: 0.0034 - val_loss: 4.3138e-05 - val_mae: 0.0053\n",
      "Epoch 803/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9098e-05 - mae: 0.0035\n",
      "Epoch 803: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7780e-05 - mae: 0.0034 - val_loss: 4.3473e-05 - val_mae: 0.0053\n",
      "Epoch 804/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.4577e-05 - mae: 0.0031\n",
      "Epoch 804: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.9004e-05 - mae: 0.0035 - val_loss: 4.4347e-05 - val_mae: 0.0054\n",
      "Epoch 805/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6164e-05 - mae: 0.0032\n",
      "Epoch 805: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.8135e-05 - mae: 0.0034 - val_loss: 5.6157e-05 - val_mae: 0.0061\n",
      "Epoch 806/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 2.0370e-05 - mae: 0.0036\n",
      "Epoch 806: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 1.9482e-05 - mae: 0.0036 - val_loss: 4.3623e-05 - val_mae: 0.0053\n",
      "Epoch 807/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.5831e-05 - mae: 0.0032\n",
      "Epoch 807: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 1.7732e-05 - mae: 0.0034 - val_loss: 4.5300e-05 - val_mae: 0.0054\n",
      "Epoch 808/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.5361e-05 - mae: 0.0032\n",
      "Epoch 808: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 1.6037e-05 - mae: 0.0032 - val_loss: 4.3111e-05 - val_mae: 0.0053\n",
      "Epoch 809/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.5788e-05 - mae: 0.0032\n",
      "Epoch 809: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.7119e-05 - mae: 0.0033 - val_loss: 4.3033e-05 - val_mae: 0.0053\n",
      "Epoch 810/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.5464e-05 - mae: 0.0032\n",
      "Epoch 810: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 1.7426e-05 - mae: 0.0033 - val_loss: 4.2272e-05 - val_mae: 0.0052\n",
      "Epoch 811/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6592e-05 - mae: 0.0033\n",
      "Epoch 811: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 1.6787e-05 - mae: 0.0033 - val_loss: 4.2527e-05 - val_mae: 0.0052\n",
      "Epoch 812/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6183e-05 - mae: 0.0032\n",
      "Epoch 812: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.7882e-05 - mae: 0.0034 - val_loss: 4.3956e-05 - val_mae: 0.0053\n",
      "Epoch 813/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.7670e-05 - mae: 0.0034\n",
      "Epoch 813: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 1.7043e-05 - mae: 0.0033 - val_loss: 4.3088e-05 - val_mae: 0.0053\n",
      "Epoch 814/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.7944e-05 - mae: 0.0034\n",
      "Epoch 814: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 1.7767e-05 - mae: 0.0034 - val_loss: 4.7649e-05 - val_mae: 0.0056\n",
      "Epoch 815/1000\n",
      "580/800 [====================>.........] - ETA: 0s - loss: 1.6190e-05 - mae: 0.0032\n",
      "Epoch 815: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 1.6558e-05 - mae: 0.0032 - val_loss: 4.5566e-05 - val_mae: 0.0054\n",
      "Epoch 816/1000\n",
      "590/800 [=====================>........] - ETA: 0s - loss: 2.3092e-05 - mae: 0.0039\n",
      "Epoch 816: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 2.1761e-05 - mae: 0.0038 - val_loss: 4.2648e-05 - val_mae: 0.0053\n",
      "Epoch 817/1000\n",
      "600/800 [=====================>........] - ETA: 0s - loss: 1.6224e-05 - mae: 0.0033\n",
      "Epoch 817: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 1.6451e-05 - mae: 0.0033 - val_loss: 4.2293e-05 - val_mae: 0.0053\n",
      "Epoch 818/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 1.7164e-05 - mae: 0.0033\n",
      "Epoch 818: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 1.8321e-05 - mae: 0.0034 - val_loss: 4.2178e-05 - val_mae: 0.0052\n",
      "Epoch 819/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.6558e-05 - mae: 0.0033\n",
      "Epoch 819: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.9290e-05 - mae: 0.0036 - val_loss: 5.0974e-05 - val_mae: 0.0057\n",
      "Epoch 820/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.9019e-05 - mae: 0.0036\n",
      "Epoch 820: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.8531e-05 - mae: 0.0035 - val_loss: 4.2589e-05 - val_mae: 0.0053\n",
      "Epoch 821/1000\n",
      "570/800 [====================>.........] - ETA: 0s - loss: 1.5876e-05 - mae: 0.0032\n",
      "Epoch 821: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 1.6376e-05 - mae: 0.0032 - val_loss: 4.5702e-05 - val_mae: 0.0054\n",
      "Epoch 822/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9414e-05 - mae: 0.0036\n",
      "Epoch 822: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7766e-05 - mae: 0.0034 - val_loss: 4.2106e-05 - val_mae: 0.0053\n",
      "Epoch 823/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.8086e-05 - mae: 0.0034\n",
      "Epoch 823: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 1.8259e-05 - mae: 0.0035 - val_loss: 4.3750e-05 - val_mae: 0.0053\n",
      "Epoch 824/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.6195e-05 - mae: 0.0032\n",
      "Epoch 824: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 1.6371e-05 - mae: 0.0033 - val_loss: 4.1824e-05 - val_mae: 0.0052\n",
      "Epoch 825/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.7142e-05 - mae: 0.0033\n",
      "Epoch 825: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.6387e-05 - mae: 0.0033 - val_loss: 4.3220e-05 - val_mae: 0.0053\n",
      "Epoch 826/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.8775e-05 - mae: 0.0035\n",
      "Epoch 826: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.7521e-05 - mae: 0.0034 - val_loss: 4.5930e-05 - val_mae: 0.0054\n",
      "Epoch 827/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.7923e-05 - mae: 0.0034\n",
      "Epoch 827: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 1.7691e-05 - mae: 0.0034 - val_loss: 4.3764e-05 - val_mae: 0.0053\n",
      "Epoch 828/1000\n",
      "580/800 [====================>.........] - ETA: 0s - loss: 1.6596e-05 - mae: 0.0033\n",
      "Epoch 828: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 1.6818e-05 - mae: 0.0033 - val_loss: 4.4482e-05 - val_mae: 0.0053\n",
      "Epoch 829/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.6504e-05 - mae: 0.0033\n",
      "Epoch 829: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 1.6855e-05 - mae: 0.0033 - val_loss: 4.1816e-05 - val_mae: 0.0052\n",
      "Epoch 830/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.5906e-05 - mae: 0.0032\n",
      "Epoch 830: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 1.6953e-05 - mae: 0.0033 - val_loss: 5.0799e-05 - val_mae: 0.0057\n",
      "Epoch 831/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520/800 [==================>...........] - ETA: 0s - loss: 1.7156e-05 - mae: 0.0034\n",
      "Epoch 831: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 1.7461e-05 - mae: 0.0034 - val_loss: 4.5319e-05 - val_mae: 0.0054\n",
      "Epoch 832/1000\n",
      "570/800 [====================>.........] - ETA: 0s - loss: 1.7275e-05 - mae: 0.0033\n",
      "Epoch 832: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 1.6711e-05 - mae: 0.0033 - val_loss: 4.3643e-05 - val_mae: 0.0053\n",
      "Epoch 833/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7788e-05 - mae: 0.0034\n",
      "Epoch 833: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.6854e-05 - mae: 0.0033 - val_loss: 4.1953e-05 - val_mae: 0.0052\n",
      "Epoch 834/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7389e-05 - mae: 0.0033\n",
      "Epoch 834: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.5962e-05 - mae: 0.0032 - val_loss: 4.2484e-05 - val_mae: 0.0052\n",
      "Epoch 835/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6911e-05 - mae: 0.0033\n",
      "Epoch 835: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.8377e-05 - mae: 0.0035 - val_loss: 5.2989e-05 - val_mae: 0.0059\n",
      "Epoch 836/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.8529e-05 - mae: 0.0035\n",
      "Epoch 836: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6883e-05 - mae: 0.0033 - val_loss: 4.2708e-05 - val_mae: 0.0053\n",
      "Epoch 837/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7455e-05 - mae: 0.0033\n",
      "Epoch 837: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7236e-05 - mae: 0.0033 - val_loss: 4.1857e-05 - val_mae: 0.0052\n",
      "Epoch 838/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6014e-05 - mae: 0.0033\n",
      "Epoch 838: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7137e-05 - mae: 0.0033 - val_loss: 4.6295e-05 - val_mae: 0.0055\n",
      "Epoch 839/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6559e-05 - mae: 0.0032\n",
      "Epoch 839: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.6599e-05 - mae: 0.0033 - val_loss: 4.6359e-05 - val_mae: 0.0055\n",
      "Epoch 840/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.6793e-05 - mae: 0.0032\n",
      "Epoch 840: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6488e-05 - mae: 0.0032 - val_loss: 4.6577e-05 - val_mae: 0.0055\n",
      "Epoch 841/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 2.3567e-05 - mae: 0.0038\n",
      "Epoch 841: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 2.0605e-05 - mae: 0.0036 - val_loss: 4.6088e-05 - val_mae: 0.0054\n",
      "Epoch 842/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5375e-05 - mae: 0.0032\n",
      "Epoch 842: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.6504e-05 - mae: 0.0033 - val_loss: 4.1873e-05 - val_mae: 0.0052\n",
      "Epoch 843/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7547e-05 - mae: 0.0034\n",
      "Epoch 843: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.8232e-05 - mae: 0.0034 - val_loss: 4.6808e-05 - val_mae: 0.0055\n",
      "Epoch 844/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7866e-05 - mae: 0.0034\n",
      "Epoch 844: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7885e-05 - mae: 0.0034 - val_loss: 4.2311e-05 - val_mae: 0.0052\n",
      "Epoch 845/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7772e-05 - mae: 0.0034\n",
      "Epoch 845: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7749e-05 - mae: 0.0034 - val_loss: 4.1669e-05 - val_mae: 0.0052\n",
      "Epoch 846/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.4983e-05 - mae: 0.0031\n",
      "Epoch 846: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.5852e-05 - mae: 0.0032 - val_loss: 4.2533e-05 - val_mae: 0.0053\n",
      "Epoch 847/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6958e-05 - mae: 0.0034\n",
      "Epoch 847: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7832e-05 - mae: 0.0034 - val_loss: 4.1659e-05 - val_mae: 0.0052\n",
      "Epoch 848/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.7001e-05 - mae: 0.0033\n",
      "Epoch 848: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.6439e-05 - mae: 0.0033 - val_loss: 4.5664e-05 - val_mae: 0.0054\n",
      "Epoch 849/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6329e-05 - mae: 0.0032\n",
      "Epoch 849: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 1.6936e-05 - mae: 0.0033 - val_loss: 4.1865e-05 - val_mae: 0.0052\n",
      "Epoch 850/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 1.8719e-05 - mae: 0.0034\n",
      "Epoch 850: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.9260e-05 - mae: 0.0035 - val_loss: 4.2023e-05 - val_mae: 0.0052\n",
      "Epoch 851/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.7647e-05 - mae: 0.0033\n",
      "Epoch 851: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.7694e-05 - mae: 0.0034 - val_loss: 5.2333e-05 - val_mae: 0.0058\n",
      "Epoch 852/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.9528e-05 - mae: 0.0035\n",
      "Epoch 852: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.8027e-05 - mae: 0.0034 - val_loss: 4.2696e-05 - val_mae: 0.0052\n",
      "Epoch 853/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5135e-05 - mae: 0.0031\n",
      "Epoch 853: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.6433e-05 - mae: 0.0033 - val_loss: 4.7171e-05 - val_mae: 0.0055\n",
      "Epoch 854/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 2.0116e-05 - mae: 0.0036\n",
      "Epoch 854: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.9253e-05 - mae: 0.0035 - val_loss: 4.4426e-05 - val_mae: 0.0054\n",
      "Epoch 855/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.7709e-05 - mae: 0.0034\n",
      "Epoch 855: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.7363e-05 - mae: 0.0034 - val_loss: 4.4551e-05 - val_mae: 0.0054\n",
      "Epoch 856/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5782e-05 - mae: 0.0032\n",
      "Epoch 856: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.7922e-05 - mae: 0.0034 - val_loss: 4.4186e-05 - val_mae: 0.0054\n",
      "Epoch 857/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.8033e-05 - mae: 0.0035\n",
      "Epoch 857: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7940e-05 - mae: 0.0034 - val_loss: 4.2305e-05 - val_mae: 0.0052\n",
      "Epoch 858/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.7954e-05 - mae: 0.0034\n",
      "Epoch 858: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.7954e-05 - mae: 0.0034 - val_loss: 4.7474e-05 - val_mae: 0.0056\n",
      "Epoch 859/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7182e-05 - mae: 0.0033\n",
      "Epoch 859: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.6987e-05 - mae: 0.0033 - val_loss: 4.2033e-05 - val_mae: 0.0052\n",
      "Epoch 860/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780/800 [============================>.] - ETA: 0s - loss: 1.6399e-05 - mae: 0.0033\n",
      "Epoch 860: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 153us/sample - loss: 1.6286e-05 - mae: 0.0032 - val_loss: 4.2192e-05 - val_mae: 0.0052\n",
      "Epoch 861/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.5950e-05 - mae: 0.0032\n",
      "Epoch 861: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6775e-05 - mae: 0.0033 - val_loss: 4.1945e-05 - val_mae: 0.0052\n",
      "Epoch 862/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5851e-05 - mae: 0.0031\n",
      "Epoch 862: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.6305e-05 - mae: 0.0032 - val_loss: 4.2850e-05 - val_mae: 0.0053\n",
      "Epoch 863/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.6261e-05 - mae: 0.0032\n",
      "Epoch 863: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.8235e-05 - mae: 0.0034 - val_loss: 4.3844e-05 - val_mae: 0.0054\n",
      "Epoch 864/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.7040e-05 - mae: 0.0034\n",
      "Epoch 864: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7394e-05 - mae: 0.0034 - val_loss: 4.1803e-05 - val_mae: 0.0052\n",
      "Epoch 865/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7378e-05 - mae: 0.0033\n",
      "Epoch 865: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.7503e-05 - mae: 0.0033 - val_loss: 4.2365e-05 - val_mae: 0.0053\n",
      "Epoch 866/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6860e-05 - mae: 0.0033\n",
      "Epoch 866: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.7060e-05 - mae: 0.0033 - val_loss: 4.1687e-05 - val_mae: 0.0052\n",
      "Epoch 867/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6310e-05 - mae: 0.0032\n",
      "Epoch 867: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.7542e-05 - mae: 0.0034 - val_loss: 4.1763e-05 - val_mae: 0.0052\n",
      "Epoch 868/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.9181e-05 - mae: 0.0035\n",
      "Epoch 868: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7797e-05 - mae: 0.0034 - val_loss: 4.3022e-05 - val_mae: 0.0053\n",
      "Epoch 869/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7055e-05 - mae: 0.0033\n",
      "Epoch 869: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.8006e-05 - mae: 0.0034 - val_loss: 4.6814e-05 - val_mae: 0.0055\n",
      "Epoch 870/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6494e-05 - mae: 0.0033\n",
      "Epoch 870: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6389e-05 - mae: 0.0033 - val_loss: 4.3578e-05 - val_mae: 0.0053\n",
      "Epoch 871/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.8040e-05 - mae: 0.0034\n",
      "Epoch 871: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6909e-05 - mae: 0.0033 - val_loss: 4.2669e-05 - val_mae: 0.0053\n",
      "Epoch 872/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6772e-05 - mae: 0.0033\n",
      "Epoch 872: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6758e-05 - mae: 0.0033 - val_loss: 4.6985e-05 - val_mae: 0.0055\n",
      "Epoch 873/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 2.0058e-05 - mae: 0.0037\n",
      "Epoch 873: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 2.1500e-05 - mae: 0.0038 - val_loss: 4.1913e-05 - val_mae: 0.0052\n",
      "Epoch 874/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 2.0686e-05 - mae: 0.0036\n",
      "Epoch 874: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.9442e-05 - mae: 0.0035 - val_loss: 4.5915e-05 - val_mae: 0.0055\n",
      "Epoch 875/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6981e-05 - mae: 0.0033\n",
      "Epoch 875: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7725e-05 - mae: 0.0034 - val_loss: 4.6640e-05 - val_mae: 0.0055\n",
      "Epoch 876/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.7362e-05 - mae: 0.0034\n",
      "Epoch 876: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7225e-05 - mae: 0.0033 - val_loss: 4.5423e-05 - val_mae: 0.0054\n",
      "Epoch 877/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5477e-05 - mae: 0.0032\n",
      "Epoch 877: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6390e-05 - mae: 0.0033 - val_loss: 4.5094e-05 - val_mae: 0.0054\n",
      "Epoch 878/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 2.2608e-05 - mae: 0.0039\n",
      "Epoch 878: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.9747e-05 - mae: 0.0036 - val_loss: 4.2090e-05 - val_mae: 0.0052\n",
      "Epoch 879/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.6423e-05 - mae: 0.0032\n",
      "Epoch 879: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6459e-05 - mae: 0.0032 - val_loss: 4.2294e-05 - val_mae: 0.0052\n",
      "Epoch 880/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6946e-05 - mae: 0.0033\n",
      "Epoch 880: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.8345e-05 - mae: 0.0034 - val_loss: 4.4491e-05 - val_mae: 0.0054\n",
      "Epoch 881/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 2.1934e-05 - mae: 0.0038\n",
      "Epoch 881: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.9839e-05 - mae: 0.0036 - val_loss: 4.3869e-05 - val_mae: 0.0054\n",
      "Epoch 882/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6159e-05 - mae: 0.0033\n",
      "Epoch 882: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.8284e-05 - mae: 0.0035 - val_loss: 5.0304e-05 - val_mae: 0.0057\n",
      "Epoch 883/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.9287e-05 - mae: 0.0035\n",
      "Epoch 883: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.8240e-05 - mae: 0.0034 - val_loss: 4.4434e-05 - val_mae: 0.0054\n",
      "Epoch 884/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7586e-05 - mae: 0.0034\n",
      "Epoch 884: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7711e-05 - mae: 0.0034 - val_loss: 5.8580e-05 - val_mae: 0.0062\n",
      "Epoch 885/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.9279e-05 - mae: 0.0035\n",
      "Epoch 885: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.7783e-05 - mae: 0.0034 - val_loss: 4.1991e-05 - val_mae: 0.0052\n",
      "Epoch 886/1000\n",
      "790/800 [============================>.] - ETA: 0s - loss: 1.6190e-05 - mae: 0.0032\n",
      "Epoch 886: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 150us/sample - loss: 1.6181e-05 - mae: 0.0032 - val_loss: 4.3382e-05 - val_mae: 0.0053\n",
      "Epoch 887/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6428e-05 - mae: 0.0033\n",
      "Epoch 887: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.6897e-05 - mae: 0.0033 - val_loss: 4.2109e-05 - val_mae: 0.0053\n",
      "Epoch 888/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5759e-05 - mae: 0.0032\n",
      "Epoch 888: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7091e-05 - mae: 0.0033 - val_loss: 5.1623e-05 - val_mae: 0.0058\n",
      "Epoch 889/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/800 [=================>............] - ETA: 0s - loss: 1.6931e-05 - mae: 0.0033\n",
      "Epoch 889: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7381e-05 - mae: 0.0033 - val_loss: 4.5392e-05 - val_mae: 0.0055\n",
      "Epoch 890/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.6478e-05 - mae: 0.0032\n",
      "Epoch 890: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 156us/sample - loss: 1.6451e-05 - mae: 0.0033 - val_loss: 4.3077e-05 - val_mae: 0.0053\n",
      "Epoch 891/1000\n",
      "390/800 [=============>................] - ETA: 0s - loss: 1.5267e-05 - mae: 0.0031\n",
      "Epoch 891: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.6311e-05 - mae: 0.0033 - val_loss: 4.1798e-05 - val_mae: 0.0052\n",
      "Epoch 892/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6240e-05 - mae: 0.0033\n",
      "Epoch 892: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.7202e-05 - mae: 0.0034 - val_loss: 4.2571e-05 - val_mae: 0.0053\n",
      "Epoch 893/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5786e-05 - mae: 0.0032\n",
      "Epoch 893: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6707e-05 - mae: 0.0032 - val_loss: 4.2037e-05 - val_mae: 0.0053\n",
      "Epoch 894/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7255e-05 - mae: 0.0033\n",
      "Epoch 894: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6956e-05 - mae: 0.0033 - val_loss: 4.3180e-05 - val_mae: 0.0053\n",
      "Epoch 895/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.6408e-05 - mae: 0.0033\n",
      "Epoch 895: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.6408e-05 - mae: 0.0033 - val_loss: 4.2225e-05 - val_mae: 0.0052\n",
      "Epoch 896/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7384e-05 - mae: 0.0033\n",
      "Epoch 896: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6895e-05 - mae: 0.0033 - val_loss: 4.1788e-05 - val_mae: 0.0052\n",
      "Epoch 897/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8088e-05 - mae: 0.0034\n",
      "Epoch 897: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6797e-05 - mae: 0.0032 - val_loss: 4.1760e-05 - val_mae: 0.0052\n",
      "Epoch 898/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.4849e-05 - mae: 0.0030\n",
      "Epoch 898: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.7043e-05 - mae: 0.0033 - val_loss: 5.0549e-05 - val_mae: 0.0058\n",
      "Epoch 899/1000\n",
      "770/800 [===========================>..] - ETA: 0s - loss: 1.6866e-05 - mae: 0.0033\n",
      "Epoch 899: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 157us/sample - loss: 1.6844e-05 - mae: 0.0033 - val_loss: 4.2171e-05 - val_mae: 0.0052\n",
      "Epoch 900/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.5649e-05 - mae: 0.0032\n",
      "Epoch 900: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.6714e-05 - mae: 0.0033 - val_loss: 5.1428e-05 - val_mae: 0.0058\n",
      "Epoch 901/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7123e-05 - mae: 0.0033\n",
      "Epoch 901: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.7567e-05 - mae: 0.0034 - val_loss: 4.2101e-05 - val_mae: 0.0052\n",
      "Epoch 902/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6384e-05 - mae: 0.0032\n",
      "Epoch 902: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6695e-05 - mae: 0.0033 - val_loss: 4.3524e-05 - val_mae: 0.0053\n",
      "Epoch 903/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7595e-05 - mae: 0.0034\n",
      "Epoch 903: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.7300e-05 - mae: 0.0034 - val_loss: 4.1698e-05 - val_mae: 0.0052\n",
      "Epoch 904/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7009e-05 - mae: 0.0033\n",
      "Epoch 904: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.6977e-05 - mae: 0.0033 - val_loss: 4.4224e-05 - val_mae: 0.0053\n",
      "Epoch 905/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6824e-05 - mae: 0.0033\n",
      "Epoch 905: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.9001e-05 - mae: 0.0035 - val_loss: 4.3634e-05 - val_mae: 0.0053\n",
      "Epoch 906/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.8972e-05 - mae: 0.0035\n",
      "Epoch 906: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.8100e-05 - mae: 0.0034 - val_loss: 4.1341e-05 - val_mae: 0.0052\n",
      "Epoch 907/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.4957e-05 - mae: 0.0031\n",
      "Epoch 907: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 148us/sample - loss: 1.6823e-05 - mae: 0.0033 - val_loss: 5.1634e-05 - val_mae: 0.0058\n",
      "Epoch 908/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.8153e-05 - mae: 0.0034\n",
      "Epoch 908: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 142us/sample - loss: 1.7396e-05 - mae: 0.0034 - val_loss: 4.2349e-05 - val_mae: 0.0053\n",
      "Epoch 909/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5674e-05 - mae: 0.0032\n",
      "Epoch 909: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6401e-05 - mae: 0.0033 - val_loss: 4.7992e-05 - val_mae: 0.0056\n",
      "Epoch 910/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.8291e-05 - mae: 0.0035\n",
      "Epoch 910: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.7433e-05 - mae: 0.0033 - val_loss: 4.1353e-05 - val_mae: 0.0052\n",
      "Epoch 911/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6383e-05 - mae: 0.0032\n",
      "Epoch 911: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6869e-05 - mae: 0.0033 - val_loss: 4.1472e-05 - val_mae: 0.0052\n",
      "Epoch 912/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 2.2411e-05 - mae: 0.0038\n",
      "Epoch 912: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 2.2686e-05 - mae: 0.0038 - val_loss: 4.9399e-05 - val_mae: 0.0056\n",
      "Epoch 913/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.5229e-05 - mae: 0.0031\n",
      "Epoch 913: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.5985e-05 - mae: 0.0032 - val_loss: 4.1512e-05 - val_mae: 0.0052\n",
      "Epoch 914/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6894e-05 - mae: 0.0033\n",
      "Epoch 914: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.8227e-05 - mae: 0.0035 - val_loss: 4.7157e-05 - val_mae: 0.0056\n",
      "Epoch 915/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.8653e-05 - mae: 0.0035\n",
      "Epoch 915: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.8840e-05 - mae: 0.0035 - val_loss: 4.3010e-05 - val_mae: 0.0053\n",
      "Epoch 916/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6774e-05 - mae: 0.0033\n",
      "Epoch 916: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7362e-05 - mae: 0.0033 - val_loss: 4.3627e-05 - val_mae: 0.0053\n",
      "Epoch 917/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.6685e-05 - mae: 0.0033\n",
      "Epoch 917: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 119us/sample - loss: 1.7299e-05 - mae: 0.0034 - val_loss: 4.1720e-05 - val_mae: 0.0052\n",
      "Epoch 918/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560/800 [====================>.........] - ETA: 0s - loss: 1.8585e-05 - mae: 0.0035\n",
      "Epoch 918: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 1.8797e-05 - mae: 0.0035 - val_loss: 4.2149e-05 - val_mae: 0.0052\n",
      "Epoch 919/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7836e-05 - mae: 0.0034\n",
      "Epoch 919: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 122us/sample - loss: 1.7428e-05 - mae: 0.0033 - val_loss: 4.1681e-05 - val_mae: 0.0052\n",
      "Epoch 920/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6225e-05 - mae: 0.0033\n",
      "Epoch 920: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6446e-05 - mae: 0.0033 - val_loss: 4.5468e-05 - val_mae: 0.0054\n",
      "Epoch 921/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.8554e-05 - mae: 0.0034\n",
      "Epoch 921: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.8279e-05 - mae: 0.0034 - val_loss: 4.1556e-05 - val_mae: 0.0052\n",
      "Epoch 922/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.4980e-05 - mae: 0.0031\n",
      "Epoch 922: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.6002e-05 - mae: 0.0032 - val_loss: 4.1862e-05 - val_mae: 0.0053\n",
      "Epoch 923/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7006e-05 - mae: 0.0033\n",
      "Epoch 923: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.6950e-05 - mae: 0.0033 - val_loss: 4.2265e-05 - val_mae: 0.0052\n",
      "Epoch 924/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5466e-05 - mae: 0.0032\n",
      "Epoch 924: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.5871e-05 - mae: 0.0032 - val_loss: 5.0821e-05 - val_mae: 0.0057\n",
      "Epoch 925/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.8585e-05 - mae: 0.0034\n",
      "Epoch 925: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.7884e-05 - mae: 0.0034 - val_loss: 4.5375e-05 - val_mae: 0.0054\n",
      "Epoch 926/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.6268e-05 - mae: 0.0033\n",
      "Epoch 926: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7788e-05 - mae: 0.0034 - val_loss: 4.1762e-05 - val_mae: 0.0052\n",
      "Epoch 927/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4829e-05 - mae: 0.0030\n",
      "Epoch 927: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6988e-05 - mae: 0.0033 - val_loss: 4.1868e-05 - val_mae: 0.0052\n",
      "Epoch 928/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6876e-05 - mae: 0.0034\n",
      "Epoch 928: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.6206e-05 - mae: 0.0032 - val_loss: 4.4918e-05 - val_mae: 0.0054\n",
      "Epoch 929/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5800e-05 - mae: 0.0032\n",
      "Epoch 929: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.6305e-05 - mae: 0.0032 - val_loss: 4.2090e-05 - val_mae: 0.0052\n",
      "Epoch 930/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5769e-05 - mae: 0.0032\n",
      "Epoch 930: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6436e-05 - mae: 0.0032 - val_loss: 4.2247e-05 - val_mae: 0.0052\n",
      "Epoch 931/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7950e-05 - mae: 0.0035\n",
      "Epoch 931: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7181e-05 - mae: 0.0034 - val_loss: 4.8726e-05 - val_mae: 0.0056\n",
      "Epoch 932/1000\n",
      "430/800 [===============>..............] - ETA: 0s - loss: 1.7928e-05 - mae: 0.0034\n",
      "Epoch 932: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.8115e-05 - mae: 0.0034 - val_loss: 5.0445e-05 - val_mae: 0.0057\n",
      "Epoch 933/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.6767e-05 - mae: 0.0033\n",
      "Epoch 933: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 151us/sample - loss: 1.6767e-05 - mae: 0.0033 - val_loss: 4.8740e-05 - val_mae: 0.0056\n",
      "Epoch 934/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6152e-05 - mae: 0.0032\n",
      "Epoch 934: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6968e-05 - mae: 0.0033 - val_loss: 4.1635e-05 - val_mae: 0.0052\n",
      "Epoch 935/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.8999e-05 - mae: 0.0035\n",
      "Epoch 935: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.7582e-05 - mae: 0.0034 - val_loss: 4.9214e-05 - val_mae: 0.0057\n",
      "Epoch 936/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.6962e-05 - mae: 0.0033\n",
      "Epoch 936: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 144us/sample - loss: 1.6588e-05 - mae: 0.0032 - val_loss: 4.1515e-05 - val_mae: 0.0052\n",
      "Epoch 937/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.5356e-05 - mae: 0.0031\n",
      "Epoch 937: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.6408e-05 - mae: 0.0032 - val_loss: 4.2369e-05 - val_mae: 0.0052\n",
      "Epoch 938/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6173e-05 - mae: 0.0032\n",
      "Epoch 938: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.7514e-05 - mae: 0.0034 - val_loss: 4.1681e-05 - val_mae: 0.0052\n",
      "Epoch 939/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9986e-05 - mae: 0.0036\n",
      "Epoch 939: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8029e-05 - mae: 0.0034 - val_loss: 4.1797e-05 - val_mae: 0.0052\n",
      "Epoch 940/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6514e-05 - mae: 0.0033\n",
      "Epoch 940: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 147us/sample - loss: 1.6542e-05 - mae: 0.0033 - val_loss: 4.1625e-05 - val_mae: 0.0052\n",
      "Epoch 941/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.7244e-05 - mae: 0.0033\n",
      "Epoch 941: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 140us/sample - loss: 1.6252e-05 - mae: 0.0032 - val_loss: 4.1627e-05 - val_mae: 0.0052\n",
      "Epoch 942/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7236e-05 - mae: 0.0033\n",
      "Epoch 942: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7410e-05 - mae: 0.0033 - val_loss: 4.4989e-05 - val_mae: 0.0054\n",
      "Epoch 943/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5980e-05 - mae: 0.0032\n",
      "Epoch 943: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.7169e-05 - mae: 0.0033 - val_loss: 4.1389e-05 - val_mae: 0.0052\n",
      "Epoch 944/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.5734e-05 - mae: 0.0032\n",
      "Epoch 944: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 1.6508e-05 - mae: 0.0033 - val_loss: 4.3359e-05 - val_mae: 0.0053\n",
      "Epoch 945/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6176e-05 - mae: 0.0032\n",
      "Epoch 945: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6311e-05 - mae: 0.0032 - val_loss: 4.1410e-05 - val_mae: 0.0052\n",
      "Epoch 946/1000\n",
      "500/800 [=================>............] - ETA: 0s - loss: 1.7451e-05 - mae: 0.0034\n",
      "Epoch 946: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 1.6390e-05 - mae: 0.0033 - val_loss: 4.9886e-05 - val_mae: 0.0057\n",
      "Epoch 947/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/800 [=================>............] - ETA: 0s - loss: 1.8052e-05 - mae: 0.0034\n",
      "Epoch 947: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 126us/sample - loss: 1.6803e-05 - mae: 0.0033 - val_loss: 4.1606e-05 - val_mae: 0.0052\n",
      "Epoch 948/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6865e-05 - mae: 0.0033\n",
      "Epoch 948: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.9300e-05 - mae: 0.0035 - val_loss: 5.3542e-05 - val_mae: 0.0059\n",
      "Epoch 949/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.9611e-05 - mae: 0.0035\n",
      "Epoch 949: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.8614e-05 - mae: 0.0035 - val_loss: 5.0511e-05 - val_mae: 0.0057\n",
      "Epoch 950/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.5650e-05 - mae: 0.0032\n",
      "Epoch 950: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.6845e-05 - mae: 0.0033 - val_loss: 4.2262e-05 - val_mae: 0.0052\n",
      "Epoch 951/1000\n",
      "520/800 [==================>...........] - ETA: 0s - loss: 1.7144e-05 - mae: 0.0033\n",
      "Epoch 951: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.7656e-05 - mae: 0.0034 - val_loss: 4.3219e-05 - val_mae: 0.0053\n",
      "Epoch 952/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6530e-05 - mae: 0.0033\n",
      "Epoch 952: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 127us/sample - loss: 1.7738e-05 - mae: 0.0034 - val_loss: 4.1861e-05 - val_mae: 0.0052\n",
      "Epoch 953/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.7707e-05 - mae: 0.0034\n",
      "Epoch 953: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.7005e-05 - mae: 0.0033 - val_loss: 4.5843e-05 - val_mae: 0.0054\n",
      "Epoch 954/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.8628e-05 - mae: 0.0034\n",
      "Epoch 954: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.7589e-05 - mae: 0.0033 - val_loss: 4.2763e-05 - val_mae: 0.0053\n",
      "Epoch 955/1000\n",
      "510/800 [==================>...........] - ETA: 0s - loss: 1.8692e-05 - mae: 0.0035\n",
      "Epoch 955: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 1.7787e-05 - mae: 0.0034 - val_loss: 4.1786e-05 - val_mae: 0.0052\n",
      "Epoch 956/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.8882e-05 - mae: 0.0035\n",
      "Epoch 956: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 1.8782e-05 - mae: 0.0035 - val_loss: 4.2959e-05 - val_mae: 0.0053\n",
      "Epoch 957/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 2.1479e-05 - mae: 0.0037\n",
      "Epoch 957: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 2.0279e-05 - mae: 0.0036 - val_loss: 4.2157e-05 - val_mae: 0.0053\n",
      "Epoch 958/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.7013e-05 - mae: 0.0033\n",
      "Epoch 958: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.7538e-05 - mae: 0.0034 - val_loss: 4.1830e-05 - val_mae: 0.0052\n",
      "Epoch 959/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5788e-05 - mae: 0.0032\n",
      "Epoch 959: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6501e-05 - mae: 0.0033 - val_loss: 4.2255e-05 - val_mae: 0.0053\n",
      "Epoch 960/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4127e-05 - mae: 0.0029\n",
      "Epoch 960: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 129us/sample - loss: 1.6843e-05 - mae: 0.0033 - val_loss: 4.1952e-05 - val_mae: 0.0053\n",
      "Epoch 961/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6473e-05 - mae: 0.0033\n",
      "Epoch 961: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.6494e-05 - mae: 0.0033 - val_loss: 4.2555e-05 - val_mae: 0.0053\n",
      "Epoch 962/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4459e-05 - mae: 0.0030\n",
      "Epoch 962: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.9002e-05 - mae: 0.0035 - val_loss: 4.8568e-05 - val_mae: 0.0056\n",
      "Epoch 963/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.7778e-05 - mae: 0.0034\n",
      "Epoch 963: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.8021e-05 - mae: 0.0034 - val_loss: 4.5359e-05 - val_mae: 0.0054\n",
      "Epoch 964/1000\n",
      "400/800 [==============>...............] - ETA: 0s - loss: 1.3926e-05 - mae: 0.0030\n",
      "Epoch 964: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 146us/sample - loss: 1.6555e-05 - mae: 0.0033 - val_loss: 4.3478e-05 - val_mae: 0.0053\n",
      "Epoch 965/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4503e-05 - mae: 0.0031\n",
      "Epoch 965: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.5967e-05 - mae: 0.0032 - val_loss: 4.1992e-05 - val_mae: 0.0052\n",
      "Epoch 966/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.4473e-05 - mae: 0.0031\n",
      "Epoch 966: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 136us/sample - loss: 1.6401e-05 - mae: 0.0033 - val_loss: 4.1895e-05 - val_mae: 0.0052\n",
      "Epoch 967/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.4610e-05 - mae: 0.0030\n",
      "Epoch 967: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 137us/sample - loss: 1.7022e-05 - mae: 0.0032 - val_loss: 4.9953e-05 - val_mae: 0.0057\n",
      "Epoch 968/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6950e-05 - mae: 0.0033\n",
      "Epoch 968: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 141us/sample - loss: 1.6495e-05 - mae: 0.0032 - val_loss: 4.4290e-05 - val_mae: 0.0054\n",
      "Epoch 969/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6269e-05 - mae: 0.0033\n",
      "Epoch 969: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 145us/sample - loss: 1.8848e-05 - mae: 0.0035 - val_loss: 4.4198e-05 - val_mae: 0.0054\n",
      "Epoch 970/1000\n",
      "440/800 [===============>..............] - ETA: 0s - loss: 1.6425e-05 - mae: 0.0032\n",
      "Epoch 970: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 139us/sample - loss: 1.8549e-05 - mae: 0.0035 - val_loss: 4.2366e-05 - val_mae: 0.0052\n",
      "Epoch 971/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.6063e-05 - mae: 0.0032\n",
      "Epoch 971: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.6987e-05 - mae: 0.0033 - val_loss: 4.4575e-05 - val_mae: 0.0054\n",
      "Epoch 972/1000\n",
      "410/800 [==============>...............] - ETA: 0s - loss: 1.7664e-05 - mae: 0.0034\n",
      "Epoch 972: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 143us/sample - loss: 1.6827e-05 - mae: 0.0033 - val_loss: 4.2034e-05 - val_mae: 0.0052\n",
      "Epoch 973/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6965e-05 - mae: 0.0033\n",
      "Epoch 973: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6578e-05 - mae: 0.0033 - val_loss: 4.4960e-05 - val_mae: 0.0054\n",
      "Epoch 974/1000\n",
      "420/800 [==============>...............] - ETA: 0s - loss: 1.6684e-05 - mae: 0.0032\n",
      "Epoch 974: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 138us/sample - loss: 1.7126e-05 - mae: 0.0033 - val_loss: 4.3164e-05 - val_mae: 0.0053\n",
      "Epoch 975/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.5852e-05 - mae: 0.0032\n",
      "Epoch 975: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6830e-05 - mae: 0.0033 - val_loss: 4.3357e-05 - val_mae: 0.0053\n",
      "Epoch 976/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/800 [=================>............] - ETA: 0s - loss: 1.8045e-05 - mae: 0.0034\n",
      "Epoch 976: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 130us/sample - loss: 1.7474e-05 - mae: 0.0034 - val_loss: 4.1756e-05 - val_mae: 0.0052\n",
      "Epoch 977/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.6970e-05 - mae: 0.0034\n",
      "Epoch 977: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 134us/sample - loss: 1.6856e-05 - mae: 0.0033 - val_loss: 4.1692e-05 - val_mae: 0.0052\n",
      "Epoch 978/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.6648e-05 - mae: 0.0033\n",
      "Epoch 978: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.6685e-05 - mae: 0.0033 - val_loss: 4.1700e-05 - val_mae: 0.0052\n",
      "Epoch 979/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.5857e-05 - mae: 0.0032\n",
      "Epoch 979: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.6708e-05 - mae: 0.0033 - val_loss: 4.1752e-05 - val_mae: 0.0052\n",
      "Epoch 980/1000\n",
      "460/800 [================>.............] - ETA: 0s - loss: 1.5641e-05 - mae: 0.0032\n",
      "Epoch 980: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 133us/sample - loss: 1.6387e-05 - mae: 0.0033 - val_loss: 4.9021e-05 - val_mae: 0.0057\n",
      "Epoch 981/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 1.6849e-05 - mae: 0.0033\n",
      "Epoch 981: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 1.7720e-05 - mae: 0.0034 - val_loss: 4.4202e-05 - val_mae: 0.0053\n",
      "Epoch 982/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.9447e-05 - mae: 0.0035\n",
      "Epoch 982: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.8552e-05 - mae: 0.0035 - val_loss: 4.2537e-05 - val_mae: 0.0053\n",
      "Epoch 983/1000\n",
      "570/800 [====================>.........] - ETA: 0s - loss: 1.7404e-05 - mae: 0.0034\n",
      "Epoch 983: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 1.7483e-05 - mae: 0.0034 - val_loss: 4.5148e-05 - val_mae: 0.0054\n",
      "Epoch 984/1000\n",
      "570/800 [====================>.........] - ETA: 0s - loss: 1.8960e-05 - mae: 0.0035\n",
      "Epoch 984: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 1.7655e-05 - mae: 0.0033 - val_loss: 4.3746e-05 - val_mae: 0.0053\n",
      "Epoch 985/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.8095e-05 - mae: 0.0035\n",
      "Epoch 985: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.8288e-05 - mae: 0.0034 - val_loss: 4.1968e-05 - val_mae: 0.0052\n",
      "Epoch 986/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.8154e-05 - mae: 0.0034\n",
      "Epoch 986: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 1.8262e-05 - mae: 0.0035 - val_loss: 4.3642e-05 - val_mae: 0.0054\n",
      "Epoch 987/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.8518e-05 - mae: 0.0035\n",
      "Epoch 987: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 1.7954e-05 - mae: 0.0034 - val_loss: 4.1893e-05 - val_mae: 0.0053\n",
      "Epoch 988/1000\n",
      "540/800 [===================>..........] - ETA: 0s - loss: 1.7617e-05 - mae: 0.0034\n",
      "Epoch 988: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 1.6575e-05 - mae: 0.0033 - val_loss: 4.2288e-05 - val_mae: 0.0053\n",
      "Epoch 989/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.9303e-05 - mae: 0.0035\n",
      "Epoch 989: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.8286e-05 - mae: 0.0034 - val_loss: 4.1964e-05 - val_mae: 0.0053\n",
      "Epoch 990/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.5415e-05 - mae: 0.0032\n",
      "Epoch 990: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.5751e-05 - mae: 0.0032 - val_loss: 4.3697e-05 - val_mae: 0.0053\n",
      "Epoch 991/1000\n",
      "550/800 [===================>..........] - ETA: 0s - loss: 1.5465e-05 - mae: 0.0031\n",
      "Epoch 991: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 1.6484e-05 - mae: 0.0032 - val_loss: 4.2564e-05 - val_mae: 0.0052\n",
      "Epoch 992/1000\n",
      "530/800 [==================>...........] - ETA: 0s - loss: 1.7680e-05 - mae: 0.0034\n",
      "Epoch 992: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 1.7417e-05 - mae: 0.0034 - val_loss: 4.2973e-05 - val_mae: 0.0053\n",
      "Epoch 993/1000\n",
      "560/800 [====================>.........] - ETA: 0s - loss: 1.6399e-05 - mae: 0.0033\n",
      "Epoch 993: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 1.6623e-05 - mae: 0.0033 - val_loss: 4.6519e-05 - val_mae: 0.0055\n",
      "Epoch 994/1000\n",
      "480/800 [=================>............] - ETA: 0s - loss: 1.5776e-05 - mae: 0.0032\n",
      "Epoch 994: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 1.7848e-05 - mae: 0.0034 - val_loss: 4.2290e-05 - val_mae: 0.0053\n",
      "Epoch 995/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 1.8260e-05 - mae: 0.0035\n",
      "Epoch 995: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 149us/sample - loss: 1.8260e-05 - mae: 0.0035 - val_loss: 4.2805e-05 - val_mae: 0.0053\n",
      "Epoch 996/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6039e-05 - mae: 0.0033\n",
      "Epoch 996: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 125us/sample - loss: 1.7058e-05 - mae: 0.0033 - val_loss: 4.6683e-05 - val_mae: 0.0055\n",
      "Epoch 997/1000\n",
      "450/800 [===============>..............] - ETA: 0s - loss: 1.9370e-05 - mae: 0.0035\n",
      "Epoch 997: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 132us/sample - loss: 1.7725e-05 - mae: 0.0034 - val_loss: 4.2325e-05 - val_mae: 0.0052\n",
      "Epoch 998/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.6253e-05 - mae: 0.0032\n",
      "Epoch 998: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 128us/sample - loss: 1.6581e-05 - mae: 0.0033 - val_loss: 4.1366e-05 - val_mae: 0.0052\n",
      "Epoch 999/1000\n",
      "470/800 [================>.............] - ETA: 0s - loss: 1.7936e-05 - mae: 0.0034\n",
      "Epoch 999: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 131us/sample - loss: 1.6993e-05 - mae: 0.0033 - val_loss: 4.2133e-05 - val_mae: 0.0052\n",
      "Epoch 1000/1000\n",
      "490/800 [=================>............] - ETA: 0s - loss: 1.6323e-05 - mae: 0.0033\n",
      "Epoch 1000: val_loss did not improve from 0.00004\n",
      "800/800 [==============================] - 0s 124us/sample - loss: 1.6679e-05 - mae: 0.0033 - val_loss: 4.7480e-05 - val_mae: 0.0055\n"
     ]
    }
   ],
   "source": [
    "Layers = [{'size': nx+1, 'activation': None    , 'use_bias': None},\n",
    "          {'size': 10 , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1  , 'activation': 'linear', 'use_bias': False}]\n",
    "Losses = [{'kind': 'mse', 'weight': 1.0}]\n",
    "\n",
    "K = TrainFullyConnectedNN(M_samples, H_samples, \n",
    "                    Layers, Losses,\n",
    "                    'adam', ['mae'], \n",
    "                    10, 1000, 0.2, \n",
    "                    'model', os.path.abspath(''))\n",
    "\n",
    "best_model = K.quickTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7337de",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': 0.0}\n",
    "\n",
    "X = XAIR(best_model, 'lrp.alpha_1_beta_0', 'classic', M_samples, normalizeDict, **kwargs)\n",
    "a_a1b0, _  = X.quick_analyze()\n",
    "\n",
    "X = XAIR(best_model, 'lrp.z', 'classic', M_samples, normalizeDict, **kwargs)\n",
    "a_z, _  = X.quick_analyze()\n",
    "\n",
    "L = TrainLR(M_samples, H_samples, y_ref = 0.0, fit_intercept = False)\n",
    "regr = L.quickTrain()\n",
    "\n",
    "XL = XLR(regr, M_samples)\n",
    "a_LR, _ = XL.quick_analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cad66ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b82b55aa140>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.tight_layout()\n",
    "\n",
    "ax.plot(np.mean(a_a1b0, axis = 0)[50:150], 'b', label = 'Mean lrp.alpha_1_beta_0')\n",
    "ax.plot(np.mean(a_z, axis = 0)[50:150], 'r--', label = 'Mean lrp.z')\n",
    "ax.plot(np.mean(a_LR, axis = 0)[50:150], 'g:', label = 'Mean lrp.LR')\n",
    "ax.plot(grad_0[50:150], 'k-.', label = 'FD grad for sample 0')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ccd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': 0.001}\n",
    "X = XAIR(best_model, 'lrp.alpha_1_beta_0', 'letzgus', M_samples[:2], normalizeDict, **kwargs)\n",
    "X.check_sample(M_samples[0]), X.check_sample(M_samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f591db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "a, stats  = X.quick_analyze()\n",
    "plt.plot(a[0])\n",
    "plt.plot(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658003da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ref = 0.001\n",
    "best_model = K.loadBestModel()\n",
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': y_ref}\n",
    "X = XAIR(best_model, 'lrp.z', 'classic', M_samples[:10], normalizeDict, **kwargs)\n",
    "X.check_sample(M_samples[0]), X.check_sample(M_samples[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a05202",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a, stats  = X.quick_analyze()\n",
    "plt.plot(a[0])\n",
    "plt.plot(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = TrainLR(M_samples, H_samples, y_ref = y_ref, fit_intercept = False)\n",
    "regr = L.quickTrain()\n",
    "\n",
    "XL = XLR(regr, M_samples)\n",
    "a_LR, stats_LR = XL.quick_analyze()\n",
    "\n",
    "plt.plot(a_LR[0])\n",
    "plt.plot(a_LR[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb211cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ref = 0.0004\n",
    "best_model = K.loadBestModel()\n",
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': y_ref}\n",
    "X = XAIR(best_model, 'lrp.z', 'classic', M_samples[:10], normalizeDict, **kwargs)\n",
    "X.check_sample(M_samples[0]), X.check_sample(M_samples[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753dc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a, stats  = X.quick_analyze()\n",
    "plt.plot(a[0])\n",
    "plt.plot(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3550ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = TrainLR(M_samples, H_samples, y_ref = y_ref, fit_intercept = False)\n",
    "regr = L.quickTrain()\n",
    "\n",
    "XL = XLR(regr, M_samples)\n",
    "a_LR, stats_LR = XL.quick_analyze()\n",
    "\n",
    "plt.plot(a_LR[0])\n",
    "plt.plot(a_LR[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa0ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try one model with non-zero last layer bias\n",
    "\n",
    "Layers = [{'size': nx+1, 'activation': None    , 'use_bias': None},\n",
    "          {'size': 10 , 'activation': 'relu'  , 'use_bias': True},\n",
    "          {'size': 1  , 'activation': 'linear', 'use_bias': True}]\n",
    "Losses = [{'kind': 'mse', 'weight': 1.0}]\n",
    "\n",
    "K = TrainFullyConnectedNN(M_samples, H_samples, \n",
    "                    Layers, Losses,\n",
    "                    'adam', ['mae'], \n",
    "                    10, 1000, 0.2, \n",
    "                    'model', os.path.abspath(''))\n",
    "\n",
    "best_model = K.quickTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0602507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ref = 0.0004\n",
    "best_model = K.loadBestModel()\n",
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': y_ref}\n",
    "X = XAIR(best_model, 'lrp.z', 'classic', M_samples[:10], normalizeDict, **kwargs)\n",
    "X.check_sample(M_samples[0]), X.check_sample(M_samples[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, stats  = X.quick_analyze()\n",
    "plt.plot(a[0])\n",
    "plt.plot(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a85bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = TrainLR(M_samples, H_samples, y_ref = y_ref, fit_intercept = False)\n",
    "regr = L.quickTrain()\n",
    "\n",
    "XL = XLR(regr, M_samples)\n",
    "a_LR, stats_LR = XL.quick_analyze()\n",
    "\n",
    "plt.plot(a_LR[0])\n",
    "plt.plot(a_LR[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9349edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ref = 0.0\n",
    "best_model = K.loadBestModel()\n",
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': y_ref}\n",
    "X = XAIR(best_model, 'lrp.alpha_1_beta_0', 'classic', M_samples, normalizeDict, **kwargs)\n",
    "a_a1b0, _  = X.quick_analyze()\n",
    "plt.plot(np.mean(a_a1b0, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ref = 0.0\n",
    "best_model = K.loadBestModel()\n",
    "normalizeDict = {'bool_':True, 'kind': 'MaxAbs'}\n",
    "kwargs = {'y_ref': y_ref}\n",
    "X = XAIR(best_model, 'lrp.z', 'classic', M_samples, normalizeDict, **kwargs)\n",
    "a_z, _  = X.quick_analyze()\n",
    "plt.plot(np.mean(a_z, axis = 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_LRP",
   "language": "python",
   "name": "py310_lrp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
